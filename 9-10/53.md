好的，作为资深Java开发工程师，我将为您全面解答这些面试问题。

---

### **1. java中的==和equal有什么区别**

**原题**：java中的==和equal有什么区别

**解答**：

这是一个考察Java基础的核心问题，涉及到对象比较的两种不同机制。

**定义与工作原理**：
- **`==` 操作符**：这是一个比较运算符。
  - 当用于**基本数据类型**（如int, char, double等）时，它比较的是两个变量的**值**是否相等。
  - 当用于**引用数据类型**（如Object, String, 自定义类等）时，它比较的是两个变量在**内存中的地址（即是否指向同一个对象）**，而不是它们所包含的内容。
- **`equals()` 方法**：这是一个定义在`Object`类中的方法，所有Java类都继承自Object类。
  - `Object`类中的默认`equals()`实现（`return (this == obj);`）和`==`操作符的行为完全一样，也是比较内存地址。
  - 但是，**`equals()`方法的设计初衷是为了让子类重写（Override）**，从而实现基于**内容**的逻辑相等性比较。许多Java核心类（如`String`, `Integer`, `Date`）都重写了`equals()`方法。

**使用场景**：
- 使用 `==`：
  - 比较基本数据类型的值。
  - 判断两个引用是否指向JVM堆中的**同一个实际对象**。
- 使用 `equals()`：
  - 判断两个**不同的对象**在**逻辑上是否相等**（例如，两个不同的String对象是否都包含相同的字符序列）。

**注意事项与最佳实践**：
1.  **重写`equals()`必须重写`hashCode()`**：这是一个至关重要的约定。如果两个对象根据`equals()`比较是相等的，那么调用它们的`hashCode()`方法也必须产生相同的整数结果。反之则不一定。这条约定在基于哈希的集合（如`HashMap`, `HashSet`）中至关重要，如果违反，会导致这些集合无法正常工作。
2.  **空指针安全**：调用`a.equals(b)`时，如果`a`是`null`，会抛出`NullPointerException`。推荐使用`java.util.Objects.equals(Object a, Object b)`静态方法，它是空指针安全的。
    ```java
    String a = null;
    String b = "hello";
    // 不安全，会抛NPE
    // boolean result = a.equals(b);
    // 安全，推荐
    boolean safeResult = Objects.equals(a, b); // 返回false
    ```
3.  **`String`比较的经典陷阱**：由于JVM的字符串常量池机制，有时使用`==`比较字符串也能得到“正确”结果，但这完全是巧合，**永远不要使用`==`来比较字符串内容**。
    ```java
    String s1 = "hello"; // 在常量池中
    String s2 = "hello"; // 指向常量池中同一个"hello"
    String s3 = new String("hello"); // 在堆中创建一个新的String对象

    System.out.println(s1 == s2); // true (地址相同)
    System.out.println(s1 == s3); // false (地址不同)
    System.out.println(s1.equals(s3)); // true (内容相同)
    ```

---

### **2. treeMap和hashMap的区别以及底层实现**

**原题**：treeMap和hashMap的区别以及底层实现

**解答**：

`HashMap`和`TreeMap`都是`Map`接口的重要实现，但它们在数据结构、性能特性和使用场景上有显著区别。

| 特性 | HashMap | TreeMap |
| :--- | :--- | :--- |
| **底层数据结构** | **数组 + 链表/红黑树** (JDK8+) | **红黑树** (一种自平衡的二叉搜索树) |
| **元素顺序** | **不保证顺序**（遍历顺序可能与插入顺序不同），且顺序可能随时间变化 | **元素根据键（Key）自然顺序或提供的Comparator进行排序**，遍历时按排序顺序输出 |
| **`null`键** | **允许一个`null`键** | **不允许`null`键**（如果使用自然排序，会抛`NullPointerException`） |
| **性能 (`get`, `put`)** | **平均O(1)**，最坏情况（哈希冲突严重）O(n)，JDK8+优化为O(log n) | **O(log n)**，因为需要维护树的平衡 |
| **实现接口** | 实现`Map`接口 | 实现`Map`接口和`NavigableMap`接口（支持范围查询） |

**底层实现详解**：

- **HashMap**：
  1.  **存储结构**：内部有一个`Node<K,V>[] table`数组，每个数组位置称为一个“桶”（bucket）。
  2.  **`put`操作**：
      - 计算键的`hashCode()`，再通过**扰动函数**（(h = key.hashCode()) ^ (h >>> 16)）得到哈希值`hash`，目的是减少哈希冲突。
      - 使用`(n - 1) & hash`（n是数组长度）计算元素应放入的桶下标。
      - 如果该桶为空，直接放入。
      - 如果桶不为空（哈希冲突），则遍历该桶上的链表（或树）：
        - 如果找到相同的key（`hash`相等且`(key == k || key.equals(k))`），则覆盖value。
        - 如果没找到，则将新节点添加到链表末尾（或插入树中）。
  3.  **扩容**：当元素数量超过`容量 * 负载因子(默认0.75)`时，数组会扩容为原来的2倍，并重新计算所有元素的位置（rehash），这是一个耗时的操作。
  4.  **树化**：在JDK8+中，当单个桶中的链表长度超过8且数组总容量大于64时，该链表会转换为**红黑树**，以提高极端情况下的查询效率。当桶中节点数减少到6时，树会退化为链表。

- **TreeMap**：
  1.  **存储结构**：基于红黑树（Red-Black tree）。红黑树是一种近似平衡的二叉搜索树，它确保了最坏情况下基本操作（插入、删除、查找）的时间复杂度为O(log n)，同时保持着良好的平衡性，旋转开销小于AVL树。
  2.  **`put`操作**：
      - 从根节点开始比较。
      - 如果使用了自定义`Comparator`，则用它来比较键。
      - 否则，使用键的**自然顺序**（Key必须实现`Comparable`接口）。
      - 根据比较结果决定是搜索左子树还是右子树，直到找到空位插入新节点。
      - 插入新节点（默认为红色）后，可能会破坏红黑树的平衡性质（如不能有连续的红节点，根节点必须是黑等），需要通过**旋转**和**重新着色**来修复树结构，使其重新平衡。

**使用场景与最佳实践**：
- **使用`HashMap`**：当你需要**最高效的存取性能**，并且不关心元素的遍历顺序时。这是最常用的Map实现。
- **使用`TreeMap`**：当你需要**元素始终处于排序状态**，或者需要**进行范围查询**（如`subMap()`, `headMap()`, `tailMap()`）时。
- **初始化`HashMap`**：如果能预估数据量，最好在创建时指定初始容量（如`new HashMap<>(1024)`），以避免多次rehash，提升性能。
- **键对象的不可变性**：用作`HashMap`键或`TreeMap`键的对象，最好是**不可变的**（如`String`, `Integer`）。如果键的`hashCode()`或`compareTo()`结果在存入后发生变化，会导致Map行为异常，无法正确找到该键值对。

---

### **3. java中BIO和NIO是什么，如何实现的，是否有过实际的使用**

**原题**：java中BIO和NIO是什么，如何实现的，是否有过实际的使用

**解答**：

这是一个关于Java I/O模型演进的核心问题，涉及到网络编程的性能瓶颈。

**定义与工作原理**：

- **BIO (Blocking I/O) - 同步阻塞I/O**：
  - **是什么**：JDK1.4之前的传统I/O模型。**同步**意味着应用程序会主动等待I/O操作完成。**阻塞**意味着调用线程在读写操作完成之前会被挂起，什么也做不了。
  - **实现**：基于**流（Stream）**。使用`ServerSocket`和`Socket`进行网络通信。
    - **服务器端模式**：通常采用**“一个连接一个线程”** 的模型。`ServerSocket.accept()`会阻塞等待客户端连接。每当有一个新连接建立，服务器就创建一个新线程来处理这个连接的读写（`socket.getInputStream().read()`也会阻塞）。
    - **缺点**：线程是昂贵的系统资源。当连接数非常多（C10K问题）但大部分连接并不活跃时，会创建大量空闲线程，消耗大量内存，且线程上下文切换开销巨大，导致性能急剧下降。

- **NIO (New I/O / Non-blocking I/O) - 同步非阻塞I/O**：
  - **是什么**：JDK1.4引入。**同步**的含义不变，但**非阻塞**意味着调用线程在发起一个I/O操作后可以立即返回去做别的事情，不必等待数据准备就绪。它通过轮询机制来知道什么时候数据就绪了。
  - **实现**：基于**通道（Channel）**和**缓冲区（Buffer）**，核心是**多路复用器（Selector）**。
    - **Channel**：类似于流，但可以同时读写，并且支持非阻塞模式。
    - **Buffer**：一个线性的、有限的数据容器，是数据读写的中转站。
    - **Selector**：一个I/O多路复用的核心组件。一个Selector可以同时轮询多个Channel上的事件（如连接就绪、读就绪、写就绪）。当一个Channel上的事件就绪时，Selector会通知应用程序，然后应用程序再对这个Channel进行实际的I/O操作。
    - **服务器端模式**：采用**“一个线程处理多个连接”** 的Reactor模式。将所有Channel注册到Selector上，由一个或少量线程不断轮询Selector，检查哪些Channel有就绪的事件，然后只对这些就绪的Channel进行I/O操作。极大减少了线程开销。

**使用场景与最佳实践**：
- **BIO**：适用于**连接数较少且固定**的架构，例如传统的客户端/桌面应用程序、内部系统调用。编程模型简单。
- **NIO**：适用于**高并发、高连接数（长连接）** 的场景，例如聊天服务器、游戏服务器、RPC框架等。Netty和Mina等高性能网络框架都是基于Java NIO构建的。
- **实际使用**：在实际项目中，我们很少直接使用原生NIO的API进行开发，因为它的API复杂，需要自己处理很多底层细节（如粘包拆包、断线重连等）。我们通常会使用**Netty**框架。Netty对NIO进行了极好的封装和增强，提供了简单易用的API和强大的功能，是构建高性能网络应用的首选。例如，我在[某项目]中开发一个实时数据推送服务，就使用了Netty作为通信框架，它可以轻松应对数万客户端的并发长连接。

**扩展：AIO (Asynchronous I/O)**：
JDK7引入了AIO（异步I/O），它是真正的**异步非阻塞I/O**。应用程序发起一个I/O操作后立即返回，当操作系统完成整个I/O操作（数据已从内核空间拷贝到用户空间）后，会主动回调应用程序指定的接口。AIO理论上性能更高，但在Linux上的实现不够成熟，应用不如NIO广泛。

---

### **4. JVM调优，使用过哪些参数？**

**原题**：JVM调优，使用过哪些参数？

**解答**：

JVM调优是一个经验性很强的工作，目标通常是在有限的硬件资源下，获得更高的吞吐量或更低的延迟。调优没有银弹，需要结合监控工具（如jstat, jstack, jmap, VisualVM, Prometheus+Grafana）进行分析。

**常用JVM参数分类**：

1.  **堆内存相关（最核心）**：
    - `-Xms` / `-Xmx`：设置**堆的初始大小**和**最大大小**。通常将它们设为**相同的值**，以避免堆扩容带来的性能抖动。例如：`-Xms4g -Xmx4g`。
    - `-Xmn`：设置**年轻代（Young Generation）**的大小。整个堆 = 年轻代 + 老年代（Old Generation）。增大年轻代会让Minor GC频率降低，但每次时间可能变长。Oracle推荐设置为整个堆的3/8。
    - `-XX:SurvivorRatio`：设置Eden区和Survivor区的大小比例。例如`-XX:SurvivorRatio=8`表示Eden:Survivor:Survivor = 8:1:1。
    - `-XX:NewRatio`：设置老年代和年轻代的比例。例如`-XX:NewRatio=2`表示老年代:年轻代=2:1。

2.  **垃圾收集器相关**：
    - **JDK8及之前**：
      - `-XX:+UseParallelGC`：使用Parallel Scavenge + Parallel Old组合，**注重吞吐量**。
      - `-XX:+UseConcMarkSweepGC`：使用ParNew + CMS组合，**注重低延迟**，减少Full GC停顿时间。（现已不推荐）
    - **JDK8+ ~ 现在（主流）**：
      - `-XX:+UseG1GC`：启用G1垃圾收集器，适用于大内存、低延迟场景。是JDK9以后的默认收集器。
        - `-XX:MaxGCPauseMillis`：为G1设置**目标最大停顿时间**（毫秒），G1会尽力实现但不保证。
        - `-XX:InitiatingHeapOccupancyPercent`：触发Mixed GC的堆占用率阈值（默认45%）。
      - `-XX:+UseZGC` / `-XX:+UseShenandoahGC`：JDK11+引入的**超低延迟**收集器（停顿时间不随堆大小增长），适用于超大堆（TB级别）。

3.  **GC日志相关（必须配置）**：
    - `-XX:+PrintGC` / `-XX:+PrintGCDetails`：打印GC详细信息。
    - `-Xloggc:<file>`：将GC日志输出到文件。
    - `-XX:+PrintGCTimeStamps` / `-XX:+PrintGCDateStamps`：在GC日志中添加时间戳。
    - `-XX:+UseGCLogFileRotation` & `-XX:NumberOfGCLogFiles=5` & `-XX:GCLogFileSize=10M`：GC日志文件滚动归档。

4.  **故障排查相关**：
    - `-XX:+HeapDumpOnOutOfMemoryError`：在发生OOM时自动生成堆转储（Heap Dump）文件。
    - `-XX:HeapDumpPath=<path>`：指定堆转储文件的路径。
    - `-XX:OnOutOfMemoryError=<command>`：发生OOM时执行指定命令（如发报警邮件、重启脚本）。

**调优思路与最佳实践**：
1.  **第一步：监控分析**：不要盲目调参！先用`jstat -gcutil <pid> 1s`观察GC频率、各区域使用率、停顿时间。用`jstack`查看线程状态，排查死锁或长时间GC导致的停顿。
2.  **第二步：设定目标**：是追求高吞吐量（如后台批处理系统）还是低延迟（如在线API服务）？
3.  **第三步：调整堆大小**：根据物理内存，设置`-Xms`和`-Xmx`为同一值。通常建议堆大小不超过系统可用内存的70-80%。
4.  **第四步：选择收集器**：
    - 吞吐量优先：`UseParallelGC`。
    - 低延迟优先（堆<8G）：`UseG1GC`并设置`MaxGCPauseMillis`。
    - 超大堆超低延迟（JDK11+）：`UseZGC`。
5.  **第五步：细化调整**：根据GC日志，调整新生代大小、SurvivorRatio等参数，避免对象过早晋升到老年代，减少Full GC。
6.  **最佳实践**：**将调优后的参数写入启动脚本**，并配合完善的日志和监控系统。

**示例参数**（一个8G堆的Web服务）：
```bash
java -Xms8g -Xmx8g \
-XX:+UseG1GC \
-XX:MaxGCPauseMillis=200 \
-XX:InitiatingHeapOccupancyPercent=40 \
-XX:+PrintGCDetails -XX:+PrintGCDateStamps \
-Xloggc:/opt/app/logs/gc.log \
-XX:+HeapDumpOnOutOfMemoryError \
-XX:HeapDumpPath=/opt/app/logs/heapdump.hprof \
-jar myapp.jar
```

---

### **5. tcp三次握手和四次挥手，为什么是四次挥手而不是三次**

**原题**：tcp三次握手和四次挥手，为什么是四次挥手而不是三次

**解答**：

**TCP三次握手（建立连接）**：
目的是为了确认双方的发送和接收能力都正常，并同步初始序列号（ISN）。
1.  **SYN**：客户端发送一个SYN包（SYN=1, seq=x）到服务器，进入SYN_SENT状态。
2.  **SYN-ACK**：服务器收到SYN包，发回一个SYN-ACK包（SYN=1, ACK=1, ack=x+1, seq=y）作为应答，进入SYN_RCVD状态。
3.  **ACK**：客户端收到SYN-ACK包，再发送一个ACK包（ACK=1, ack=y+1）给服务器。服务器收到后，双方进入ESTABLISHED状态，连接建立成功。

**TCP四次挥手（终止连接）**：
目的是双方都确认要关闭连接。由于TCP是**全双工**的，每个方向都必须单独进行关闭。
1.  **FIN**：主动关闭方（假设是客户端）发送一个FIN包（FIN=1, seq=u），用来关闭客户端到服务器的数据传送，客户端进入FIN_WAIT_1状态。
2.  **ACK**：服务器收到FIN包，发回一个ACK包（ACK=1, ack=u+1），确认收到关闭请求。服务器进入CLOSE_WAIT状态，客户端收到后进入FIN_WAIT_2状态。
    - **此时，从客户端到服务器的连接已关闭，但服务器到客户端的连接仍然可用**。服务器可能还有数据要发送给客户端（半关闭状态）。
3.  **FIN**：当服务器也完成了数据的发送，准备关闭连接时，它发送自己的FIN包（FIN=1, seq=w）给客户端，服务器进入LAST_ACK状态。
4.  **ACK**：客户端收到FIN包，发回一个ACK包（ACK=1, ack=w+1）作为确认，并进入TIME_WAIT状态，等待2MSL（Maximum Segment Lifetime）时间后彻底关闭。服务器收到ACK后，立即关闭连接。

**为什么是四次而不是三次？**
核心原因就是TCP连接的**全双工**特性。挥手比握手多一次，是因为**握手的SYN和ACK可以被合并**在一个包里发送（服务器同时对客户端的SYN进行确认和发送自己的SYN）。而挥手时，当被动关闭方收到主动方的FIN时，它可能还有数据要发送，不能立即关闭连接，所以它的ACK和FIN**不能合并**，必须分两次发送，这就导致了四次挥手。

---

### **6. tcp建立连接后如果没有数据传输会断开吗**

**原题**：tcp建立连接后如果没有数据传输会断开吗

**解答**：

**会的**。即使没有数据传输，TCP连接也可能会被断开。这通常是由操作系统内核的TCP协议栈机制或网络设备（如防火墙）的策略控制的。

1.  **TCP Keepalive机制**：
    - 操作系统内核为每个TCP连接提供了一个可选的**保活（Keepalive）** 机制。
    - 当启用该机制后，在一个连接空闲（没有数据交换）超过指定的时间后，内核会向对端发送一个保活探测包（Keepalive Probe）。如果连续多个探测包都没有得到响应，内核就认为该连接已经失效，并将其断开。
    - **参数**（Linux系统，可全局或 per-socket 设置）：
      - `tcp_keepalive_time`：连接空闲多久后开始发送探测包（默认7200秒，即2小时）。
      - `tcp_keepalive_intvl`：探测包发送的间隔时间（默认75秒）。
      - `tcp_keepalive_probes`：最多发送多少个探测包（默认9次）。
    - 因此，一个启用了Keepalive的空闲连接，最多可能在 `7200s + 75s * 9 ≈ 7875s`（约2小时11分钟）后断开。

2.  **应用层心跳包**：
    - 很多应用层协议（如HTTP/1.1的持久连接、WebSocket、MQTT、自定义RPC协议）会自己实现**应用层的心跳机制**。
    - 客户端和服务器会定期互相发送一个很小的、不包含业务数据的心跳包（或Ping-Pong包），其主要目的有兩個：
      - **保活**：告诉网络路径上的所有防火墙和路由器，这个连接是活跃的，请不要因为它空闲而将其断开。
      - **检测故障**：及时发现对端是否已经崩溃、死机或网络不可达。
    - 应用层心跳的间隔（如30秒、60秒）远小于TCP Keepalive的默认值，因此能更及时地维持连接和发现故障，是更常用的方式。

3.  **中间设备（防火墙/NAT）**：
    - 许多防火墙和NAT（网络地址转换）设备会为经过它们的连接设置一个**会话超时时间**。如果一条连接在超时时间内没有任何数据包，设备会为了节省资源而删除该连接的会话表项，导致后续的数据包被丢弃，连接实质上被断开了。

**结论**：一个空闲的TCP连接不会永远存在。它可能被操作系统、中间网络设备或因对端异常而断开。因此，在需要长连接的应用中，**必须实现应用层的心跳机制**来维持连接。

---

### **7. 如果服务访问出现卡顿现象怎么排查，你的思路是什么？**

**原题**：如果服务访问出现卡顿现象怎么排查，你的思路是什么？

**解答**：

服务卡顿是一个综合性问题，排查思路需要从外到内、从上到下，层层递进。我的系统性排查思路如下：

**第一步：明确现象和范围**
1.  **是全局性问题还是局部性问题？**：通过监控查看是所有实例、所有接口都卡顿，还是只有某个服务、某个接口卡顿？这有助于快速定位问题边界。
2.  **是什么时候开始的？** 是否有最近的发布、配置变更或流量陡增？

**第二步：监控指标分析（自上而下）**
1.  **基础设施层**：
    - **CPU**：使用率是否过高？`us`（用户态）高可能是应用代码问题，`sy`（内核态）高可能是系统调用频繁或线程上下文切换频繁。`iowait`高可能是磁盘I/O瓶颈。
    - **内存**：是否耗尽？是否频繁Swap？
    - **磁盘I/O**：读写延迟、使用率是否异常？（特别是数据库和日志）
    - **网络I/O**：带宽是否打满？是否有大量丢包或重传？（`netstat`, `sar`）
2.  **应用层**：
    - **GC情况**：使用`jstat`或GC日志查看。**是否发生了长时间的Full GC？** Young GC频率是否异常？这是Java应用卡顿的最常见原因。
    - **线程池**：是否有大量线程阻塞？是否线程池耗尽？使用`jstack`导出线程栈，查看线程状态（BLOCKED, WAITING等），分析锁竞争或慢I/O。
    - **业务指标**：QPS、响应时间、错误率。通过APM工具（如SkyWalking, Pinpoint）或链路追踪，定位是哪个慢接口、哪个慢服务调用导致的。
3.  **下游依赖层**：
    - **数据库**：慢查询是否增多？数据库CPU/连接数是否异常？是否存在大表锁或行锁等待？
    - **缓存**：Redis/Memcached的响应时间是否变慢？缓存命中率是否下降？
    - **外部服务/API**：调用第三方服务的响应时间是否变长？超时是否增多？

**第三步：深入诊断工具**
- **CPU高**：`top -Hp <pid>`找到耗CPU的线程ID，再用`jstack <pid>`将线程ID（十进制）转换为十六进制，去线程栈里找到对应的代码行。
- **内存高/OOM**：使用`jmap -histo:live <pid>`查看对象实例统计，或用`jmap -dump`生成堆转储文件，用MAT/JProfiler分析内存泄漏。
- **线程阻塞**：分析`jstack`输出的线程栈，查找`"BLOCKED (on object monitor)"`或等待锁的线程，定位死锁或锁竞争热点。
- **I/O问题**：使用`iostat`, `iotop`命令诊断磁盘I/O，使用`tcpdump`或Wireshark抓包分析网络问题。

**第四步：常见原因及解决方案**
- **数据库慢查询**：增加索引、优化SQL、引入读写分离、分库分表。
- **缓存问题**：检查缓存穿透、缓存击穿、缓存雪崩，优化缓存策略。
- **GC问题**：根据前述JVM调优方法，调整堆大小、选择垃圾收集器、优化代码避免创建过多对象。
- **代码BUG**：如死循环、无限递归、同步锁使用不当、 inefficient algorithms。
- **资源竞争**：线程池配置不合理、连接池耗尽。

**总结思路**：从监控入手，先定位出问题的资源层面（CPU/内存/IO/网络）或应用层面（GC/线程/某个服务），再使用相应的工具进行深入分析，最终定位到具体的代码或配置问题。这是一个需要结合监控系统、日志分析和命令行工具的综合能力。

---

### **8. 手撕：二叉树的右视图**

**原题**：二叉树的右视图

**相似LeetCode题**：第199题 - Binary Tree Right Side View (https://leetcode.com/problems/binary-tree-right-side-view/)

**解题思路**：
二叉树的右视图，就是从右边看向二叉树时能看到的节点序列。实际上，就是求**每一层最右边的一个节点**。

**方法一：BFS（广度优先搜索 - 层序遍历）**
这是最直观的解法。我们利用队列进行二叉树的层序遍历。在遍历每一层时，我们记录下该层的最后一个元素，这个元素就是从右侧能看到的节点。
- **时间复杂度**：O(N)，其中N是树中的节点个数，每个节点恰好入队出队一次。
- **空间复杂度**：O(N)，最坏情况下队列中会存储最多一层的节点数（完美二叉树最后一层约为N/2）。

**方法二：DFS（深度优先搜索）**
我们按照“根结点 -> 右子树 -> 左子树”的顺序进行深度优先遍历。同时维护一个变量`depth`表示当前深度。如果当前深度`depth`等于结果列表`resultList`的大小，说明当前节点是这一层第一个被访问的节点（因为我们先遍历右子树），也就是右视图能看到的节点，将其加入结果列表。
- **时间复杂度**：O(N)，每个节点访问一次。
- **空间复杂度**：O(H)，其中H是树的高度，主要是递归栈的开销。最坏情况（链表）下为O(N)。

**最优解法**：两种方法都是O(N)。BFS通常更直观易懂。这里我使用BFS的写法。

**Java代码实现（带详细注释）**：

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
import java.util.*;

class Solution {
    public List<Integer> rightSideView(TreeNode root) {
        // 初始化结果列表
        List<Integer> result = new ArrayList<>();
        // 边界情况：如果树为空，直接返回空列表
        if (root == null) {
            return result;
        }

        // 使用队列来进行BFS层序遍历
        Queue<TreeNode> queue = new LinkedList<>();
        // 将根节点加入队列，开始遍历
        queue.offer(root);

        while (!queue.isEmpty()) {
            // 获取当前层的节点数量
            int levelSize = queue.size();
            // 遍历当前层的所有节点
            for (int i = 0; i < levelSize; i++) {
                // 从队列中取出当前节点
                TreeNode currentNode = queue.poll();
                // 如果是当前层的最后一个节点（即最右边的节点），将其值加入结果列表
                if (i == levelSize - 1) {
                    result.add(currentNode.val);
                }
                // 将当前节点的左子节点加入队列，为下一层遍历做准备
                if (currentNode.left != null) {
                    queue.offer(currentNode.left);
                }
                // 将当前节点的右子节点加入队列，为下一层遍历做准备
                if (currentNode.right != null) {
                    queue.offer(currentNode.right);
                }
            }
            // 当前层遍历结束，此时result中已经添加了该层最右边的节点
        }
        // 返回最终的结果列表
        return result;
    }
}
```

**边界情况处理**：
- 树为空：直接返回空列表。
- 只有根节点：返回只包含根节点值的列表。
- 树退化为链表：算法依然有效。

---

以上即为对所有面试题的全面解答，希望能对您有所帮助。
