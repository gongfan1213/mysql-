非常全面且具有深度的一次面试，涵盖了数据库、缓存、操作系统、网络、项目设计和算法。让我们逐一进行深度解析，帮你彻底吃透这些知识点。

---

### **1. MySQL的查询内部过程？**

MySQL的查询执行过程是一个复杂的 pipeline，大致分为以下步骤：

1.  **连接器（Connector）**：管理客户端连接，负责身份认证和权限校验。
2.  **查询缓存（Query Cache）**（**MySQL 8.0已移除**）：如果查询语句命中缓存，则直接返回结果。但由于缓存失效非常频繁，弊大于利，新版已删除。
3.  **分析器（Parser）**：进行**词法分析**和**语法分析**。判断SQL语句是否符合MySQL语法。
4.  **优化器（Optimizer）**：**核心阶段**。生成执行计划。优化器会决定：
    - 使用哪个索引（如果有多个索引可用）。
    - 多表关联（join）的顺序。
    - 是否可以将一些条件进行优化。
5.  **执行器（Executor）**：
    - 首先进行权限检查。
    - 然后调用**存储引擎接口**，按照优化器选择的执行计划逐步执行。
    - 执行器通过循环调用存储引擎的`next()`接口，获取满足条件的行，并组成结果集。
6.  **存储引擎（Storage Engine）**（如InnoDB）：负责数据的**存储和提取**。执行器调用引擎接口，引擎负责从磁盘或缓存中读取数据。

**简单流程**：`连接` -> `解析SQL` -> `优化查询计划` -> `执行计划（调用存储引擎）` -> `返回结果`

---

### **2. MySQL优化器怎么去进行优化的？**

优化器是基于成本的（Cost-Based Optimizer, CBO），它的目标是选择一个它认为**执行成本最低**的执行计划。

**优化策略主要包括：**

1.  **选择最优索引**：
    - 计算全表扫描的成本（需要读多少页）。
    - 计算使用每个可用索引的成本（需要回表多少次）。
    - 选择成本最低的方案。

2.  **多表关联优化**：
    - **决定驱动表**：优化器会估算不同表作为驱动表（外层循环的表）时的成本，选择成本最低的关联顺序。
    - **关联算法选择**：选择使用**Nested-Loop Join**（适用于索引良好的OLTP）、**Hash Join**（MySQL 8.0+，适用于大数据集且无索引）等。

3.  **条件简化与重写**：
    - 去除不必要的括号。
    - 将HAVING子句中的条件合并到WHERE子句中。
    - 常量表达式求值（如`WHERE id = 3*5`优化为`WHERE id = 15`）。

4.  **访问方式优化**：
    - `const`：通过主键或唯一索引定位一条记录。
    - `ref`：使用非唯一索引扫描。
    - `range`：索引范围扫描。
    - `index`：全索引扫描。
    - `ALL`：全表扫描。

可以使用`EXPLAIN`命令来查看优化器最终选择的执行计划。

---

### **3. Redis有哪些数据结构？ & 4. 数据结构底层是怎么实现的？**

这两个问题需要合并回答，才能体现深度。

| 数据结构 | 底层实现（编码方式） | 简要原理 |
| :--- | :--- | :--- |
| **String** | `int`, `embstr`, `raw` | `int`存储整数；`embstr`存储短字符串（<=39字节），内存连续；`raw`存储长字符串。 |
| **List** | `quicklist` (3.2+) | 一个由**ziplist**（压缩列表）作为节点的**双向链表**。平衡了内存效率和性能。 |
| **Hash** | `ziplist`, `hashtable` | 元素少时用`ziplist`（省内存），元素多或value大时转为`hashtable`（O(1)查询）。 |
| **Set** | `intset`, `hashtable` | 元素全是整数且少时用`intset`（有序数组），否则用`hashtable`（value为null的hash）。 |
| **ZSet** | `ziplist`, `skiplist+dict` | 元素少时用`ziplist`；元素多时用**跳跃表（skiplist）**（支持范围查询） + **哈希表（dict）**（支持O(1)单点查询）的混合结构。 |
| **Bitmap** | `String` | 本质上是对String类型的位操作。 |
| **HyperLogLog** | `String` | 使用特定的String来存储基数估算所需的数据。 |
| **Geospatial** | `ZSet` | 底层使用ZSet实现，value是地方名，score是经纬度编码后的一个数字。 |
| **Stream** | `rax`（基数树） | 用于实现消息队列，支持多播。 |

---

### **5. Hash的底层扩容是什么样的？**

Redis Hash底层使用字典（`dict`），其扩容机制非常经典，称为**渐进式Rehash**。

**为什么要扩容？** 当哈希表保存的键值对数量过多时，会导致哈希冲突加剧，链表过长，查询效率退化为O(n)。

**触发条件**：同时满足以下两个条件：
1.  服务器没有执行`BGSAVE`或`BGREWRITEAOF`命令。
2.  哈希表的**负载因子**（`used / size`） >= 1。

如果正在执行`BGSAVE`等持久化操作，Redis会尝试避免扩容以减少内存写操作，触发条件会变为负载因子 >= 5。

**扩容过程（渐进式Rehash）**：
1.  **准备**：为字典的`ht[1]`哈希表分配空间，大小为第一个大于等于`ht[0].used * 2`的 2^n。
2.  **设置变量**：设置一个**rehash索引** `rehashidx`，将其值设置为0，表示rehash工作正式开始。
3.  **逐步迁移**：在后续的每次**增、删、改、查**请求中，除了执行指定的操作外，还会顺带将`ht[0]`哈希表在`rehashidx`索引上的**所有键值对rehash到`ht[1]`**。完成后，将`rehashidx`值加一。
4.  **最终完成**：随着操作的不断执行，最终在某个时刻，`ht[0]`的所有键值对都会被rehash至`ht[1]`。此时将`rehashidx`设置为-1，表示rehash操作已完成。然后交换`ht[0]`和`ht[1]`的角色，`ht[1]`变为空表。

**优点**：将庞大的迁移工作分摊到每一次请求操作中，避免了集中式rehash导致的服务器**长时间阻塞**。

---

### **6. 操作系统怎么管理进程？**

操作系统通过一个叫做**进程控制块（PCB, Process Control Block）** 的数据结构来管理进程。在Linux中，PCB就是`task_struct`结构体。

**PCB中包含的信息**：
- **进程标识符（PID）**：唯一标识一个进程。
- **进程状态**：如就绪、运行、阻塞/等待。
- **程序计数器（PC）**：指向下一条要执行的指令地址。
- **CPU寄存器**：当进程被切换时，需要保存寄存器数据以便恢复。
- **内存管理信息**：如页表、段表的地址。
- **I/O状态信息**：分配给进程的I/O设备、打开的文件列表等。
- **CPU调度信息**：如进程优先级、调度队列指针等。

**操作系统对进程的管理，本质上就是对所有进程的PCB进行组织（如通过链表）和管理**，包括：
- **创建**：分配PCB，初始化资源。
- **调度**：根据算法从就绪队列中选择一个PCB对应的进程来运行。
- **切换**：保存当前进程的上下文到其PCB，恢复下一个进程的上下文。
- **通信**：通过PCB中的信息来实现进程间通信（IPC）。
- **终止**：回收PCB和其占用的所有资源。

---

### **7. Linux用的是什么进程调度算法？**

现代Linux系统针对不同类型的进程，使用了**多种调度策略的组合**，其核心是**完全公平调度器（CFS, Completely Fair Scheduler）**。

**CFS的核心思想**：不是分配固定的时间片，而是**分配CPU时间的比例**。
- 它使用一棵**红黑树**来跟踪所有可运行的进程。
- 树的键是进程的**虚拟运行时间（vruntime）**（实际运行时间经过优先级加权后的值）。
- CFS总是选择**vruntime最小**的进程来运行，即“最需要CPU”的进程。
- 通过这种方式，CFS试图在所有可运行进程之间完全公平地分配CPU时间。

**此外，Linux还有其他的调度类**，按优先级从高到低排列：
- **Stop_Sched_Class**：最高优先级，用于执行一些特殊的任务（如CPU热插拔）。
- **DL_Sched_Class**： Deadline调度，用于有严格截止时间的实时任务。
- **RT_Sched_Class**： 实时调度（FIFO, RR），用于普通实时任务。
- **CFS**：用于绝大多数普通分时进程。
- **Idle_Sched_Class**：空闲调度，在CPU无事可做时运行idle进程。

---

### **8. 操作系统怎么解决饥饿问题？**

**饥饿（Starvation）**：指某个进程因为优先级太低，长期得不到所需的资源（最主要是CPU时间）而无法执行。

**解决方案**：

1.  **老化（Aging）**：这是最常用且有效的技术。**逐渐增加等待时间很长的进程的优先级**。一个低优先级进程在就绪队列中等待的时间越长，系统就逐步提升它的优先级，最终它会被提升到足够高而获得执行机会。
2.  **公平调度算法**：如Linux的CFS，其核心就是保证**公平性**，防止任何一个进程被完全“饿死”。每个进程最终都能获得大致相等的CPU时间比例。
3.  **资源配额**：对资源的使用设置上限，防止高优先级进程垄断资源。

---

### **9. 锁有哪些？**

从不同的维度，锁可以分为很多类型：

**按乐观/悲观分**：
- **悲观锁**：假定会发生并发冲突，先加锁再操作。如`synchronized`，`ReentrantLock`。
- **乐观锁**：假定不会发生冲突，先操作，提交时再检查。如**CAS操作**、数据库的`version`字段。

**按锁的粒度分**：
- **表锁**：锁住整张表（MyISAM）。
- **行锁**：锁住某一行（InnoDB）。
- **页锁**：锁住一页（数据页）。
- **间隙锁（Gap Lock）**：锁住一个范围，但不包括记录本身。
- **临键锁（Next-Key Lock）**：行锁 + 间隙锁。

**按读写性质分**：
- **共享锁（S锁/读锁）**：允许其他事务读，但不能写。
- **排他锁（X锁/写锁）**：不允许其他事务读和写。

**按是否阻塞分**：
- **自旋锁**：获取不到锁时，线程会循环尝试（忙等待），避免上下文切换开销，适用于锁持有时间极短的场景。

**数据库中的锁**：记录锁、间隙锁、临键锁、意向共享锁、意向排他锁等。

---

### **10. 为什么四次挥手要比三次握手多一次？**

核心原因：**TCP连接是双全工的，每个方向必须单独进行关闭。**

- **三次握手**：
    - Client -> Server: SYN。 （Client说：“我想建立连接”）
    - Server -> Client: SYN-ACK。（Server说：“我同意，我也想建立连接”）
    - Client -> Server: ACK。 （Client说：“好的，建立成功”）
    - **后两次可以合并**，因为Server对Client连接的确认和自己发起连接的请求可以放在一个包里发送。

- **四次挥手**：
    - Client -> Server: FIN。（Client说：“我数据发完了，要关闭我到你方向的连接”）
    - Server -> Client: ACK。（Server说：“我知道你要关了”）
    - **此时，从Client到Server的连接已关闭，但Server到Client的连接可能还在传输数据**。这是一个**半关闭状态**。
    - ...（Server处理完剩余数据）...
    - Server -> Client: FIN。（Server说：“我数据也发完了，我也要关了”）
    - Client -> Server: ACK。（Client说：“好的，关闭成功”）

**为什么不能合并？** 因为Server收到第一个FIN后，可能还有数据要发送给Client，所以它的ACK和FIN**不能像握手时那样合并**在一个报文里发送，这就导致了四次挥手。

---

### **11. 网络上的负载均衡有哪些算法？**

| 算法 | 描述 | 优点 | 缺点 |
| :--- | :--- | :--- | :--- |
| **轮询（Round Robin）** | 将请求按顺序逐一分配到不同的服务器。 | 实现简单，绝对公平 | 无法考虑服务器性能差异 |
| **加权轮询（Weighted RR）** | 给性能好的服务器分配更高的权重，获得更多请求。 | 考虑了服务器性能 | 无法考虑实时负载 |
| **随机（Random）** | 随机选择一个服务器。 | 实现简单 | 无法保证均匀 |
| **最少连接（Least Connections）** | 将请求分配给当前连接数最少的服务器。 | 考虑了服务器的实时负载 | 实现稍复杂 |
| **源地址哈希（IP Hash）** | 根据客户端IP计算哈希值，固定分配到一个服务器。 | 可实现会话保持（Session Persistence） | 服务器宕机或扩容会破坏会话 |
| **一致性哈希** | 对IP Hash的改进，宕机或扩容时只影响部分请求。 | 具有良好的可扩展性 | 实现复杂 |
| **最短响应时间** | 将请求分配给平均响应时间最短的服务器。 | 最智能，体验最好 | 需要收集响应时间，开销大 |

---

### **项目场景题深度解析**

**场景：怎么根据视频播放量去向用户做推送？**

**1. 播放量怎么收集？**
- **客户端上报**：用户在App/Web端播放视频时，客户端在视频播放达到一定阈值（如播放完成、播放过半）时，向后端上报一条播放日志。
- **日志收集**：上报的日志通过**日志收集Agent**（如Filebeat）收集，然后发送到**消息队列**（如Kafka）进行缓冲和解耦。
- **实时处理**：使用**流处理框架**（如Flink、Spark Streaming）消费Kafka中的消息，进行实时聚合计算。计算每个视频在**近N小时/天**内的播放量。
- **结果存储**：将聚合后的结果（视频ID -> 播放量）写入一个**高速的存储系统**，如Redis（存储实时热榜）或Elasticsearch（便于复杂查询）。

**2. 10w播放量和100w播放量的视频有什么不同的实现方式吗？**
**有的，核心区别在于推送的【精准性】和【范围】。**

- **10w播放量（腰部视频）**：
    - **策略**：可以进行**个性化推荐**。
    - **实现**：将这部分视频作为推荐系统的候选集。利用用户的历史行为（点赞、收藏、观看时长等）构建用户画像，通过**协同过滤**或**深度学习模型**为用户匹配可能感兴趣的视频，实现“千人千面”的推送。

- **100w播放量（爆款头部视频）**：
    - **策略**：可以进行**全局热榜推送**。
    - **实现**：这类视频已经经过了市场的验证，大众接受度高。可以直接推送给**更广泛的用户群体**，甚至作为App的**开屏推送**或**PUSH通知**。推送时可能会加上“全网热播”、“大家都在看”等标签。

**3. MQ了解哪几种？为什么不用Kafka？rocketMQ有什么优势？**

| 特性 | Kafka | RocketMQ | RabbitMQ |
| :--- | :--- | :--- | :--- |
| **设计初衷** | 处理海量日志、大数据领域的数据管道 | 金融级的业务消息中间件 | 企业级消息代理 |
| **吞吐量** | **极高**（百万级） | **很高**（十万级） | 一般（万级） |
| **延迟** | 毫秒级（高吞吐牺牲了低延迟） | **亚毫秒级** | 微秒级 |
| **事务消息** | 支持 | **支持（更完善）** | 不支持 |
| **消息可靠性** | 高（副本机制） | **非常高**（多副本、刷盘策略） | 高 |
| **优势** | 吞吐量无敌，生态成熟 | 吞吐量高，延迟低，事务支持好，阿里系生态 | 协议支持多（AMQP），管理界面好 |

**为什么不用Kafka？**
- **延迟更高**：Kafka为高吞吐做了优化，其批量处理的机制导致延迟不如RocketMQ稳定和低。
- **功能特性**：在事务消息、消息重试、死信队列等业务场景常用的功能上，RocketMQ的原生支持更友好、更完善。
- **运维生态**：RocketMQ由阿里开源，中文文档和社区支持更好，与Java技术栈、Spring Cloud Alibaba等集成更丝滑。

**RocketMQ的优势**：
1.  **低延迟、高吞吐**：在保证高吞吐的同时，提供了更稳定的低延迟表现。
2.  **强大的事务消息**：原生支持分布式事务消息，解决业务中的最终一致性问题。
3.  **丰富的消息功能**：支持定时消息、顺序消息、消息过滤、消息重试、死信队列等。
4.  **优秀的架构设计**：NameServer+Broker的架构，无单点故障，扩展性强。

**4. 前后端如何交互？**
这是一个开放式问题，考察你对现代Web开发的理解。
- **API设计**：遵循**RESTful**风格，使用HTTP动词（GET/POST/PUT/DELETE）定义操作，返回JSON格式数据。
- **通信协议**：**HTTP/HTTPS**。
- **数据格式**：**JSON** 是主流，序列化/反序列化方便。
- **长连接**：对于实时性要求高的场景（如弹幕、点赞通知），会使用 **WebSocket** 协议。
- **安全**：使用**HTTPS**加密传输；使用**Token**（如JWT）进行身份认证和授权；对API进行限流和防刷。

---

### **算法：力扣22. 括号生成**

**解题思路：回溯法（DFS）**
- **核心**：生成所有可能的组合，但通过约束条件（剪枝）来避免无效序列。
- **约束条件（剪枝）**：
    1.  左括号数量不能超过`n`。
    2.  右括号数量不能超过左括号数量（否则会形成无效括号，如`)`）。
- **过程**：从空字符串开始，每次尝试添加一个`(`或`)`，如果满足上述约束就继续递归，当字符串长度达到`2*n`时，就是一个有效解。

**Java代码（ACM模式需自己处理输入输出）**：

```java
import java.util.ArrayList;
import java.util.List;
import java.util.Scanner;

public class Main {
    public static void main(String[] args) {
        Scanner scanner = new Scanner(System.in);
        int n = scanner.nextInt();
        List<String> result = generateParenthesis(n);
        for (String s : result) {
            System.out.println(s);
        }
    }

    public static List<String> generateParenthesis(int n) {
        List<String> result = new ArrayList<>();
        backtrack(result, new StringBuilder(), 0, 0, n);
        return result;
    }

    private static void backtrack(List<String> result, StringBuilder current, int open, int close, int max) {
        // 终止条件：当前字符串长度已达2n
        if (current.length() == max * 2) {
            result.add(current.toString());
            return;
        }

        // 选择1：添加左括号
        if (open < max) {
            current.append('(');
            backtrack(result, current, open + 1, close, max); // 递归
            current.deleteCharAt(current.length() - 1);      // 回溯，撤销选择
        }

        // 选择2：添加右括号（注意约束：右括号数必须小于左括号数）
        if (close < open) {
            current.append(')');
            backtrack(result, current, open, close + 1, max); // 递归
            current.deleteCharAt(current.length() - 1);       // 回溯，撤销选择
        }
    }
}
```

**复杂度分析**：
- **时间复杂度**：O(4^n / √n)，这是卡特兰数的渐近边界。
- **空间复杂度**：O(n)，递归栈的深度最大为2n。

**如何向面试官讲解**：
“这道题可以使用回溯算法来解决。我定义了两个计数器`open`和`close`来记录当前字符串中左右括号的数量。在回溯过程中，我遵循两个约束条件进行剪枝：一是左括号数不能超过n，二是右括号数不能超过左括号数。只要满足这两个条件，就可以继续添加括号。当路径字符串长度达到2n时，就说明找到了一个有效组合，将其加入结果列表。通过递归和回溯，可以系统地探索所有可能的有效括号组合。”

---

这次面试考察的知识点非常深入和全面，你能进入这个环节本身就证明了你的实力。把这些知识点系统性地整理和消化，你的技术体系会变得更加完整和牢固。祝你成功！
