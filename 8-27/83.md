好的，我们先抄一遍题目，再逐一进行详细解答。

---

**题目：小米-java后端开发工程师（技术面）面经**

1、HashMap 的底层原理是什么？它是如何处理哈希冲突的？为什么长度是2的幂次方？

2、谈谈你对Java并发包 JUC 的理解。synchronized 和 ReentrantLock 的区别？什么是可重入锁？说说volatile 关键字的作用？它能保证原子性吗？

3、简述Java的垃圾回收机制。有哪些常见的垃圾收集器？它们各自的优缺点和适用场景？如何判断一个对象可以被回收？

4、谈谈你对Java IO/NIO的理解。NIO中的 Selector, Channel, Buffer 是什么？NIO和传统BIO的区别？NIO是如何实现非阻塞的？

5、如何在2亿个整数中找出不重复的整数？

6、快速排序的平均和最坏时间复杂度是多少？为什么？

7、哈希表插入和查找的时间复杂度是多少？为什么？

8、MySQL的索引底层数据结构是什么？为什么使用B+树而不是B树或哈希表？什么是聚簇索引和非聚簇索引？什么是覆盖索引和最左前缀原则？

9、谈谈你对MySQL事务隔离级别的理解。什么是脏读、不可重复读、幻读？MySQL默认的隔离级别是什么？MVCC是如何实现的？

10、SQL优化有哪些常见手段？如何查看一条SQL的执行计划？其中哪些关键信息值得关注？遇到过数据库死锁吗？如何分析和解决？

11、是否了解分库分表？什么时候需要？有哪些常见的分片策略？

12、Spring框架的核心是什么？Spring Bean的生命周期是怎样的？Spring是如何解决循环依赖问题的？

13、Spring MVC的请求处理流程是怎样的？@Autowired 和 @Resource 注解的区别？

14、Spring Boot的自动配置原理是什么？

15、为什么要使用消息队列？如何保证消息不被重复消费？如何保证消息的可靠传输？

16、是否使用过Redis？常用数据类型及其应用场景？如何用Redis实现一个分布式锁？要注意什么问题？Redis的持久化机制？

17、是否了解分布式相关技术？分布式事务的解决方案；分布式ID生成方案

18、设计一个短链接系统。

19、设计一个秒杀系统。

20、如果你要为亿级智能设备设计一个状态上报和指令下发的系统，你会考虑哪些方面？

21、项目中遇到过最大的技术挑战是什么？你是怎么解决的？

---

### **详细解答**

---

### **1、HashMap 的底层原理是什么？它是如何处理哈希冲突的？为什么长度是2的幂次方？**

**底层原理：**
在 JDK 1.8 之后，HashMap 的底层数据结构是 **数组 + 链表 + 红黑树**。
- 当插入一个键值对时，首先会通过 `hash(key)` 计算键的哈希值，再通过 `(n - 1) & hash` 计算出该键值对在数组（桶数组）中的索引位置。
- 如果该位置为空，则直接放入一个Node节点。
- 如果该位置不为空（发生哈希冲突），则会遍历该位置的链表或红黑树：
    - 如果找到相同的key（通过 `equals` 判断），则更新其value。
    - 如果没找到，则将新节点插入到链表末尾（尾插法）。当链表长度达到阈值（默认为8）且当前数组长度大于等于64时，链表会转换为红黑树，以提高查找效率。
    - 如果数组长度小于64，即使链表长度超过8，也会先进行数组扩容，而不是立即树化。

**处理哈希冲突的方法：**
1.  **链地址法（拉链法）**：将发生冲突的键值对连接成一个链表。当链表过长时，转换为红黑树。
2.  **扩容**：当HashMap中的元素数量超过 `容量 * 负载因子`（默认0.75）时，会进行扩容（resize），即创建一个新的两倍大小的数组，并重新计算所有元素的位置（rehash），这样可以减少哈希冲突。

**为什么长度是2的幂次方？**
- 核心目的是为了**让哈希值更加均匀地分布在数组中，减少哈希碰撞**。
- 计算索引的公式是：`index = (table.length - 1) & hash`。
- 当数组长度 `n` 为2的幂次方时，`n-1` 的二进制表示就是一串连续的 `1`（例如，长度为16，`n-1=15`，二进制为 `1111`）。
- 这样，`(n-1) & hash` 操作实际上等价于 `hash % n`，但位运算 `&` 的效率远高于取模运算 `%`。
- 更重要的是，这个操作可以保留哈希值的所有低位特征，而高位不会影响索引位置（因为高位会被 `n-1` 的0掩码抹去）。为了进一步降低碰撞，HashMap的 `hash()` 方法会通过扰动函数将键的高16位与低16位进行异或运算，让高位也参与进来，使得哈希分布更加均匀。

---

### **2、谈谈你对Java并发包 JUC 的理解。synchronized 和 ReentrantLock 的区别？什么是可重入锁？说说volatile 关键字的作用？它能保证原子性吗？**

**JUC（java.util.concurrent）的理解：**
JUC 是Java提供的用于处理多线程和并发编程的强大工具包，主要包含以下部分：
- **原子类（Atomic**）：如 `AtomicInteger`，基于CAS实现线程安全的原子操作。
- **锁机制（Locks）**：提供了比 `synchronized` 更灵活的锁API，如 `ReentrantLock`、`ReadWriteLock`。
- **并发容器**：如 `ConcurrentHashMap`（线程安全的HashMap）、`CopyOnWriteArrayList`（写时复制的List）。
- **线程池（Executor Framework）**：提供了强大的线程池管理，如 `ThreadPoolExecutor`、`ScheduledThreadPoolExecutor`。
- **同步工具类**：如 `CountDownLatch`（倒计数器）、`CyclicBarrier`（循环栅栏）、`Semaphore`（信号量），用于线程间的协调。
- **并发队列**：如 `BlockingQueue`（阻塞队列），用于生产者-消费者模型。

**synchronized 和 ReentrantLock 的区别：**

| 特性 | synchronized | ReentrantLock |
| :--- | :--- | :--- |
| **实现层面** | JVM层面，是Java关键字 | JDK层面，是一个类 |
| **锁的释放** | 自动释放（代码块执行完毕或异常） | 必须手动调用 `unlock()`，通常放在 `finally` 中 |
| **灵活性** | 相对不灵活 | 非常灵活，支持尝试获取锁、超时获取、可中断获取 |
| **公平锁** | 非公平锁 | 两者都可（构造函数指定，默认非公平） |
| ** Condition ** | 只能通过 `wait()/notify()` 与一个等待队列交互 | 可以绑定多个 `Condition`，实现更精确的线程唤醒 |
| **性能** | 在JDK1.6后优化很大，两者性能接近 | 在高竞争环境下可能更有优势 |

**可重入锁：**
指同一个线程可以多次获取同一把锁。例如，一个同步方法可以调用另一个同步方法，而不会因为自己已经持有锁而被阻塞。`synchronized` 和 `ReentrantLock` 都是可重入锁。

**volatile 关键字的作用：**
1.  **保证可见性**：当一个线程修改了一个 `volatile` 变量的值，新值会立即被刷新到主内存中。其他线程在读取该变量时，会直接从主内存中读取新值，而不是使用自己工作内存中的旧值。
2.  **禁止指令重排序**：通过插入内存屏障（Memory Barrier），防止JVM和处理器为了优化性能而对指令进行重排序，从而保证了有序性。

**它能保证原子性吗？**
**不能**。`volatile` 只能保证对单个变量的读/写操作具有原子性（例如 `volatile int i = 10;` 的赋值是原子的），但不能保证复合操作的原子性（例如 `i++`，它实际上是 `read-modify-write` 三个操作）。要保证复合操作的原子性，需要使用 `synchronized` 或 `java.util.concurrent.atomic` 包下的原子类。

---

### **3、简述Java的垃圾回收机制。有哪些常见的垃圾收集器？它们各自的优缺点和适用场景？如何判断一个对象可以被回收？**

**垃圾回收机制（GC）：**
Java的GC自动管理堆内存，回收不再被使用的对象所占用的空间。其核心区域是堆（Heap），堆被分为新生代（Young Generation）和老年代（Old Generation）。新生代又分为Eden区和两个Survivor区（S0, S1）。
- **新生代GC（Minor GC）**：发生在新生代，非常频繁。新对象在Eden区创建，当Eden区满时，触发Minor GC。存活的对象会被移动到Survivor区，年龄加1。对象在Survivor区之间来回拷贝，当年龄达到阈值（默认15），会被晋升到老年代。
- **老年代GC（Major GC/Full GC）**：发生在老年代，通常伴随着至少一次Minor GC，速度较慢。当老年代空间不足时触发。

**判断对象可回收的方法：**
- **引用计数法**（Java未采用）：每个对象有一个引用计数器，被引用时加1，引用失效时减1。为0时可回收。无法解决循环引用问题。
- **可达性分析算法**（Java采用）：从一系列称为 **GC Roots** 的对象作为起点，向下搜索，搜索走过的路径称为引用链。如果一个对象到GC Roots没有任何引用链相连（即不可达），则证明此对象不可用，可以被回收。
    - **GC Roots** 包括：虚拟机栈中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法栈中JNI引用的对象等。

**常见的垃圾收集器：**

| 收集器 | 区域 | 算法 | 优点 | 缺点 | 适用场景 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Serial** | 新生代 | 复制 | 简单高效，单线程无交互开销 | 会STW（Stop-The-World） | 客户端模式，资源受限的嵌入式系统 |
| **ParNew** | 新生代 | 复制 | Serial的多线程版，可配合CMS | 在单核CPU上可能不如Serial | 服务端模式，与CMS搭配使用 |
| **Parallel Scavenge** | 新生代 | 复制 | 吞吐量优先，可控的吞吐量 | 会STW | 后台运算，不需要太多交互的任务 |
| **Serial Old** | 老年代 | 标记-整理 | Serial的老年代版 | 会STW | 客户端模式，CMS的后备预案 |
| **Parallel Old** | 老年代 | 标记-整理 | Parallel Scavenge的老年代版，吞吐量优先 | 会STW | 与Parallel Scavenge搭配，吞吐量优先场景 |
| **CMS** | 老年代 | 标记-清除 | 并发收集，低停顿 | 1. 对CPU敏感 2. 产生碎片 3. 无法处理浮动垃圾 | 互联网站、B/S系统，重视响应速度 |
| **G1** | 全堆 | 标记-整理+复制 | 并发并行，可预测停顿，区域化内存管理 | 内存占用和额外执行负载高 | 面向服务端，大内存、多处理器机器，替代CMS |
| **ZGC** | 全堆 | 染色指针 | 超低停顿（<10ms），可处理TB级堆 |  | 超大堆内存，极致低延迟场景 |

---

### **4、谈谈你对Java IO/NIO的理解。NIO中的 Selector, Channel, Buffer 是什么？NIO和传统BIO的区别？NIO是如何实现非阻塞的？**

**IO/NIO的理解：**
- **BIO (Blocking IO)**：同步阻塞IO。服务器为每个客户端连接创建一个线程进行处理。当连接数很大时，线程开销巨大，效率低下。
- **NIO (New IO / Non-blocking IO)**：同步非阻塞IO。基于**通道（Channel）** 和**缓冲区（Buffer）**，使用**多路复用器（Selector）** 来管理多个通道。服务器用一个或少量线程处理所有连接，只有在连接真正有读写事件时才进行IO操作，大大提高了性能。

**NIO三要素：**
1.  **Buffer（缓冲区）**：一个用于存储数据的容器。所有数据的读写都是通过Buffer进行的。它是块IO的基础。
2.  **Channel（通道）**：类似于BIO中的流，但可以同时进行读写，是双向的。数据总是从Channel读到Buffer，或者从Buffer写到Channel。
3.  **Selector（选择器）**：是NIO的核心。一个Selector可以注册多个Channel，并监听这些Channel上的事件（如连接就绪、读就绪、写就绪）。通过调用Selector的 `select()` 方法，它会阻塞直到有注册的事件发生，然后返回这些事件，程序再针对这些事件进行相应的处理。

**NIO和BIO的区别：**

|  | BIO | NIO |
| :--- | :--- | :--- |
| **通信方式** | 面向流（Stream Oriented） | 面向缓冲区（Buffer Oriented） |
| **处理方式** | 阻塞IO（Blocking IO） | 非阻塞IO（Non-blocking IO） |
| **线程模型** | 一个连接一个线程（1:1） | 一个线程处理多个连接（M:1，通过Selector） |

**NIO如何实现非阻塞：**
关键在于 `Channel.configureBlocking(false)` 和 `Selector`。
- 将Channel设置为非阻塞模式后，调用 `read()` 或 `write()` 等方法会立即返回，而不会阻塞线程。
- 程序将多个Channel注册到Selector上，并监听感兴趣的事件。
- 主线程通过调用 `Selector.select()` 方法阻塞等待，当有Channel的事件准备就绪时（如有数据可读），`select()` 方法返回，程序获得一个SelectionKey集合。
- 程序遍历这个集合，对每个就绪的事件进行处理（如读取数据）。
- 这样，一个线程就可以高效地管理多个网络连接，而不是像BIO那样傻等。

---

### **5、如何在2亿个整数中找出不重复的整数？**

这是一个典型的海量数据问题，内存可能无法一次性加载所有数据。常用方法是 **分治法** 和 **位图法（Bitmap）** 的变种。

**方法一：双位图法（2-Bitmap）**
- 通常的Bitmap用一个bit位表示一个数是否存在（0不存在，1存在），但这只能判断存在性，无法判断重复性。
- 我们可以用 **两个bit位** 来表示一个数的状态：
    - `00`：该数字从未出现过。
    - `01`：该数字出现了一次。
    - `10`：该数字出现了两次及以上。
    - `11`：无意义。
- 遍历所有整数，根据规则更新这两个bit位的状态。
- 最后，所有状态为 `01` 的bit位对应的数字就是不重复的整数。
- **内存计算**：2亿个整数，假设是32位int，范围是0~2^32-1。我们需要为每个数分配2个bit。所需内存为：2^32 * 2 bit = 2^33 bit = 2^30 Byte = 1 GB。这在现代服务器上是可行的。

**方法二：Hash分桶 + 小顶堆**
1.  **哈希分桶**：将2亿个整数通过哈希函数分配到多个小文件中（例如100个文件）。确保相同的整数一定被分到同一个文件。
2.  **逐个处理**：对每个小文件，在内存中用HashMap统计每个整数出现的次数。
3.  **找出不重复数**：遍历每个小文件的HashMap，将出现次数为1的整数收集起来（或者写入结果文件）。
4.  （可选）如果要求Top K的不重复数，可以在每个文件统计后，使用小顶堆来维护全局出现次数最少的K个数。

**方法一（双位图）效率更高，是更优的解决方案。**

---

### **6、快速排序的平均和最坏时间复杂度是多少？为什么？**

- **平均时间复杂度**：O(n log n)
- **最坏时间复杂度**：O(n²)

**原因：**
快速排序的性能取决于选取的**基准（pivot）** 元素。
- **平均情况**：如果每次划分都能将数组大致分为两个长度相近的子数组，那么递归树的深度就是 log n，每一层需要进行 n 次比较操作，所以总时间复杂度为 O(n log n)。
- **最坏情况**：当数组已经有序（正序或逆序）且每次选择的基准都是最大或最小元素时，每次划分只能得到一个子数组（长度为n-1）和另一个空子数组。这样递归树就退化成一条链，深度为 n，需要进行 n 层划分，每层划分需要 O(n) 时间，所以总时间复杂度为 O(n²)。

**优化**：为了避免最坏情况，通常采用随机选取基准、三数取中法等策略来选择pivot。

---

### **7、哈希表插入和查找的时间复杂度是多少？为什么？**

在理想情况下，哈希表的插入和查找的**平均时间复杂度是 O(1)**。

**原因：**
- 通过哈希函数，可以在常数时间内计算出键对应的数组索引位置，然后直接在该位置进行插入或查找。
- 但是，如果发生哈希冲突，则需要遍历链表或红黑树。
    - 如果冲突严重，链表很长，时间复杂度会退化为 O(n)。
    - 在JDK 1.8之后，当链表过长（>8）时会转换为红黑树，此时在最坏情况下的时间复杂度为 O(log n)。

所以，哈希表操作的性能严重依赖于哈希函数的质量和负载因子的设置。一个好的哈希函数和合适的扩容策略可以保证大多数操作都在 O(1) 时间内完成。

---

### **8、MySQL的索引底层数据结构是什么？为什么使用B+树而不是B树或哈希表？什么是聚簇索引和非聚簇索引？什么是覆盖索引和最左前缀原则？**

**索引底层数据结构：**
InnoDB存储引擎的索引底层数据结构是 **B+树**。

**为什么是B+树而不是B树或哈希表？**
- **vs 哈希表**：
    - 哈希表适合等值查询（=），O(1)复杂度，但不支持范围查询（BETWEEN, >, <, ...）和排序（ORDER BY）。而B+树的所有叶子节点形成一个有序链表，非常适合范围查询和排序。
    - 哈希表无法利用索引完成部分索引键的查询（最左前缀原则）。
    - 哈希冲突也会影响性能。
- **vs B树**：
    - **B+树的非叶子节点只存储键，不存储数据**。这使得一个节点可以存放更多的键，树的层级更低，IO次数更少。
    - **B+树的所有数据都存储在叶子节点**，并且叶子节点之间通过指针相连，形成了一个双向链表。这使得范围查询非常高效，只需要遍历叶子节点的链表即可。而B树的数据分散在各个节点，范围查询需要进行复杂的中序遍历。

**聚簇索引（Clustered Index）和非聚簇索引（Secondary Index）：**
- **聚簇索引**：并不是一种单独的索引类型，而是一种**数据存储方式**。InnoDB的聚簇索引就是按照每张表的主键构造一棵B+树，**叶子节点中存放的就是完整的行数据**。一张表只能有一个聚簇索引。
    - 优点：数据访问快，因为索引和数据保存在同一棵B+树中。
    - 缺点：插入速度严重依赖于插入顺序。更新主键的代价高。
- **非聚簇索引（辅助索引）**：叶子节点**不包含行的全部数据**，而是存储了对应行的**主键值**。当通过辅助索引查找数据时，InnoDB会先找到主键值，然后再到聚簇索引中查找完整的行数据（这个过程称为**回表**）。

**覆盖索引（Covering Index）：**
如果一个索引包含（或者说覆盖）了所有需要查询的字段的值，我们就称之为“覆盖索引”。查询只需要扫描索引本身而无需回表，这大大提高了性能。
例如，表 `user` 有索引 `(name, age)`，查询 `SELECT age FROM user WHERE name = '张三'`，所需数据都在索引中，无需回表。

**最左前缀原则（Leftmost Prefix Principle）：**
指联合索引（Composite Index）中的最左列开始，或字符串前缀匹配。MySQL的索引可以匹配联合索引的左边连续列。
例如，联合索引 `(col1, col2, col3)`，以下查询都能用到索引：
- `WHERE col1 = val`
- `WHERE col1 = val AND col2 = val2`
- `WHERE col1 = val AND col2 = val2 AND col3 = val3`
- `WHERE col1 = val ORDER BY col2` (部分)
而 `WHERE col2 = val2` 或 `WHERE col3 = val3` 则无法使用这个索引。

---

### **9、谈谈你对MySQL事务隔离级别的理解。什么是脏读、不可重复读、幻读？MySQL默认的隔离级别是什么？MVCC是如何实现的？**

**事务隔离级别：**
SQL标准定义了4个隔离级别，用于解决并发事务可能带来的数据不一致问题。

| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
| :--- | :--- | :--- | :--- |
| **读未提交（Read Uncommitted）** | ✅可能 | ✅可能 | ✅可能 |
| **读已提交（Read Committed）** | ❌不可能 | ✅可能 | ✅可能 |
| **可重复读（Repeatable Read）** | ❌不可能 | ❌不可能 | ✅可能 |
| **串行化（Serializable）** | ❌不可能 | ❌不可能 | ❌不可能 |

- **脏读（Dirty Read）**：一个事务读到了另一个**未提交事务**修改的数据。如果那个事务回滚，读到的数据就是无效的。
- **不可重复读（Non-repeatable Read）**：在同一个事务中，多次读取同一数据，得到的结果不同。这是因为在两次读取之间，数据被另一个**已提交事务**修改了。
- **幻读（Phantom Read）**：在同一个事务中，多次执行相同的查询，返回的**记录集合**不同（有新的行被插入或已有的行被删除）。这是因为在两次查询之间，另一个**已提交事务**插入或删除了数据。

**MySQL默认的隔离级别：**
InnoDB存储引擎的默认隔离级别是 **可重复读（Repeatable Read）**。并且InnoDB通过 **Next-Key Lock** 算法在一定程度上解决了幻读问题。

**MVCC（多版本并发控制）的实现：**
MVCC是InnoDB实现**读已提交**和**可重复读**隔离级别的重要手段。它通过保存数据在某个时间点的快照来实现。
- **核心组件**：
    1.  **隐藏字段**：每行记录都有两个（或三个）隐藏字段。
        - `DB_TRX_ID`：最近一次修改本行数据的事务ID。
        - `DB_ROLL_PTR`：回滚指针，指向该行的上一个版本（在undo log中）。
        - `DB_ROW_ID`（可选）：行ID。
    2.  **Undo Log（回滚日志）**：存储数据被修改前的多个历史版本，这些版本通过回滚指针连接成一个链表。
    3.  **ReadView（一致性视图）**：事务在执行快照读时产生的读视图。它定义了当前事务能看到哪个版本的数据。
        - 对于 `Read Committed`，每次执行快照读时都会生成一个新的ReadView。
        - 对于 `Repeatable Read`，只在第一次执行快照读时生成一个ReadView，后续都复用这个ReadView。
- **工作流程（可见性判断）**：
    - 当执行一个SELECT查询时，会遍历数据行的版本链。
    - 利用ReadView中的信息（活跃事务ID列表、最小事务ID、下一个分配的事务ID）来判断每个版本的数据对当前事务是否可见。
    - 如果数据版本的 `DB_TRX_ID` 小于ReadView中的最小活跃事务ID，说明该版本在当前事务开始前已提交，是可见的。
    - 如果数据版本的 `DB_TRX_ID` 大于等于下一个分配的事务ID，说明该版本在当前事务开始后才生成，不可见。
    - 如果 `DB_TRX_ID` 在活跃事务ID列表中，说明创建该版本的事务还未提交，不可见；否则，可见。

---

### **10、SQL优化有哪些常见手段？如何查看一条SQL的执行计划？其中哪些关键信息值得关注？遇到过数据库死锁吗？如何分析和解决？**

**SQL优化常见手段：**
1.  **索引优化**：
    - 为WHERE、JOIN、ORDER BY、GROUP BY的列创建合适的索引。
    - 避免索引失效（如对索引列进行计算、函数、类型转换、`!=`、`IS NULL`、`OR`等）。
    - 使用覆盖索引。
2.  **SQL语句优化**：
    - 避免使用 `SELECT *`，只取需要的列。
    - 分解大连接查询：将一个大连接（JOIN）分解成多个单表查询，然后在应用层进行关联。
    - 优化子查询：尽量使用JOIN代替子查询。
    - 批量操作：使用批量插入（`INSERT INTO ... VALUES (), (), ...`）。
3.  **数据库设计优化**：
    - 选择合适的数据类型（越小越好）。
    - 适度进行范式/反范式设计。
    - 分库分表。

**查看执行计划：**
使用 `EXPLAIN` 关键字，例如 `EXPLAIN SELECT * FROM table WHERE ...`。

**执行计划中关键信息：**
- **type**：访问类型，从好到坏：`system > const > eq_ref > ref > range > index > ALL`。至少要达到 `range` 级别，最好达到 `ref`。
- **key**：实际使用的索引。如果为NULL，则没有使用索引。
- **rows**：MySQL认为它执行查询时必须检查的行数。越小越好。
- **Extra**：包含不适合在其他列显示的额外信息。
    - `Using filesort`：MySQL无法利用索引完成的排序，需要额外的排序操作，性能差。
    - `Using temporary`：使用了临时表保存中间结果，常见于排序和分组查询，性能很差。
    - `Using index`：使用了覆盖索引，性能好。

**数据库死锁：**
**遇到过**。死锁是指两个或多个事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。

**分析和解决：**
1.  **预防**：
    - 以固定的顺序访问表和行。
    - 减小事务的大小和长度，尽快提交事务。
    - 使用较低的隔离级别（如Read Committed）。
2.  **诊断**：
    - 启用 `innodb_print_all_deadlocks` 配置，所有死锁日志会打印到错误日志中。
    - 使用 `SHOW ENGINE INNODB STATUS` 命令查看最近的死锁信息。
3.  **解决**：
    - InnoDB会自动检测死锁，并**强制回滚其中一个代价最小的事务**（undo量最小的事务），让另一个事务得以继续执行。
    - 应用收到死锁错误后，需要进行重试。

---

### **11、是否了解分库分表？什么时候需要？有哪些常见的分片策略？**

**分库分表**：为了解决数据库的单点性能瓶颈和数据量过大的问题，将数据分散存储在多个数据库或表中。

**什么时候需要？**
- **数据量巨大**：单表数据量达到千万甚至亿级别，SQL查询性能下降，索引膨胀。
- **并发量过高**：数据库连接的吞吐量达到瓶颈，CPU、IO负载很高。

**常见分片策略（Sharding Strategy）：**
1.  **水平分片（Sharding）**：按行拆分，将同一个表中的不同行分散到不同的库/表中。
    - **范围分片**：按某个字段的范围（如时间、ID区间）分片。优点：易于扩展。缺点：可能导致数据分布不均（热点数据）。
    - **哈希分片**：按某个字段的哈希值取模分片。优点：数据分布均匀。缺点：扩展性差（重新分片麻烦）。
    - **一致性哈希**：解决哈希分片重新分片时数据迁移量过大的问题。
2.  **垂直分片**：按列拆分，将一个宽表拆分成多个小表（例如，将不常用的字段拆到另一张表）。或者将一个库中的不同表拆分到不同的数据库中。

**常见的中间件**：ShardingSphere、MyCat等。

---

### **12、Spring框架的核心是什么？Spring Bean的生命周期是怎样的？Spring是如何解决循环依赖问题的？**

**Spring框架的核心：**
- **IoC（控制反转）**：将对象的创建、依赖关系的组装的控制权从程序代码中反转到Spring容器中。开发者不再需要自己 `new` 对象，而是由容器来负责对象的生命周期和依赖注入（DI）。
- **AOP（面向切面编程）**：将那些与业务无关，但却被多个业务模块所共同调用的逻辑（如事务管理、日志、权限控制）封装起来，减少系统的重复代码，降低模块间的耦合度。

**Spring Bean的生命周期：**
1.  **实例化**：通过反射调用构造方法创建Bean的实例。
2.  **属性填充（Populate）**：为Bean的属性注入值（依赖注入）。
3.  **Aware接口回调**：如果Bean实现了 `BeanNameAware`、`BeanFactoryAware` 等接口，会调用相应的方法。
4.  **BeanPostProcessor前置处理**：调用 `BeanPostProcessor.postProcessBeforeInitialization()` 方法。
5.  **初始化**：
    - 如果Bean实现了 `InitializingBean` 接口，调用 `afterPropertiesSet()` 方法。
    - 调用自定义的 `init-method` 方法。
6.  **BeanPostProcessor后置处理**：调用 `BeanPostProcessor.postProcessAfterInitialization()` 方法（AOP代理对象就是在这里生成的）。
7.  **Bean可用**：此时Bean已经准备就绪，存放在容器中，可以被使用。
8.  **销毁**：
    - 如果Bean实现了 `DisposableBean` 接口，调用 `destroy()` 方法。
    - 调用自定义的 `destroy-method` 方法。

**Spring如何解决循环依赖？**
Spring通过**三级缓存**来解决**单例Bean**的**Setter注入**方式的循环依赖。
- **一级缓存（singletonObjects）**：存放已经完全初始化好的Bean。
- **二级缓存（earlySingletonObjects）**：存放提前暴露的早期Bean（已完成实例化，但未完成属性填充和初始化）。
- **三级缓存（singletonFactories）**：存放Bean的工厂对象，用于生成早期Bean。

**解决过程（以A依赖B，B依赖A为例）：**
1.  创建A，实例化A，将A的工厂对象放入三级缓存。
2.  为A填充属性，发现依赖B，于是去创建B。
3.  创建B，实例化B，将B的工厂对象放入三级缓存。
4.  为B填充属性，发现依赖A，于是尝试从缓存中获取A。
    - 从一级缓存未找到。
    - 从二级缓存未找到。
    - 从三级缓存中找到A的工厂对象，通过工厂对象获取**早期A对象**，并将这个早期A对象放入二级缓存，同时从三级缓存移除A的工厂。
5.  B成功获取到A的早期引用，完成属性填充和初始化，成为一个完整的Bean，被放入一级缓存。
6.  此时A继续它的属性填充步骤，成功注入已经创建好的B，然后完成A的初始化。最后将完整的A从二级缓存移除，并放入一级缓存。

**注意**：**构造器注入**的循环依赖无法解决，因为Java语言本身在调用构造器时就必须完成实例化，无法提前暴露一个早期引用。

---

### **13、Spring MVC的请求处理流程是怎样的？@Autowired 和 @Resource 注解的区别？**

**Spring MVC请求处理流程：**
1.  **DispatcherServlet**：前端控制器，接收所有请求。
2.  **HandlerMapping**：DispatcherServlet查询一个或多个HandlerMapping，找到处理该请求的Controller（Handler）。
3.  **HandlerAdapter**：DispatcherServlet通过HandlerAdapter来实际调用Controller中的方法。
4.  **Controller**：执行业务逻辑，返回一个ModelAndView（或String等视图名）。
5.  **ViewResolver**：视图解析器根据视图名解析出具体的View对象。
6.  **View**：View对象负责渲染视图，将模型数据填充到视图中，生成最终的响应（如HTML）。
7.  **Response**：DispatcherServlet将响应返回给客户端。

**@Autowired 和 @Resource 的区别：**

| 特性 | @Autowired (Spring) | @Resource (JSR-250) |
| :--- | :--- | :--- |
| **来源** | Spring框架定义 | Java标准（JSR-250） |
| **默认注入方式** | **byType** | **byName** |
| **找不到Bean处理** | 可通过 `required=false` 设置非必须 | 找不到会抛出异常 |
| **指定名称** | 需配合 `@Qualifier` | 直接用 `name` 属性 |
| **适用场景** | 通常按类型注入 | 想按名称注入时更方便 |

---

### **14、Spring Boot的自动配置原理是什么？**

Spring Boot的自动配置基于 **`@EnableAutoConfiguration`** 注解。
1.  **启动注解**：`@SpringBootApplication` 包含了 `@EnableAutoConfiguration`。
2.  **加载配置**：`@EnableAutoConfiguration` 会导入 `AutoConfigurationImportSelector`。
3.  **选择配置类**：`AutoConfigurationImportSelector` 会读取 `META-INF/spring.factories` 文件中的所有自动配置类（`org.springframework.boot.autoconfigure.EnableAutoConfiguration` 键下的内容）。
4.  **条件化配置**：这些自动配置类上通常有 `@ConditionalOnClass`、`@ConditionalOnMissingBean`、`@ConditionalOnProperty` 等条件注解。Spring Boot会根据当前项目的类路径、已有的Bean、配置属性等条件来决定是否启用该配置。
5.  **创建Bean**：如果条件满足，配置类中定义的Bean就会被创建并加入到Spring容器中。

**核心思想：** “约定大于配置”。Spring Boot预先为我们配置好了大部分常用组件的默认行为，只有在我们需要改变这些默认行为时，才需要自己显式地定义Bean或修改配置。

---

### **15、为什么要使用消息队列？如何保证消息不被重复消费？如何保证消息的可靠传输？**

**为什么使用消息队列（MQ）？**
- **解耦**：将消息的发送者和接收者解耦，双方不需要同时在线，也不需要知道对方的存在。
- **异步**：发送者发送消息后无需等待处理结果，可以继续执行，提高了系统的吞吐量。
- **削峰填谷**：应对突发流量，消息队列可以作为一个缓冲区，平滑处理高峰期的请求，保护下游系统。

**如何保证消息不被重复消费（幂等性）？**
消息队列通常提供 **at-least-once** 的投递语义，可能导致重复消费。解决方案是在**消费者端实现幂等性**。
- **数据库写入**：利用主键/唯一键约束，重复消费会导致插入失败。
- **Redis**：为每条消息生成一个全局唯一ID，消费前先检查 `setnx(key, value)`，如果已存在则表示已消费过。
- **乐观锁**：更新数据时带上版本号或状态条件（`update table set status = 'done' where id = 1 and status = 'init'`）。

**如何保证消息的可靠传输（不丢失）？**
需要从生产者、MQ本身、消费者三个环节来保证。
1.  **生产者弄丢数据**：
    - 开启MQ的**事务功能**（性能差）。
    - 使用**确认（confirm）机制**（异步，性能好）。生产者发送消息后，MQ会返回一个ack确认信号，表示已持久化。
2.  **MQ弄丢数据**：
    - 开启MQ的**持久化**。将消息和队列都持久化到磁盘。这样即使MQ重启，消息也不会丢失。
3.  **消费者弄丢数据**：
    - 关闭**自动提交offset**。消费者真正处理完业务逻辑后，再手动提交offset（acknowledge）。这样即使消费者宕机，MQ也会将未ack的消息重新投递给其他消费者。

---

### **16、是否使用过Redis？常用数据类型及其应用场景？如何用Redis实现一个分布式锁？要注意什么问题？Redis的持久化机制？**

**常用数据类型及应用场景：**
1.  **String**：最简单的键值对。用于缓存、计数器（`INCR`）、分布式锁（`SETNX`）。
2.  **Hash**： field-value 映射表。适合存储对象（如用户信息）。
3.  **List**：双向链表。可用于消息队列（LPUSH/RPOP）、最新列表（LTRIM）。
4.  **Set**：无序集合，自动去重。可用于共同关注（SINTER）、抽奖（SRANDMEMBER）。
5.  **ZSet (Sorted Set)**：有序集合，带分值。可用于排行榜（ZREVRANGE）、延迟队列（用时间戳做score）。
6.  **Bitmap / HyperLogLog / GEO**：位图（统计活跃用户）、HyperLogLog（基数统计）、GEO（地理位置）。

**用Redis实现分布式锁：**
使用 `SET` 命令的 `NX` 和 `PX` 选项：
```shell
SET lock_key unique_value NX PX 30000
```
- `NX`：表示只有当 `lock_key` 不存在时才能设置成功。
- `PX 30000`：设置锁的过期时间为30000毫秒。
- `unique_value`：必须是每个客户端唯一的随机值（如UUID），用于在释放锁时验证身份，避免误删其他客户端的锁。

**释放锁的Lua脚本（保证原子性）：**
```lua
if redis.call("get", KEYS[1]) == ARGV[1] then
    return redis.call("del", KEYS[1])
else
    return 0
end
```
**要注意的问题**：
1.  **锁过期时间**：设置一个合理的过期时间，防止业务执行过长导致锁自动释放。可以使用**看门狗（watch dog）** 机制自动续期。
2.  **集群环境**：在Redis主从架构中，主节点宕机可能导致锁丢失。可以考虑使用RedLock算法（争议较大）。

**Redis的持久化机制：**
1.  **RDB（快照）**：在指定的时间间隔内，将内存中的数据集快照写入磁盘。恢复速度快。但可能会丢失最后一次快照之后的数据。
2.  **AOF（追加文件）**：记录每次写操作命令。数据完整性高。文件通常比RDB大，恢复速度慢。
3.  **混合持久化（4.0+）**：结合两者。AOF文件的前半部分是RDB格式的全量数据，后半部分是增量AOF日志。兼顾了速度和数据安全性。

---

### **17、是否了解分布式相关技术？分布式事务的解决方案；分布式ID生成方案**

**分布式事务解决方案：**
1.  **2PC（两阶段提交）**： coordinator（协调者）和 participant（参与者）。分准备和提交两个阶段。优点是强一致性，缺点是同步阻塞、性能差、协调者单点问题。
2.  **3PC（三阶段提交）**：在2PC基础上增加了超时机制和预提交阶段，缓解了阻塞问题，但依然复杂。
3.  **TCC（Try-Confirm-Cancel）**：业务层面的2PC。
    - **Try**：预留业务资源。
    - **Confirm**：确认执行业务操作。
    - **Cancel**：取消Try阶段预留的资源。
    需要业务自己实现补偿逻辑，对代码侵入性强。
4.  **本地消息表**：将分布式事务拆分成多个本地事务。生产者将消息和业务数据放在同一个数据库事务中，然后由一个后台任务轮询消息表，将消息发送给MQ。消费者消费消息并处理。
5.  **最大努力通知**：适用于最终一致性要求不高的场景。生产者不断重试，直到消费者返回成功。
6.  **Seata**：开源的分布式事务解决方案，提供了AT、TCC、Saga等多种模式。

**分布式ID生成方案：**
1.  **UUID**：简单，本地生成，无网络开销。但无序，作为数据库主键性能差，长度长。
2.  **数据库自增ID**：利用数据库的自增主键，通过设置不同步长来生成。简单，但扩展性差，数据库压力大。
3.  **Redis INCR**：利用Redis的原子操作 `INCR`。性能好，但需要维护Redis。
4.  **雪花算法（Snowflake）**：Twitter开源的算法。生成一个64位的ID：
    - 1位符号位（0）
    - 41位时间戳（毫秒级，可用69年）
    - 10位机器ID（数据中心+机器ID，支持1024个节点）
    - 12位序列号（每毫秒可生成4096个ID）
    本地生成，性能极高，趋势递增。需要解决时钟回拨问题。
5.  **Leaf**：美团开源的分布式ID生成系统，集成了号段模式和雪花算法。

---

### **18、设计一个短链接系统。**

**核心功能**：将长URL转换为短URL，用户访问短URL时重定向到原始长URL。
**核心问题**：如何生成短码（如 `https://s.com/abc123` 中的 `abc123`）？

1.  **发号器设计**：
    - 使用分布式ID生成方案（如雪花算法、数据库自增、Redis INCR）生成一个全局唯一的10进制数字ID。
    - 将这个10进制数字ID转换为62进制（a-z, A-Z, 0-9）字符串，作为短码。例如，`123456` -> `"w7e"`。
2.  **存储**：
    - 数据库表：`(id, short_code, original_url, created_at, expires_at)`。
    - 使用Redis做缓存：`key=short_code, value=original_url`，并设置过期时间。
3.  **重定向**：
    - 用户访问 `https://s.com/abc123`。
    - 服务器根据短码 `abc123` 查询缓存或数据库，找到对应的原始长URL。
    - 返回HTTP 302重定向响应，Location头为原始URL。
4.  **其他考虑**：
    - **自定义短码**：允许用户输入自定义短码，需要检查唯一性。
    - **有效期**：设置短链接的有效期。
    - **统计**：记录访问次数、时间等 analytics 数据。
    - **防攻击**：防止有人用程序生成大量无效链接。

---

### **19、设计一个秒杀系统。**

秒杀系统的核心挑战是**瞬时高并发**和**防止超卖**。
1.  **架构原则**：**分层过滤、削峰限流**。将大量请求拦截在系统上游，保护下游脆弱的数据库。
    - **前端**：静态化页面，使用CDN。按钮置灰，防止重复提交。
    - **网关层**：限流（Rate Limiting），如令牌桶、漏桶算法。拦截掉大部分无效请求和机器人请求。
2.  **核心业务逻辑**：
    - **库存校验**：秒杀开始前，将商品库存加载到**Redis**中（`DECR` 命令是原子的）。
    - **请求入队**：通过网关的请求，先校验用户资格和库存（Redis预减库存），然后立即返回“排队中”的结果。将有效的秒杀请求发送到**消息队列**（如RabbitMQ、Kafka）中进行异步削峰。
    - **异步处理**：Worker从消息队列中消费请求，完成下单、支付等后续流程（操作数据库）。这里需要保证**幂等性**。
3.  **防超卖**：
    - **数据库层面**：在扣减库存的SQL语句中加上 `where stock > 0` 条件，利用数据库的排他锁。
    - **Redis层面**：使用 `DECR` 原子操作，扣减后结果小于0则表示已卖完。
4.  **其他**：
    - **反作弊**：识别和防止刷单、机器人。
    - **资源隔离**：将秒杀系统与主站隔离开，避免秒杀流量拖垮整个网站。

---

### **20、如果你要为亿级智能设备设计一个状态上报和指令下发的系统，你会考虑哪些方面？**

这是一个典型的物联网（IoT）平台设计问题。
1.  **通信协议**：
    - **设备上行（状态上报）**：选择轻量级的协议，如 **MQTT**（专为物联网设计，基于发布/订阅模式，开销小）或 **CoAP**。
    - **服务下行（指令下发）**：MQTT（通过topic）、HTTP长轮询、WebSocket。
2.  **海量连接与高并发**：
    - **连接层**：使用 **Netty** 等NIO框架构建高并发的接入服务器（Broker），单机支撑数十万连接。
    - **集群化**：接入层需要是无状态的，可以水平扩展。需要通过负载均衡（如LVS）将设备连接分散到不同的Broker上。
3.  **消息路由与处理**：
    - **消息队列**：接入层收到消息后，迅速将其投递到Kafka等消息队列中，实现异步化处理，削峰填谷。
    - **后端微服务**：从消息队列中消费数据，进行业务处理（如数据存储、分析、规则引擎判断）。
4.  **状态管理与指令下发**：
    - **设备状态**：使用Redis等缓存记录设备的在线状态（心跳机制）和最后上线时间。
    - **指令下发**：指令先存入DB，再根据设备状态（在线/离线）决定是立即推送（通过它连接的Broker）还是等设备上线后拉取。
5.  **数据存储**：
    - **时序数据**：设备上报的状态数据通常是时间序列数据，适合存入专门的**时序数据库（TSDB）**，如 InfluxDB、TDengine，便于后续做时间范围的聚合查询。
    - **关系型数据**：设备元信息、指令记录等存入MySQL/PostgreSQL。
6.  **安全与可靠性**：
    - **安全**：TLS/SSL加密传输，设备认证（如每个设备唯一的Token或证书）。
    - **可靠性**：消息QoS保证（如MQTT的QoS1、QoS2），确保指令和状态不丢失。
7.  **监控与运维**：
    - 全方位的监控（设备连接数、消息吞吐量、服务健康状况）。
    - 灰度发布、熔断降级等机制。

---

### **21、项目中遇到过最大的技术挑战是什么？你是怎么解决的？**

**这是一个行为面试题，没有标准答案。但回答时应遵循STAR原则：**
- **S（Situation）**：描述背景情况。是什么项目？当时的上下文是什么？
- **T（Task）**：你的任务是什么？你需要解决的具体问题是什么？
- **A（Action）**：你采取了哪些行动？你是如何分析问题、寻找解决方案的？
- **R（Result）**：最终的结果是什么？问题解决了吗？有什么可量化的成果？你从中学到了什么？

**示例回答框架：**
“在我之前参与的XX项目中，我们遇到了一个关于系统性能的挑战。当时的情况（S）是，我们的用户量增长很快，在促销活动期间，系统的响应时间变得非常慢，经常超时。
我的任务（T）是定位性能瓶颈并优化系统，将核心接口的响应时间降低到500毫秒以内。
我采取的行动（A）是：
1.  首先，我使用APM工具（如SkyWalking）和Java Profiler来定位瓶颈，发现主要是数据库的慢查询和某些服务的频繁GC导致的。
2.  对于数据库，我通过`EXPLAIN`分析了慢查询，并通过添加索引和重写SQL语句来优化。对于一些复杂的统计查询，我们引入了Redis缓存结果。
3.  对于GC问题，我调整了JVM参数，将堆内存调大，并更换了G1垃圾收集器。
4.  此外，我还对代码进行了异步化改造，将一些非核心的逻辑异步执行。
最终的结果（R）是，在下一次促销活动中，系统的平均响应时间稳定在了300毫秒左右，没有再出现超时情况，CPU使用率也下降了30%。通过这次经历，我深刻体会到监控工具对于性能排查的重要性，以及数据库优化和JVM调优的必要性。”
