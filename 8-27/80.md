这是一场非常典型且硬核的Java后端开发面试，考察点集中在并发、数据结构、数据库和消息队列等核心知识上，虽然岗位是大模型后台开发，但底层依然是这些Java后端基本功。下面我为你提供一份详细的解答。

---

### **实习项目相关**

#### **1. 如何保证执行成功率在99.99%以上？**
这是一个典型的系统高可用/高可靠设计问题。需要从**冗余、重试、监控、降级**等方面回答。
*   **冗余与负载均衡：** 服务部署多个实例，通过负载均衡（如Nginx）分散请求，避免单点故障。某个实例挂掉，流量可以切到健康的实例上。
*   **幂等性与重试机制：**
    *   **幂等性：** 保证同一操作执行一次与执行多次的效果相同。这是重试的前提。可通过token机制、状态机、数据库唯一约束等方式实现。
    *   **重试：** 对于可重试的失败操作（如网络抖动、依赖服务短暂不可用），采用**指数退避重试策略**（Exponential Backoff），避免雪崩。
*   **超时与熔断：** 设置合理的调用超时时间。使用熔断器（如Hystrix, Sentinel）当失败率达到阈值时，快速失败，防止资源被拖垮。
*   **异步与削峰填谷：** 将同步调用改为异步，利用消息队列（如Kafka）缓冲请求。生产者快速将任务写入MQ，消费者按自己的能力消费，避免流量洪峰冲垮系统。
*   **监控与告警：** 建立完善的监控（APM、日志），实时监控成功率、耗时等指标。一旦成功率下跌，立即告警，以便人工或自动系统介入处理。
*   **灰度与回滚：** 任何变更（发版、配置修改）都采用灰度发布策略，出现问题能快速回滚。

#### **2. 为什么要自己写绝对值算子，不用现有的工具？**
这个问题考察的是对技术选型的思考。
*   **性能优化：** 现有的通用工具（如Math.abs()）可能为了通用性而牺牲了极致性能。自己写的算子可以针对特定的数据类型（如int vs double）、硬件架构或运行环境（如Spark集群）进行高度优化，例如使用位运算等底层技巧。
*   **功能定制：** 现有工具的行为可能不完全符合业务需求。例如，处理边界值（如Integer.MIN_VALUE）的行为、对Null值的处理逻辑、是否需要记录日志等，自定义算子可以提供更精确的控制。
*   **依赖管理：** 为了避免引入庞大第三方库的依赖和潜在的版本冲突风险，有时会选择自己实现一个轻量级的、功能聚焦的版本。

#### **3. 雪花算法（Snowflake）的细节和场景问题**
雪花算法是生成分布式ID的经典方案。ID是一个64位的long型数字，结构通常为：
*   **1位符号位**（0，正数）
*   **41位时间戳**（毫秒级，可用69年）
*   **10位工作机器ID**（5位数据中心ID + 5位机器ID，最多支持1024个节点）
*   **12位序列号**（毫秒内的计数，支持每节点每毫秒生成4096个ID）

**可能被问崩的场景问题及解答：**
*   **Q1: 时钟回拨怎么办？**
    *   **A:** 这是雪花算法最致命的问题。解决方案：
        1.  **等待：** 如果回拨时间很短（如毫秒级），可以让线程休眠等待时间追上来。
        2.  **扩展序列号：** 如果回拨时间较长，可以将序列号的高位借1位来表示回拨，但这会缩短序列号或时间戳的位数。
        3.  **备用ID服务：** 严重回拨时，拒绝服务并报警，切换到一个备用的、不依赖时间的ID生成器。
*   **Q2: 10位工作机器ID用完了怎么办？**
    *   **A:** 10位是硬限制。通常通过一个外部系统（如数据库、ZooKeeper）来分配和管理这1024个ID，确保不重复。或者在容器化环境中，可以用Pod的IP等信息通过哈希算法生成一个唯一的ID。
*   **Q3: 每毫秒序列号用完了（超过4096个ID）怎么办？**
    *   **A:** 强制阻塞到下一毫秒再继续生成。这说明当前节点QPS已超过409.6万，需要评估是否合理或考虑分片。

---

### **八股文相关**

#### **1. `synchronized`和`volatile`的区别**
| 特性 | `synchronized` | `volatile` |
| :--- | :--- | :--- |
| **本质** | **锁**，保证原子性和可见性 | **轻量级同步机制**，只保证可见性 |
| **功能** | 互斥执行，线程阻塞 | 禁止指令重排，保证变量可见性 |
| **原子性** | 可以保证（复合操作） | 不能保证（如`i++`） |
| **阻塞** | 会 | 不会 |
| **适用范围** | 代码块、方法 | 变量 |
| **性能** | 重量级，开销大 | 轻量级，开销小 |

**核心：** `volatile`解决的是**可见性**和**有序性**问题，`synchronized`解决的是**原子性**、**可见性**和**有序性**问题。

#### **2. HashMap的底层原理**
*   **JDK1.8之前：** 数组 + 链表
*   **JDK1.8及之后：** 数组 + 链表 / 红黑树
*   **工作流程：**
    1.  `put(key, value)`时，计算key的hash值。
    2.  通过`(n - 1) & hash`确定元素在数组（table）中的位置（下标）。
    3.  如果该位置为空，直接插入。
    4.  如果不为空，则比较key：
        *   如果key相同，则覆盖value。
        *   如果key不同，则采用**尾插法**插入链表。
    5.  插入后，如果链表长度大于8**且数组长度大于64**，则将链表转换为红黑树。
    6.  如果数组元素数量超过`容量 * 负载因子(0.75)`，则进行扩容（ resize ）。

#### **3. 为什么用红黑树，不用跳表或者AVL树？**
*   **vs AVL树：** AVL树是**高度平衡**的二叉搜索树，查询性能略优于红黑树。但红黑树是**近似平衡**的，在插入和删除操作时，**所需的旋转次数更少**，性能更高。对于HashMap这种写操作频繁的场景，红黑树的综合性能更好。
*   **vs 跳表：** 跳表需要额外的空间来存储多级索引（空间换时间）。而红黑树作为二叉树结构，**空间开销更小**。HashMap的底层是数组，每个数组元素指向一个树或链表，使用红黑树可以更好地利用局部性原理，且实现更成熟。

#### **4. 为什么扩容的时候要乘2？**
为了**保持容量始终是2的幂次**。
*   **计算下标：** HashMap通过`(n - 1) & hash`来计算下标，其中`n`是数组长度。当`n`是2的幂次时，`n-1`的二进制形式全是`1`（例如15的二进制是`1111`）。这样`(n-1) & hash`操作等价于`hash % n`，但**位运算的效率远高于取模运算**。
*   **扩容时重新散列：** 元素在新表中的位置要么是**原位置**，要么是**原位置+旧容量**。这是一个非常巧妙的设计，避免了重新计算hash，只需看hash值在新增的最高位上是0还是1即可，效率极高。

#### **5. MySQL的事务隔离级别是什么，怎么实现的？**
*   **隔离级别：** 读未提交 -> 读已提交 -> 可重复读 -> 串行化（一致性逐渐增强，并发性逐渐减弱）。
*   **实现机制：** 主要通过**MVCC（多版本并发控制）** 和**锁机制**来实现。
    *   **MVCC：** 在InnoDB中，每行记录都有两个隐藏字段：`DB_TRX_ID`（最后修改的事务ID）和`DB_ROLL_PTR`（回滚指针，指向undo log中的旧版本）。当一个事务开始时，它会创建一个一致性视图（ReadView），根据这个视图和undo log来找到适合自己的数据版本，从而实现非锁定读。
    *   **锁：** 用于保证写操作的隔离性。如行锁、间隙锁（Gap Lock）、Next-Key Lock（解决幻读）。

#### **6. 怎么避免脏读的？**
*   **脏读：** 一个事务读到了另一个**未提交事务**修改的数据。
*   **解决：** **读已提交（RC）** 及以上隔离级别可以避免。
*   **实现：** 在**读已提交**级别下，一个事务只能读到另一个事务**已经提交**的修改。这是通过MVCC实现的：每个`SELECT`语句都会生成一个新的ReadView，从而总是能读取到最新已提交的数据版本。

#### **7. Kafka怎么避免重复消费？**
重复消费的根本原因是：**消费者消费成功后，在提交offset之前宕机了**，重启后又会从上次的offset开始消费。
*   **解决方案：** 保证消费的**幂等性**。
    1.  **数据库幂等：** 利用数据库主键或唯一键约束，重复插入会失败。
    2.  **Redis幂等：** 为每条消息生成一个唯一ID（如业务ID），消费前先查Redis这个ID是否存在，存在则跳过，不存在则处理并写入Redis。
    3.  **乐观锁：** 更新数据时带上版本号或状态条件。

#### **8. Kafka如果消费者消费成功了，还没有来得及发送ack就挂了要怎么处理？**
这正是Kafka默认的**“至少一次”（At Least Once）** 语义带来的问题。
*   **过程：** 消费者拉取消息 -> 处理消息 -> 提交offset（ack）。
*   **问题：** 如果在处理和提交offset之间消费者挂了，Kafka会认为这条消息没有被成功处理。当消费者重启后，会**重新拉取这条消息**，从而导致重复消费。
*   **处理：** 如上一题所述，**业务方必须自己实现幂等消费**来应对这种情况。Kafka本身在0.11.0版本后提供了**事务消息**和**幂等生产者**，但只能保证端到端的**精确一次（Exactly Once）** 语义（生产者->Broker->消费者），对消费者自身的业务逻辑幂等无法保证。

---

### **手撕算法：K个一组翻转链表**

**思路：**
1.  先计算链表总长度`len`。
2.  需要翻转的组数为`len / k`。
3.  创建一个虚拟头节点`dummy`，指向`head`。
4.  定义两个指针`pre`和`end`。`pre`指向当前要翻转的链表的前驱，`end`指向要翻转的链表的末尾。
5.  循环`len / k`次：
    a. 将`end`走到当前组的第k个节点。
    b. 记录`end.next`为`next`，然后断开链表。
    c. 记录`pre.next`为`start`（即要翻转部分的头）。
    d. 翻转从`start`到`end`的链表。
    e. 将`pre.next`指向翻转后的新头`end`，将`start.next`指向`next`（连接后续链表）。
    f. 更新`pre`和`end`为下一组的前驱（即`start`）。

**代码实现：**
```java
class Solution {
    public ListNode reverseKGroup(ListNode head, int k) {
        if (head == null || k == 1) return head;
        ListNode dummy = new ListNode(0);
        dummy.next = head;
        ListNode pre = dummy;
        ListNode end = dummy;

        while (end.next != null) {
            // 让end走k步，指向当前组的最后一个节点
            for (int i = 0; i < k && end != null; i++) {
                end = end.next;
            }
            if (end == null) break; // 不足k个，不翻转

            // 记录下一组的起点，并断开当前组
            ListNode nextGroupStart = end.next;
            end.next = null;

            // 记录当前组的起点，并断开与前驱的连接
            ListNode groupStart = pre.next;
            pre.next = null;

            // 翻转当前组
            pre.next = reverseList(groupStart); // 翻转后，groupStart变成了组尾，end变成了组头

            // 连接后续链表
            groupStart.next = nextGroupStart;

            // 更新pre和end，为下一组做准备
            pre = groupStart;
            end = groupStart;
        }
        return dummy.next;
    }

    private ListNode reverseList(ListNode head) {
        ListNode prev = null;
        ListNode curr = head;
        while (curr != null) {
            ListNode nextTemp = curr.next;
            curr.next = prev;
            prev = curr;
            curr = nextTemp;
        }
        return prev;
    }
}
```
