这是一场非常高质量的后端面试，问题从项目深度、架构设计到底层原理都有涉及。下面我为你提供一份详细的解答。

---

### **1. 实习项目相关**

（略）请根据你自己的项目准备，重点突出：你做了什么、解决了什么难题、带来了什么价值、有什么样的思考。

---

### **2. 线程池的几种拒绝策略？**

当线程池的任务队列已满且线程数达到`maximumPoolSize`时，新提交的任务会触发拒绝策略。JDK内置了4种策略：

1.  **`AbortPolicy` (默认策略)：** 直接抛出 `RejectedExecutionException` 异常。**这是最严格的策略**，能确保任务不会丢失，但需要调用方处理好异常。
2.  **`CallerRunsPolicy`：** 调用者运行策略。它不会抛出异常，也不会将任务丢弃，而是**将任务回退给调用者线程来执行**（即谁提交的这个任务，谁就去执行它）。这是一种简单的反馈机制，可以减缓新任务提交的速度。
3.  **`DiscardPolicy`：** 静默丢弃策略。直接丢弃新提交的任务，**不抛出任何异常，就像什么都没发生一样**。如果允许任务丢失，这是最简单的一种方案。
4.  **`DiscardOldestPolicy`：** 丢弃最老任务策略。它会**丢弃队列头部的（下一个即将被执行的）任务**，然后尝试重新提交当前这个新任务。这种策略需要谨慎使用，因为它会丢弃等待最久的任务。

---

### **3. 场景题：数据突然增大如何设计解决方案？**

这是一个经典的**分库分表**场景题，考察系统架构的扩展能力。

1.  **评估与监控：**
    *   首先需要监控系统，确定是哪种数据量增大（用户数据、订单数据、日志数据？），以及增大的速度和规模。
    *   评估当前数据库的瓶颈（CPU、IO、连接数？）。

2.  **垂直拆分 (Scale-up)：**
    *   如果只是单表数据量大，优先考虑**单库分表**。根据业务选择分表键（如`user_id`），采用哈希或范围等策略将数据分布到多个物理表中。
    *   将不同业务模块的表拆分到不同的数据库中（如用户库、订单库）。

3.  **水平拆分 (Scale-out)：**
    *   如果单库容量或性能达到瓶颈，需要进行**分库分表**。引入分片中间件（如ShardingSphere、MyCat）来透明化路由和数据聚合。

4.  **数据归档与清理：**
    *   对**冷热数据**进行分离。将历史冷数据（如一年前的订单）从业务主库**归档**到专门的归档库（如HBase、TiDB）或对象存储中，减轻主库压力。

5.  **读写分离：**
    *   在分库分表之前或之后，都可以采用**主从复制+读写分离**的方案。将读请求路由到多个从库，写请求走主库，大幅提升系统的读吞吐量。

6.  **缓存优化：**
    *   进一步优化缓存策略，提高缓存命中率，减少对数据库的直接访问。

7.  **代码与索引优化：**
    *   审视现有SQL语句，优化慢查询。检查并优化索引，避免全表扫描。

---

### **4. 项目中的分表是如何避免全表扫描的？**

**核心答案：分表后，所有的查询条件都必须带上分表键（Sharding Key）。**

*   **原理：** 分表策略（如 `分表序号 = user_id % 64`）决定了数据存储在哪个具体的表中。如果没有分表键，中间件（或应用自己）就**不知道应该去哪个表里查询数据**，只能向所有分表都发送查询请求（即全表扫描），然后对结果进行聚合，性能极差。
*   **如何避免：**
    1.  **SQL设计约束：** 在代码规范和CR阶段就要求，**所有对分表表的查询都必须包含分表键**（如`user_id`）。
    2.  **使用中间件：** 像ShardingSphere这样的中间件，对于**不带分表键的查询会直接抛出异常**或发出警告，强制开发者修改SQL。
    3.  **建立其他维度的映射：** 如果业务上必须按非分表键查询（如按订单号`order_sn`查），而订单号里不包含`user_id`，可以：
        *   在生成订单号时编码进`user_id`的信息。
        *   或者单独维护一个 `<order_sn, user_id>` 的映射关系表（或Redis缓存），先通过`order_sn`查到`user_id`，再带上`user_id`去分表中查询。

---

### **5. SQL语句：查下单最多的用户？**

假设表结构为 `orders(order_id, user_id, amount, create_time)`。

```sql
SELECT user_id, COUNT(order_id) AS order_count
FROM orders
GROUP BY user_id
ORDER BY order_count DESC
LIMIT 1;
```
**注意：** 如果数据量非常大，这个GROUP BY操作会非常耗时，需要在`user_id`字段上建立索引。更好的方式是在业务上通过异步计算，将结果存入缓存或统计表中。

---

### **6. 项目中什么场景需要用到分布式锁？**

分布式锁用于在**分布式系统**中，**对共享资源进行互斥访问**。典型场景：

1.  **秒杀扣减库存：** 防止超卖。多个Pod实例同时扣减同一个商品库存，必须加锁保证原子性。
2.  **防止重复处理：** 如定时任务在多台机器上部署，需要加锁保证同一任务在同一时间只被一台机器执行。
3.  **状态同步：** 对同一个用户资产（如余额）进行操作时，需要加锁。
4.  **核心流程互斥：** 如同一笔订单不能同时发起支付和退款。

**核心原则：** 但凡需要互斥访问的资源不在同一个JVM进程里，就需要分布式锁。

---

### **7. Redisson锁的Key和Value设计？**

*   **Key：** 锁的Key需要**唯一标识被锁定的资源**。通常格式为 `业务前缀:资源标识`，例如 `seckill:lock:stock:{skuId}`。`{skuId}` 是变量，表示具体要对哪个商品加锁。
*   **Value：** Redisson的Value是一个**唯一值**，通常是一个UUID + 线程ID（如 `9281de21-99c7-4a6e-bcfa-04d6c4f0a9d7:1`）。**这个设计至关重要**，它保证了：
    1.  **锁的持有者验证：** 只有知道这个值的客户端才能释放锁，避免了误删其他客户端的锁。
    2.  **可重入性：** 同一个客户端上的同一个线程可以多次获取同一把锁，每次获取value值相同，只需增加一个计数器即可。

---

### **8. 缓存穿透、击穿、雪崩 & 更好方案**

（概念和基础解决方案见上一面经解答）

**更好的解决方案与性能考量：**

*   **缓存穿透 -> 布隆过滤器 (Bloom Filter)：**
    *   **性能问题：** 缓存空值可能浪费内存，且对不停变换的恶意Key效果有限。
    *   **更好方案：** 在缓存之前架设一个**布隆过滤器**。将所有可能存在的key哈希映射到bitmap中。请求来时先查布隆过滤器，如果肯定不存在，直接返回，保护下游。**优点是内存占用极小。**

*   **缓存击穿 -> 逻辑过期：**
    *   **性能问题：** 使用互斥锁，在锁未获取到时，请求会阻塞，体验不佳。
    *   **更好方案：** **逻辑过期**。不给缓存设置TTL，而是在value中封装一个过期时间和数据。业务线程发现数据逻辑过期后，**发起一个异步更新任务**，自己先返回旧的脏数据。这样可以保证非阻塞，体验更好。

*   **缓存雪崩 -> 高可用架构：**
    *   **性能问题：** 错开过期时间能预防，但无法应对Redis实例彻底宕机。
    *   **更好方案：** 构建**Redis高可用架构**，如Redis Sentinel（主从哨兵）或Redis Cluster（集群）。这样即使个别节点宕机，整体服务依然可用，从根本上解决雪崩问题。

---

### **9. 旁路缓存的替代方案？**

旁路缓存（Cache-Aside）确实有数据不一致和维护复杂的问题。替代方案有：

1.  **Read-Through / Write-Through（读写穿透）：**
    *   **原理：** 应用不再直接操作数据库，而是直接操作缓存。缓存组件自己负责数据的加载（Read-Through）和写入数据库（Write-Through）。
    *   **优点：** 对应用透明，代码更简洁，能更好地保证缓存和数据库的一致性。
    *   **缺点：** 需要缓存组件支持（如Ehcache、一些云服务商的缓存服务），或者自己封装一个代理层。

2.  **Write-Behind（异步写入）：**
    *   **原理：** 应用写缓存成功即返回，缓存组件**异步地、批量地**将数据更新到数据库。
    *   **优点：** 写性能极高，非常适合写多读少的场景。
    *   **缺点：** 数据一致性最弱（有丢失风险），实现复杂。

**结论：** 没有银弹。**旁路缓存仍然是最常用、最灵活的模式**。读写穿透和异步写入通常需要特定的缓存产品或框架支持。

---

### **10. 扣减库存为什么用Lua脚本？原子性？回滚？兜底？**

*   **为什么用Lua脚本：** 因为Lua脚本在Redis中是**原子性**执行的。在执行脚本时，Redis会阻塞其他所有命令，直到脚本执行完毕。这样可以确保 `判断库存 -> 扣减库存` 多个操作作为一个整体执行，不会被打断，避免超卖。

*   **执行异常会回滚吗？** **不会。** Redis的Lua脚本执行是原子性的，但**不支持回滚/事务**。如果脚本中途执行失败，**已经执行成功的命令不会被撤销**。例如，脚本先扣了库存，然后执行后续逻辑时报错了，库存扣减这个操作就永久生效了。

*   **怎么做兜底？**
    1.  **脚本设计严谨：** 尽量让脚本只包含最核心的、必须原子执行的逻辑（如库存检查与扣减）。其他操作（如更新订单状态）放在脚本外执行。
    2.  **业务日志与对账：** 记录详细的操作日志。通过**定时对账任务**，比对Redis中的库存、数据库中的库存和订单系统中的销量，发现不一致时进行**人工或自动修复**。这是最后也是最关键的防线。
    3.  **发送消息：** 在Lua脚本成功扣减库存后，可以发送一个消息到MQ。由另一个消费者来执行创建订单等后续操作，即使后续操作失败，也可以通过消费重试机制来保证最终成功。

---

### **11. synchronized 和 ReentrantLock 的底层实现和区别？**

| 特性 | `synchronized` (JVM内置锁) | `ReentrantLock` (API层面的锁) |
| :--- | :--- | :--- |
| **底层实现** | JVM层面通过**对象头中的Mark Word**和**monitor**对象实现。 | 基于**AQS（AbstractQueuedSynchronizer）** 框架，通过CAS和CLH队列实现。 |
| **实现方式** | 关键字，由JVM控制 | Java类，需要手动编码 `lock()` 和 `unlock()` |
| **灵活性** | 较差。锁的获取和释放是固化的。 | 非常灵活。可尝试非阻塞获取、可中断、超时获取、公平/非公平。 |
| **公平性** | **只能是非公平锁** | **可选**公平锁或非公平锁（构造函数指定） |
| ** Condition ** | 只能通过 `wait()/notify()` 与一个条件关联 | 可以绑定**多个**`Condition`，实现更精细的线程等待/唤醒 |
| **性能** | JDK1.6后优化很大，两者性能相差无几 | 在高度竞争下可能略有优势 |

---

### **12. MySQL怎么解决幻读问题的？**

**可重复读（RR）隔离级别下，MySQL通过两种机制解决幻读：**
1.  **MVCC (多版本并发控制)：** 在第一次执行查询时，会生成一个一致性视图（ReadView）。后续整个事务中的所有普通查询都基于这个视图，因此看不到其他事务新插入的数据，从而在**快照读**时避免了幻读。
2.  **Next-Key Lock (临键锁)：** 这是InnoDB的默认行锁算法，它等于 **记录锁(Record Lock) + 间隙锁(Gap Lock)**。
    *   当执行**当前读**（如 `SELECT ... FOR UPDATE`, `UPDATE`, `DELETE`）时，InnoDB不仅会给符合条件的已有记录加锁，还会给这些记录之间的**间隙**加锁。
    *   这样就**阻止了其他事务在这个间隙中插入新的数据**，从而从根本上解决了**当前读**情况下的幻读问题。

**结论：** MVCC解决了快照读的幻读，Next-Key Lock解决了当前读的幻读。

---

### **13. MVCC失效的情况？**

面试官可能想问的是：**在哪种情况下，即使是在RR级别下，也无法避免幻读？** 或者 **MVCC不生效的情况？**

1.  **当前读（Current Read）：** 如 `SELECT ... FOR UPDATE`, `LOCK IN SHARE MODE`, `UPDATE`, `DELETE` 等操作，读取的是数据的最新版本，并且会加锁，**不会使用MVCC的快照**。此时需要靠Next-Key Lock来防止幻读。
2.  **读已提交（RC）隔离级别：** 在RC级别下，**每次读取都会生成一个新的ReadView**，所以每次都能看到其他事务已提交的新数据，MVCC无法避免不可重复读和幻读。
3.  **串行化（Serializable）隔离级别：** 这个级别直接通过加锁来实现，基本不用MVCC。
4.  **使用`READ UNCOMMITTED`级别：** 这个级别会读未提交的数据，根本不使用MVCC。

所以，**MVCC主要在RR隔离级别下的普通SELECT（快照读）中生效**。

---

### **14. 接口文档需要写哪些内容？**

一份合格的RESTful API接口文档应包含以下要素：

1.  **接口基本信息：**
    *   **接口名称：** 如“创建用户订单”。
    *   **请求URL：** `/v1/orders`。
    *   **请求方法：** `POST`。
2.  **请求参数：**
    *   **Header参数：** 如 `Content-Type: application/json`, `Authorization: Bearer <token>`。
    *   **Path Variable：** 如 `/users/{id}`。
    *   **Query String：** 如 `?page=1&size=20`。
    *   **Body参数：** 描述JSON结构体每个字段的含义、类型、是否必填、示例和说明。
3.  **响应信息：**
    *   **响应格式：** 如 `application/json`。
    *   **成功响应：** HTTP状态码（如200）、Body数据结构说明。
    *   **错误响应：** 各种错误状态码（如400, 401, 403, 500）及其对应的错误码和错误信息说明。
4.  **示例：**
    *   一个完整的**请求示例**和**响应示例**，这是最直观的部分。
5.  **其他说明：**
    *   接口的**幂等性**、**限流**策略、**权限**要求等。

**工具：** 强烈推荐使用 **Swagger/OpenAPI** 等工具来自动生成和维护接口文档，保证代码与文档的一致性。
