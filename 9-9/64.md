# FastAPI Async 异步编程详细讲解

## 1. 异步编程基础概念

### 1.1 同步 vs 异步

```python
import time
import asyncio

# 同步版本
def sync_task():
    print("开始同步任务")
    time.sleep(2)  # 阻塞调用
    print("同步任务完成")
    return "同步结果"

# 异步版本
async def async_task():
    print("开始异步任务")
    await asyncio.sleep(2)  # 非阻塞等待
    print("异步任务完成")
    return "异步结果"
```

### 1.2 事件循环(Event Loop)机制

```mermaid
graph TD
    A[事件循环 Event Loop] --> B[任务队列 Task Queue]
    A --> C[执行器 Executor]
    
    B --> B1[协程 Coroutine 1]
    B --> B2[协程 Coroutine 2]
    B --> B3[协程 Coroutine 3]
    
    C --> C1[遇到 await]
    C1 --> C2[挂起当前任务]
    C2 --> C3[执行下一个任务]
    C3 --> C4[IO操作完成]
    C4 --> C5[恢复执行]
    
    D[运行流程] --> D1[创建事件循环]
    D --> D2[添加任务到队列]
    D --> D3[循环处理任务]
    D --> D4[遇到IO切换]
    D --> D5[完成所有任务]
```

## 2. FastAPI 异步核心架构

### 2.1 异步路由处理

```python
from fastapi import FastAPI, BackgroundTasks
import asyncio
import aiohttp

app = FastAPI()

# 基础异步端点
@app.get("/async-endpoint")
async def read_async_data():
    # 模拟异步IO操作
    result = await fetch_data_from_db()
    return {"data": result}

# 混合异步/同步端点
@app.get("/mixed-endpoint")
async def mixed_endpoint():
    # CPU密集型任务使用线程池
    cpu_result = await asyncio.to_thread(cpu_intensive_task)
    
    # IO密集型任务直接await
    io_result = await async_io_task()
    
    return {"cpu": cpu_result, "io": io_result}

# 后台任务
@app.post("/process-data")
async def process_data(background_tasks: BackgroundTasks):
    data = await get_request_data()
    background_tasks.add_task(process_in_background, data)
    return {"message": "Processing started"}

async def fetch_data_from_db():
    # 模拟数据库查询
    await asyncio.sleep(1)
    return {"id": 1, "name": "示例数据"}

def cpu_intensive_task():
    # 模拟CPU密集型计算
    return sum(i * i for i in range(10**6))

async def async_io_task():
    # 模拟异步IO操作
    async with aiohttp.ClientSession() as session:
        async with session.get('https://api.example.com/data') as response:
            return await response.json()

async def process_in_background(data: dict):
    # 后台处理任务
    await asyncio.sleep(5)
    print(f"Processed data: {data}")
```

### 2.2 依赖注入的异步支持

```python
from fastapi import Depends, HTTPException
from typing import Annotated

# 异步依赖项
async def get_async_dependency():
    await asyncio.sleep(0.1)
    return {"dependency": "async_data"}

# 同步依赖项（FastAPI会自动在线程池中运行）
def get_sync_dependency():
    time.sleep(0.1)
    return {"dependency": "sync_data"}

@app.get("/with-dependencies")
async def endpoint_with_deps(
    async_dep: Annotated[dict, Depends(get_async_dependency)],
    sync_dep: Annotated[dict, Depends(get_sync_dependency)]
):
    return {"async": async_dep, "sync": sync_dep}
```

## 3. 高级异步模式

### 3.1 异步数据库操作

```python
import asyncpg
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy import text

# SQLAlchemy 异步引擎
async_engine = create_async_engine(
    "postgresql+asyncpg://user:password@localhost/dbname",
    echo=True,
)

AsyncSessionLocal = sessionmaker(
    bind=async_engine,
    class_=AsyncSession,
    expire_on_commit=False,
)

# 异步数据库依赖
async def get_async_db():
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()

@app.get("/users/{user_id}")
async def get_user(user_id: int, db: AsyncSession = Depends(get_async_db)):
    result = await db.execute(
        text("SELECT * FROM users WHERE id = :id"),
        {"id": user_id}
    )
    user = result.scalar()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return {"user": user}
```

### 3.2 异步缓存机制

```python
from aiocache import Cache, cached
from aiocache.serializers import PickleSerializer

# 配置异步缓存
cache = Cache(Cache.REDIS, endpoint="localhost", port=6379, namespace="main")

# 带缓存的异步端点
@app.get("/cached-data/{item_id}")
@cached(ttl=60, cache=Cache.REDIS, key_builder=lambda f, *args, **kwargs: f"item:{kwargs['item_id']}")
async def get_cached_data(item_id: int):
    # 模拟耗时的数据获取
    await asyncio.sleep(2)
    return {"item_id": item_id, "data": f"content for {item_id}"}

# 手动缓存管理
@app.post("/refresh-cache/{item_id}")
async def refresh_cache(item_id: int):
    data = await fetch_fresh_data(item_id)
    await cache.set(f"item:{item_id}", data, ttl=300)
    return {"status": "cache refreshed"}

async def fetch_fresh_data(item_id: int):
    await asyncio.sleep(1)
    return {"fresh_data": f"new data for {item_id}"}
```

## 4. 异步任务队列和并发控制

### 4.1 异步任务队列

```python
from fastapi import BackgroundTasks
from asyncio import Semaphore
from typing import List

# 并发控制信号量
concurrency_limiter = Semaphore(10)  # 最大10个并发任务

@app.post("/batch-process")
async def batch_process(items: List[int], background_tasks: BackgroundTasks):
    for item in items:
        # 使用信号量控制并发
        background_tasks.add_task(process_item_with_limiter, item)
    return {"message": f"Started processing {len(items)} items"}

async def process_item_with_limiter(item: int):
    async with concurrency_limiter:
        await process_single_item(item)

async def process_single_item(item: int):
    print(f"Processing item {item}")
    await asyncio.sleep(1)  # 模拟处理时间
    print(f"Finished processing item {item}")
```

### 4.2 异步流式响应

```python
import json
from fastapi.responses import StreamingResponse

@app.get("/stream-data")
async def stream_data():
    async def data_generator():
        for i in range(10):
            # 模拟数据生成
            data_chunk = {"chunk": i, "data": f"item_{i}"}
            yield f"{json.dumps(data_chunk)}\n"
            await asyncio.sleep(0.5)  # 模拟延迟
    
    return StreamingResponse(
        data_generator(),
        media_type="application/x-ndjson"
    )
```

## 5. 错误处理和性能监控

### 5.1 异步错误处理

```python
from contextlib import asynccontextmanager
from fastapi import Request
from fastapi.responses import JSONResponse
import logging

logger = logging.getLogger(__name__)

# 异步异常处理器
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error"}
    )

# 异步上下文管理器用于资源管理
@asynccontextmanager
async def get_managed_resource():
    resource = await acquire_resource()
    try:
        yield resource
    finally:
        await release_resource(resource)

async def acquire_resource():
    await asyncio.sleep(0.1)
    return {"resource": "acquired"}

async def release_resource(resource):
    await asyncio.sleep(0.1)
    print(f"Released: {resource}")

@app.get("/managed-resource")
async def use_managed_resource():
    async with get_managed_resource() as resource:
        result = await process_with_resource(resource)
        return result

async def process_with_resource(resource):
    await asyncio.sleep(0.5)
    return {"result": "success", "resource": resource}
```

### 5.2 异步性能监控

```python
import time
from prometheus_client import Counter, Histogram
from starlette.middleware.base import BaseHTTPMiddleware

# 指标定义
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP Requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration', ['method', 'endpoint'])

# 异步中间件
class AsyncMetricsMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        start_time = time.time()
        
        # 记录请求开始
        REQUEST_COUNT.labels(method=request.method, endpoint=request.url.path).inc()
        
        try:
            response = await call_next(request)
            duration = time.time() - start_time
            
            # 记录请求持续时间
            REQUEST_DURATION.labels(
                method=request.method, 
                endpoint=request.url.path
            ).observe(duration)
            
            return response
        except Exception as e:
            duration = time.time() - start_time
            REQUEST_DURATION.labels(
                method=request.method, 
                endpoint=request.url.path
            ).observe(duration)
            raise

# 添加中间件
app.add_middleware(AsyncMetricsMiddleware)
```

## 6. 最佳实践和常见陷阱

### 6.1 异步代码最佳实践

```python
# 好的实践
async def proper_async_function():
    # 使用异步库进行IO操作
    async with aiohttp.ClientSession() as session:
        response = await session.get('https://api.example.com/data')
        return await response.json()

# 避免的实践
async def bad_async_function():
    # 错误：在异步函数中使用同步阻塞调用
    time.sleep(2)  # 这会阻塞事件循环！
    # 应该使用：await asyncio.sleep(2)
    
    # 错误：在异步函数中执行CPU密集型任务
    result = sum(i * i for i in range(10**7))  # 这会阻塞事件循环！
    # 应该使用：await asyncio.to_thread(cpu_intensive_task)

# 正确的CPU密集型任务处理
def cpu_intensive_calculation():
    return sum(i * i for i in range(10**7))

@app.get("/compute")
async def compute_endpoint():
    # 将CPU密集型任务放到线程池中执行
    result = await asyncio.to_thread(cpu_intensive_calculation)
    return {"result": result}
```

### 6.2 异步资源管理

```python
from typing import AsyncIterator

# 使用异步上下文管理器管理资源
class AsyncDatabaseConnection:
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.connection = None
    
    async def __aenter__(self):
        self.connection = await asyncpg.connect(self.connection_string)
        return self.connection
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.connection:
            await self.connection.close()

# 使用异步生成器管理资源
async def get_db_connection() -> AsyncIterator[asyncpg.Connection]:
    connection = await asyncpg.connect("postgresql://user:password@localhost/db")
    try:
        yield connection
    finally:
        await connection.close()

@app.get("/data")
async def get_data(conn: asyncpg.Connection = Depends(get_db_connection)):
    return await conn.fetch("SELECT * FROM table")
```

## 7. 测试异步代码

### 7.1 异步测试示例

```python
import pytest
from httpx import AsyncClient
from main import app

# 异步测试用例
@pytest.mark.asyncio
async def test_async_endpoint():
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get("/async-endpoint")
        assert response.status_code == 200
        assert response.json()["data"] is not None

# 使用 pytest-asyncio 进行测试
@pytest.mark.asyncio
async def test_concurrent_requests():
    async with AsyncClient(app=app, base_url="http://test") as client:
        # 并发发送多个请求
        tasks = [
            client.get(f"/item/{i}") 
            for i in range(5)
        ]
        responses = await asyncio.gather(*tasks)
        
        for response in responses:
            assert response.status_code == 200
```

这个详细的FastAPI异步编程指南涵盖了从基础概念到高级模式的所有方面，包括最佳实践、错误处理、性能监控和测试。通过合理使用异步编程，可以显著提高FastAPI应用的并发性能和资源利用率。
