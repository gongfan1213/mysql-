非常好的AI项目相关面试题，这些问题考察了你对AI应用底层原理的深入理解。让我们逐一进行深度解析，帮你构建一个体系化的知识框架。

---

### **2. Embedding向量检索的原理与准确性保证**

**原理**：
1.  **嵌入（Embedding）**：使用深度学习模型（如BERT、OpenAI的text-embedding-ada-002）将一段文本（词、句、段落）映射到一个**高维向量空间**（通常是几百到几千维）。这个向量能够捕捉文本的语义信息，语义相似的文本在向量空间中的距离会更近。
2.  **检索**：给定一个查询（Query），同样将其转换为向量。然后在一个庞大的**向量数据库**中，寻找与查询向量**最相似**的K个向量。这个过程称为**K近邻（K-NN）搜索**。

**保证检索准确性的方法**：
1.  **高质量的Embedding模型**：这是基础。使用在大规模语料上训练好的、强大的模型（如OpenAI的模型或开源的sentence-transformers模型）。
2.  **相似度度量算法**：选择合适的方法计算向量间的相似度。
    - **余弦相似度（Cosine Similarity）**：最常用，衡量的是向量方向的差异，对向量的绝对大小不敏感。
    - **欧氏距离（Euclidean Distance）**：衡量向量间的绝对距离。
    - **点积（Dot Product）**：计算简单，但受向量维度影响大。
3.  **高效的近似最近邻（ANN）算法**：当向量库极大时，精确的K-NN搜索计算成本极高。使用ANN算法在精度和速度之间取得平衡。
    - **HNSW（Hierarchical Navigable Small World）**：当前最流行的ANN算法之一，通过构建多层图结构实现高效检索，精度损失很小。
    - **IVF（Inverted File Index）**：先对向量空间进行聚类，搜索时先找到最近的几个簇，再在簇内进行精细搜索。
4.  **精心处理输入文本**：
    - **文本清洗**：去除无关字符、停用词。
    - **文本分块（Chunking）**：将长文档切割成大小合适的片段，保证每个片段语义完整且不会信息过载（见问题5）。
5.  **评测与调优**：构建一个测试集，评估检索结果的召回率（Recall）和准确率（Precision），不断调整模型、分块策略和相似度阈值。

---

### **3. Function Calling如何解析用户意图？**

**Function Calling**的本质是让大模型根据用户输入，**结构化地**输出一个调用某个函数的请求，而不是一段自然语言。

**解析过程**：
1.  **定义函数（Tools）**：首先，开发者需要向大模型清晰地描述一个或多个可用的函数。包括：函数名、描述、参数列表（每个参数的名称、类型、描述）。
    ```json
    {
      "name": "get_current_weather",
      "description": "获取指定城市的当前天气",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {
            "type": "string",
            "description": "城市名称，例如：北京"
          }
        },
        "required": ["location"]
      }
    }
    ```
2.  **模型决策**：将用户查询（"北京天气怎么样？"）和定义好的函数描述一起作为输入送给大模型。
3.  **结构化输出**：大模型会分析用户意图。如果它认为需要调用函数来回答问题，它就不会直接生成天气情况，而是会输出一个符合函数参数要求的**JSON对象**。
    ```json
    {
      "name": "get_current_weather", // 决定要调用的函数名
      "arguments": {
        "location": "北京"           // 解析出的参数
      }
    }
    ```
4.  **执行与回复**：你的程序接收到这个JSON后，真正去调用本地函数或外部API获取天气数据，然后将结果再次送给大模型，让大模型组织成自然语言回复给用户。

**所以，解析用户意图的不是Function Calling本身，而是背后的大模型**。Function Calling只是为模型提供了一种规范和格式，让它能将其意图判断结果以一种机器可读的方式输出。

---

### **4. 对话记忆功能 & 队列与堆**

#### **对话记忆的实现（队列）**
你的回答（队列）是**非常经典和正确的**实现方式。通常使用一个**固定长度的队列**（或列表）来保存最近的`K`轮对话（用户提问+AI回答）。
- **实现**：每次新的对话产生，就将`(user_input, ai_response)`对加入队列。如果队列长度超过限制，则从队首移除最老的对话。
- **使用**：在构造下次对话的Prompt时，会将这个队列里的历史对话内容也附加上，通常格式为：
    ```
    用户: 你好
    AI: 你好！我是AI助手。
    用户: 今天的天气怎么样？
    AI: 今天北京晴，25度。
    （当前用户的新问题）
    ```

#### **队列的底层实现是什么？为什么使用堆？**
- **队列的底层**：在Python中，`collections.deque`（双端队列）是使用**双向链表**实现的，在头尾的添加和删除操作时间复杂度都是O(1)。
- **为什么使用堆（Heap）？**：**这里面试官可能误解了你，或者是在考察另一个概念**。标准的对话记忆使用队列，**不会用堆**。
    - **堆**通常用于需要**快速获取最大/最小值**的场景，例如**优先级队列**。
    - **一个可能的高级用法**：如果你想让记忆系统不是简单地遗忘最老的对话，而是遗忘**最不重要的**对话，那么你可以为每轮对话计算一个“重要性”分数，然后用一个**小顶堆**来维护，总是淘汰分数最小的对话。但这非常复杂，不是常见做法。

**高分回答**：“我使用一个固定长度的队列来实现短期记忆，这是一种简单高效的方式。堆通常用于实现优先级队列，适用于需要根据优先级而非时序来处理元素的场景。在标准的对话记忆中，我们关心的是对话的先后顺序，因此队列是更合适的选择。如果您提到的堆是为了实现基于重要性的记忆机制，那是一种更高级的研究方向，如Agent中的‘反思’或‘总结’功能。”

---

### **5. 文本导入向量数据库 & 切割依据**

**切割（Chunking）是RAG系统的关键一步，直接影响检索质量。**

**切割依据**：
1.  **固定大小**：最简单的方法，按字符数或token数切割（如512个token一块）。缺点是可能把完整的句子或段落切断。
2.  **按分隔符**：根据自然分隔符进行切割，如：
    - `\n\n`（空行）：分割段落。
    - `。!?`：分割句子。
    - `### Chapter`：分割章节。
3.  **语义切割**：使用模型判断哪里是语义边界。更高级，但成本也更高。
4.  **递归切割**：组合使用上述方法。例如，先按章节切，再按段落切，如果段落还太大，再按句子切。

**最佳实践**：
- **重叠（Overlapping）**：在切割时，让相邻的文本块有一小部分内容重叠（例如100个token）。这可以防止一个关键信息刚好被切成两半而落在两个块中，导致检索时信息不完整。
- **添加元数据**：为每个文本块添加元数据，如来源文件名、标题、章节等，便于追溯。

**导入流程**：`原始文本 -> 文本清洗 -> 文本分块 -> 通过Embedding模型转换为向量 -> 将(向量, 文本块, 元数据)存入向量数据库`

---

### **6. 对话记忆的限制与Prompt变化**

- **是所有数据都保存吗？**：**通常不会**。只保存最近的若干轮对话（短期记忆）。保存所有对话会导致Prompt极速膨胀，消耗大量Token，增加成本，并且可能让模型混淆，关注到过于久远的不相关信息。
- **超出最大限度怎么办？**：
    1.  **滑动窗口**：最常用方法，即移出最老的对话，加入最新的对话。
    2.  **总结压缩（Summary）**：一种更高级的方法。当对话达到一定长度时，让大模型对之前的对话历史进行**总结**，然后用这个总结摘要来代替原有的详细历史。这样既保留了核心信息，又大大节省了Token。
- **Prompt会改变吗？**：**会的**。因为Prompt中包含了历史对话记录，每次新的交互都会改变这个记录。所以**每次请求的Prompt都是动态生成的**。

---

### **7. 非阻塞式响应的实现**

**实现原理**：对于耗时的操作（如调用大模型生成文本），不讓HTTP请求线程等待其完成，而是立即返回一个响应，并通过其他方式（如WebSocket、SSE、轮询）在操作完成后将结果推送给客户端。

**实现方式（以Spring Boot为例）**：
1.  **使用`@Async`异步方法**：将调用大模型的逻辑封装到一个被`@Async`注解的方法中，该方法返回`CompletableFuture<String>`。
2.  **立即响应**：Controller方法调用这个异步方法后，立即返回一个中间结果（例如一个任务ID或一个确认信息）。
    ```java
    @PostMapping("/chat")
    public DeferredResult<ResponseEntity<String>> chat(@RequestBody Request request) {
        DeferredResult<ResponseEntity<String>> deferredResult = new DeferredResult<>();
        // 将deferredResult和任务关联起来，并提交到线程池执行
        asyncService.processChat(request, deferredResult);
        return deferredResult; // 此时Tomcat线程立即释放
    }
    ```
3.  **依赖**：需要在Spring配置中开启异步支持`@EnableAsync`，并配置一个`TaskExecutor`线程池。

**推送技术**：
- **SSE (Server-Sent Events)**：服务器可以主动向浏览器发送数据，适合单向通知场景。
- **WebSocket**：全双工通信，适合需要高频、双向通信的场景。

---

### **8. 项目协议：WebSocket vs HTTPS**

- **整个项目基于什么协议？**：AI对话项目通常基于**WebSocket**协议来实现**全双工、低延迟的实时对话**。普通的请求-响应则使用**HTTP/HTTPS**。
- **和HTTPS的区别**：
    | 特性 | **HTTP/HTTPS** | **WebSocket** |
    | :--- | :--- | :--- |
    | **通信模式** | **请求-响应**（半双工） | **全双工**（双向通信） |
    | **生命周期** | 短连接（一次请求结束即断开） | 长连接（建立后保持连接） |
    | **开销** | 每次请求都有HTTP头开销 | 建立连接后数据包头部开销很小 |
    | **适用场景** | 获取网页、API调用 | 实时聊天、实时数据推送、在线游戏 |

**关系**：WebSocket连接在建立时，首先要发起一个**HTTP请求**（带有`Upgrade: websocket`头），进行“握手”，成功后协议就升级为WebSocket。

---

### **9. 项目职责**

这是一个行为题，考察你的项目贡献和技能广度。
**高分回答**：“在这个项目中，我主要负责后端核心模块的设计与开发。包括了大模型API的集成、Function Calling的流程编排、向量数据库的构建与检索，以及使用WebSocket实现实时对话功能。前端界面是由另一位专注于前端的同事开发的，但我对前端的调用逻辑和后端接口的联调有深入的了解，能够独立进行接口调试和问题排查。”

---

### **10. ZSet底层结构**

- **ZSet是什么**：Redis的有序集合（Sorted Set），每个元素都有一个分数（score），元素按分数排序，且元素唯一。
- **底层数据结构**：使用两种结构的组合：
    1.  **跳跃表（SkipList）**：用于支持**高效的范围操作**（如`ZRANGE`），可以在O(log N)时间复杂度内完成。
    2.  **哈希表（Hash Table）**：用于支持**高效的单点查询**（如`ZSCORE`），可以在O(1)时间复杂度内根据成员（member）找到其分数（score）。
- **这种“哈希表+跳跃表”的混合设计**，是典型的**空间换时间**策略，同时保证了ZSet的两种操作模式都有极高的性能。

---

### **11. Lua脚本的使用与场景**

- **如何使用**：在Redis客户端使用`EVAL`命令或`SCRIPT LOAD` + `EVALSHA`命令来执行Lua脚本。
    ```lua
    EVAL "return redis.call('set', KEYS[1], ARGV[1])" 1 mykey myvalue
    ```
- **使用场景**：
    1.  **原子性操作**：需要多个命令原子性执行时，如**分布式锁的释放**（判断锁标识再删除）。
    2.  **减少网络开销**：将多个命令组合成一个脚本执行，减少客户端与Redis服务器之间的网络往返次数（RTT）。
    3.  **复杂操作**：在服务器端执行一些复杂的逻辑，如操作多个数据结构。

---

### **12. 乐观锁**

- **是什么**：乐观锁是一种**冲突检测**机制。它假设多用户并发操作不会产生冲突，因此不上锁。只在提交更新时，检查数据是否被其他线程修改过。
- **锁的是什么？**：乐观锁**不锁任何东西**。它通常通过一个**版本号（version）字段**或**时间戳**来实现。读取数据时，同时读出version。更新数据时，执行类似这样的操作：
    ```sql
    UPDATE table SET stock = stock - 1, version = version + 1 
    WHERE id = 123 AND version = old_version;
    ```
    如果返回的影响行数为0，说明有其他线程已经修改过数据，本次操作失败，需要重试。
- **使用场景**：**读多写少**的场景。你在**秒杀扣减库存**、**更新商品信息**等场景中可以使用乐观锁，避免使用悲观锁带来的性能开销。

---

### **13. 全局唯一ID实现**

- **雪花算法（Snowflake）**：**最佳实践**。生成一个64位的Long型ID。
    - **结构**：`1位符号位(0) + 41位时间戳(毫秒) + 10位机器ID + 12位序列号`
    - **优点**：**本地生成、高性能、趋势递增**（对数据库索引友好）。
- **Redis `INCR`命令**：利用Redis的单线程原子性，生成序列ID。需要维护Redis。
- **数据库自增主键**：简单，但分库分表时麻烦，且暴露业务量。
- **UUID**：本地生成，性能好。但无序，作为数据库主键时插入效率低，且长度长。

---

### **14. 压测**

**高分回答**：“是的，我们使用**JMeter**对系统的关键接口，特别是对话接口和向量检索接口，进行过压力测试。主要关注**QPS（每秒查询率）**、**响应时间（P95, P99）** 以及系统在高压下的**错误率**。通过压测，我们找到了系统的瓶颈，比如数据库连接数不足或某个外部API调用缓慢，并针对性地进行了优化，如调整线程池参数、引入缓存、扩容等。”

---

### **15. 单精度与双精度区别**

| 特性 | **单精度（float, 32位）** | **双精度（double, 64位）** |
| :--- | :--- | :--- |
| **位数** | 32位 | 64位 |
| **符号位** | 1位 | 1位 |
| **指数位** | 8位 | 11位 |
| **尾数位** | 23位 | 52位 |
| **精度** | 约6-7位有效数字 | 约15-16位有效数字 |
| **取值范围** | ±3.4e±38 | ±1.7e±308 |
| **占用空间** | 小 | 大（是float的两倍） |
| **计算速度** | 快 | 慢（取决于硬件） |

**应用**：在AI中，模型的参数通常用**单精度（FP32）** 甚至**半精度（FP16）** 存储，以节省内存和提高计算速度。而需要高精度的科学计算则使用双精度。

---

### **16. TCP/IP七层网络模型**

**经典七层模型（OSI模型）** 和 **实际使用的五层TCP/IP模型** 对比：

| OSI七层模型 | TCP/IP五层模型 | 核心协议 | 功能 | 设备 |
| :--- | :--- | :--- | :--- | :--- |
| 应用层 | 应用层 | HTTP, HTTPS, FTP, DNS, WebSocket, MQTT | 为应用程序提供网络服务 | |
| 表示层 | (融入应用层) | SSL/TLS | 数据格式转换、加密解密 | |
| 会话层 | (融入应用层) | | 建立、管理和终止会话 | |
| 传输层 | 传输层 | **TCP**, **UDP** | 提供端到端的可靠或不可靠传输 | |
| 网络层 | 网络层 | **IP**, ICMP, RIP | 寻址和路由选择，将数据包从一个网络传到另一个网络 | **路由器** |
| 数据链路层 | 数据链路层 | Ethernet, PPP | 在相邻节点之间可靠地传输数据帧 | **交换机** |
| 物理层 | 物理层 | IEEE 802.3 | 在物理介质上传输原始比特流 | **集线器、网线** |

**记忆口诀**：“**应表会传网数物**”（Please Do Not Throw Sausage Pizza Away）。

---

这场面试的深度和广度都非常高，说明面试官水平很高，也说明你的项目很有技术含量。把这些知识点系统化地整理清楚，你的技术实力又会上升一个大的台阶。祝你接下来面试顺利！
