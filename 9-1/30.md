非常高兴为你解答这些深入且高质量的Java面试题。这些问题涵盖了JVM、并发、数据库、分布式系统等多个领域，非常能考察候选人的技术深度。下面我将为你逐一详细解答。

---

### 2. HashMap里，链表转红黑树的阈值为什么设成8？退化的时候是6呢？

*   **为什么是8？** 这是基于统计学上的**泊松分布**计算出的一个空间与时间的权衡值。
    *   在理想的随机哈希情况下，链表长度达到8的概率非常低（约0.00000006）。这意味着在绝大多数情况下，链表都不会达到这个长度。
    *   设置一个较高的阈值（8）可以避免在极端情况下（如哈希函数设计不佳）过早地转换为红黑树。因为红黑树虽然查询效率高（O(log n))，但其节点大小是链表节点的两倍，占用更多空间，且维护（插入、旋转）成本更高。
    *   **核心思想**：在概率极低的事件发生时，我们才使用更复杂但能保证性能的数据结构，从而在99.9%的情况下享受链表简单结构带来的空间节省。

*   **为什么退化是6？** 主要是为了防止**频繁的转换**。
    *   如果退化的阈值也是8，那么当一个红黑树的节点数在8附近波动时（比如反复插入和删除），可能会频繁地在链表和红黑树之间进行转换。这种转换本身是有成本的。
    *   设置一个**缓冲区间**（8升，6降），避免了在临界值附近的抖动，保证了性能的稳定。

### 3. synchronized的锁升级过程，能讲一下吗？

synchronized的锁状态在对象头（Mark Word）中表示，其升级过程是不可逆的，目的是减少获得锁和释放锁带来的性能开销。

1.  **无锁状态**：新创建的对象。
2.  **偏向锁**：
    *   **目的**：在无线程竞争的情况下，消除同步原语，提高性能。
    *   **过程**：第一个线程访问同步块时，通过CAS操作将线程ID记录到对象头的Mark Word中。之后该线程再进入和退出同步块时，无需进行任何CAS操作，只需简单检查Mark Word中是否存储着自己的线程ID。
3.  **轻量级锁**：
    *   **触发**：当有另一个线程来竞争锁时，偏向锁就会升级为轻量级锁。
    *   **过程**：原持有偏向锁的线程被挂起，JVM会在其栈帧中创建一个名为**锁记录（Lock Record）**的空间，并将对象头的Mark Word复制到其中。然后，JVM尝试使用CAS将对象头的Mark Word替换为指向该锁记录的指针。如果成功，当前线程获得锁；如果失败，表示有其他线程竞争，当前线程会尝试**自旋**（循环等待）来获取锁。
4.  **重量级锁**：
    *   **触发**：如果自旋失败（比如自旋次数超过阈值，或者自旋时又来了第三个竞争者），锁就会升级为重量级锁。
    *   **过程**：此时，未获得锁的线程都会**被阻塞**，进入等待队列。锁的标志位变为指向操作系统**互斥量（Mutex）** 的指针。等待锁的线程不再消耗CPU，但线程间的切换会带来高昂的成本。

### 4. G1垃圾回收器是怎么预测停顿时间的？它的Region大小一般怎么定？

*   **预测停顿时间（Pause Prediction Model）**：
    *   G1将堆划分为多个固定大小的Region。
    *   它通过跟踪每个Region的垃圾总量和回收所需的时间，构建了一个**衰减平均值（Decaying Average）** 模型。
    *   简单来说，G1会根据**历史数据**（例如，回收N个Region平均需要M毫秒）来预测**本次回收**选择X个Region大概需要多少时间。
    *   它会动态调整回收的Region数量（即回收集 - Collection Set），力求在用户指定的目标停顿时间（`-XX:MaxGCPauseMillis`）内，回收尽可能多的垃圾。

*   **Region大小**：
    *   Region的大小在JVM启动时确定，范围在**1M到32M**之间，且是2的幂。
    *   计算公式大致为：`HeapSize / 2048`。例如，堆大小为4G，则Region大小为4G/2048 = 2M。
    *   JVM会选择一个最接近这个计算值的2的幂次方数作为最终的Region大小。目的是将整个堆合理划分为约2000个Region。

### 5. volatile能保证数组里每个元素的可见性吗？如果不能，要怎么解决？

*   **不能**。`volatile`关键字只能保证**数组引用本身**的可见性，即如果线程A将`volatile array`指向一个新的数组，线程B能立即看到这个新引用。但它**不能**保证数组**元素**的读写操作的可见性和原子性。
*   **解决方案**：
    1.  **使用原子数组类**：`AtomicIntegerArray`, `AtomicLongArray`, `AtomicReferenceArray`。这些类内部使用`volatile`和CAS操作来保证每个元素的原子性和可见性。
    2.  **对数组元素的操作加锁**：使用`synchronized`或`java.util.concurrent.locks.Lock`来同步对特定元素的访问。
    3.  **将volatile变量放在每个元素里**：这通常不现实，因为需要修改元素类型。

### 6. ThreadLocal为什么会内存泄漏，根本原因是什么？JDK后来有什么改进方案吗？

*   **根本原因**：
    1.  **关键数据结构**：`ThreadLocal`的值存储在每个线程的`ThreadLocalMap`中。这个Map的`Entry`继承自`WeakReference<ThreadLocal<?>>`，其**Key是弱引用指向ThreadLocal对象**，Value是强引用指向实际存储的值。
    2.  **问题产生**：当外部的强引用指向`ThreadLocal`的对象被回收（例如`tl = null`）后，由于Key是弱引用，在下次GC时，这个Key就会被回收，导致`Entry`的Key变为`null`，但Value仍然被一个强引用（`Thread -> ThreadLocalMap -> Entry -> Value`）关联着。
    3.  **内存泄漏**：如果线程迟迟不结束（例如是线程池中的线程），这个Value就永远无法被访问到（因为Key是null），但也永远无法被回收，造成内存泄漏。

*   **JDK的改进**：
    *   在`ThreadLocalMap`的`set`, `get`, `remove`方法中，都增加了**启发式清理**：在操作过程中，如果遇到了Key为`null`的`Entry`（称为“stale entry”），就会顺便将其Value置空，从而断开对Value的强引用，允许GC回收它。
    *   **最佳实践**：**每次使用完`ThreadLocal`后，必须手动调用`remove()`方法**，彻底清理掉当前线程的Map中的Entry。这是最可靠的做法。

### 7. Java 8里，Stream的并行处理是怎么实现的？

*   Stream的并行处理底层使用的是**Fork/Join框架**（具体是`ForkJoinPool`）。
*   **过程**：
    1.  **分割（Fork）**：将一个大的数据源（如List）通过`Spliterator`分割成多个足够小的子任务。
    2.  **执行与合并（Join）**：每个子任务在一个工作线程中执行指定的操作（如filter、map）。执行完毕后，将各个子任务的结果合并（Reduce）成最终的整体结果。
*   默认情况下，并行流使用**公共的ForkJoinPool**（`ForkJoinPool.commonPool()`），其线程数默认为处理器核心数-1。你也可以自定义一个ForkJoinPool来运行并行流。

### 8. ForkJoinPool的工作窃取（Work-Stealing）机制，能解释一下吗？

*   **目的**：充分利用多核CPU性能，减少线程间的竞争和空闲等待。
*   **机制**：
    1.  每个工作线程都维护一个**双端队列（Deque）**，用来存放它自己产生的子任务。
    2.  线程在处理自己队列中的任务时，遵循**LIFO（后进先出）** 的顺序，因为新产生的任务粒度更小，更快能完成，有助于更快地得出部分结果。
    3.  当某个线程自己的任务队列为空时，它不会闲着，而是会随机选择另一个线程的队列，从**队尾（另一端）** **“窃取”** 一个任务来执行（FIFO顺序）。
*   **优点**：
    *   减少了线程的等待时间。
    *   减少了访问同一个任务队列的竞争（自己线程访问队尾，窃取线程访问队头）。

### 9. AQS里面为什么用的是CLH队列，而不是普通的链表？

AQS（AbstractQueuedSynchronizer）使用CLH变体队列的主要原因是为了**高效且无锁地管理阻塞线程**。

*   **CLH队列的本质**：是一个虚拟的FIFO队列，每个等待的线程只需要监视其前驱节点的状态。
*   **相比普通链表的优势**：
    1.  **无锁入队**：通过CAS操作可以高效、无锁地将新节点添加到队列尾部，避免了普通链表需要加锁来维护一致性的问题。
    2.  **降低CPU开销**：线程在挂起前会**自旋**检查前驱节点的状态。一旦前驱节点释放锁，它就能立即被唤醒，响应速度快。AQS对此进行了优化，避免了原始CLH无限自旋的缺点，而是结合了`LockSupport.park()`/`unpark()`来挂起和唤醒线程。
    3.  **公平性**：严格保证了FIFO的公平锁语义。

### 10. 线程池的核心参数一般怎么设置？听说美团有动态调整的方案，了解吗？

*   **常规设置**：
    *   **CPU密集型**：`corePoolSize` = `CPU核心数 + 1`
    *   **IO密集型**：`corePoolSize` = `2 * CPU核心数` 或更大，因为IO操作不占用CPU，线程大多时间在等待。
    *   `maxPoolSize`：根据系统最大负载和资源情况设定。
    *   `workQueue`：通常使用`LinkedBlockingQueue`（无界队列需谨慎）或`SynchronousQueue`。
    *   **黄金公式**：`线程数 = CPU核心数 * (1 + 平均等待时间 / 平均计算时间)`。这需要压测来估算。

*   **美团动态调整方案**：
    *   核心思想是**监控线程池的运行状态**（如队列大小、活跃线程数、最大线程数等），并提供一个**动态参数修改的接口**。
    *   例如，在发生流量洪峰时，通过配置中心下发指令，动态调大`corePoolSize`和`maxPoolSize`，快速应对；在流量平稳后，再动态调小，节约资源。开源项目**Hippo**和**DynamicTp**就是这类思想的实现。

### 11. 平时怎么监控和优化慢SQL查询？

1.  **监控**：
    *   **开启慢查询日志**：在MySQL中设置`long_query_time`，记录执行时间超过阈值的SQL。
    *   **使用监控工具**：如Arthas、Prometheus + Grafana、SkyWalking、APM工具（Pinpoint, APM）等。
    *   `EXPLAIN`命令：分析SQL的执行计划，查看是否使用索引、是否有全表扫描、连接类型等。

2.  **优化**：
    *   **索引优化**：为`WHERE`, `ORDER BY`, `GROUP BY`, `JOIN`的字段添加合适的索引；避免索引失效（见第14题）。
    *   **SQL语句优化**：
        *   避免`SELECT *`，只取需要的字段。
        *   优化子查询，常用`JOIN`代替。
        *   避免在WHERE子句中对字段进行函数操作、表达式计算或类型转换。
    *   **设计优化**：合理的表结构设计（如范式与反范式的权衡）、分库分表。

### 12. 如果让你用CAS实现一个无锁栈，你有什么思路？

核心是使用一个`AtomicReference`来指向栈顶节点，通过CAS来保证原子性的入栈和出栈操作。

```java
import java.util.concurrent.atomic.AtomicReference;

public class LockFreeStack<T> {
    private static class Node<T> {
        T value;
        Node<T> next;
        Node(T value) {
            this.value = value;
        }
    }

    private final AtomicReference<Node<T>> top = new AtomicReference<>();

    public void push(T item) {
        Node<T> newHead = new Node<>(item);
        Node<T> oldHead;
        do {
            oldHead = top.get();
            newHead.next = oldHead; // 新节点的next指向当前栈顶
        } while (!top.compareAndSet(oldHead, newHead)); // CAS尝试将栈顶替换为新节点
    }

    public T pop() {
        Node<T> oldHead;
        Node<T> newHead;
        do {
            oldHead = top.get();
            if (oldHead == null) {
                return null; // 栈为空
            }
            newHead = oldHead.next; // 新的栈顶应该是老栈顶的下一个节点
        } while (!top.compareAndSet(oldHead, newHead)); // CAS尝试弹出老栈顶
        return oldHead.value;
    }
}
```
**注意**：这就是一个经典的Treiber Stack实现。它存在ABA问题，但在Java中由于垃圾回收的存在，ABA问题通常不会造成危害（因为同一个地址不会被重用于不同的节点）。

### 13. 用CompletableFuture怎么实现有依赖关系的多个异步任务？

`CompletableFuture`提供了强大的链式编程能力。

*   **串行依赖**：`thenApply()`, `thenAccept()`, `thenRun()`, `thenCompose()`
    ```java
    CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> "Hello")
            .thenApply(s -> s + " World") // 依赖上一步的结果
            .thenApply(String::toUpperCase);
    System.out.println(future.get()); //输出 "HELLO WORLD"
    ```

*   **聚合依赖（AND聚合）**：`thenCombine()`（两个都完成，然后处理）
    ```java
    CompletableFuture<Integer> priceFuture = getPriceAsync();
    CompletableFuture<Double> rateFuture = getRateAsync();
    CompletableFuture<Double> resultFuture = priceFuture.thenCombine(rateFuture, (price, rate) -> price * rate);
    ```

*   **聚合依赖（OR聚合）**：`applyToEither()`（任意一个完成就处理）
    ```java
    CompletableFuture<String> fastSource = fetchFromSourceA();
    CompletableFuture<String> slowSource = fetchFromSourceB();
    CompletableFuture<String> result = fastSource.applyToEither(slowSource, data -> data);
    ```

### 14. 能列举一些MySQL索引失效的场景吗？最左前缀原则的底层原理是啥？

*   **索引失效常见场景**：
    1.  **违反最左前缀原则**：联合索引`(a, b, c)`，查询条件为`b = ? and c = ?`，无法使用索引。
    2.  **在索引列上做计算、函数或类型转换**：`WHERE YEAR(create_time) = 2023`，`WHERE amount * 2 > 100`。
    3.  **使用范围查询（>, <, LIKE '%xx'）右边的列失效**：`WHERE a > 1 AND b = 2`，联合索引`(a, b)`，`b`无法使用索引。
    4.  **使用`OR`连接非索引列**：`WHERE a = 1 OR b = 2`，如果`b`无索引，则整个查询可能全表扫描。
    5.  **`!=`或`<>`操作符**。
    6.  **`IS NULL`和`IS NOT NULL`** 有时会导致索引失效（取决于数据分布和优化器选择）。
    7.  **字符串查询不加引号**（类型隐式转换）：索引字段是`varchar`，查询用`WHERE id = 123`（数字），会导致类型转换，索引失效。

*   **最左前缀原则的底层原理**：
    *   MySQL中的索引（如B+Tree）是按照索引定义的**字段顺序**来排序的。
    *   先按第一个字段排序，第一个字段相同再按第二个字段排序，以此类推。
    *   因此，查询条件必须从索引的**最左边列开始**，并且不能跳过中间的列，才能高效地利用这棵排序树进行查找。`WHERE a = ? and c = ?`只能用到`a`列的索引，无法用到`c`列。

### 15. 一张十几亿数据的订单表，分页查询要怎么优化？

`LIMIT offset, size`在offset非常大时（如`LIMIT 1000000, 20`）效率极低，因为MySQL需要先扫描`offset + size`条记录，然后抛弃前offset条。

*   **优化方案1：使用索引覆盖扫描 + 子查询**
    ```sql
    SELECT * FROM orders 
    INNER JOIN (
        SELECT id FROM orders 
        WHERE ... -- 你的查询条件
        ORDER BY create_time DESC 
        LIMIT 1000000, 20
    ) AS tmp ON orders.id = tmp.id;
    ```
    先通过覆盖索引（只查ID）快速定位到需要的那20条记录的ID，再通过ID回表查询完整的行数据。这大大减少了需要扫描和排序的数据量。

*   **优化方案2：记录上一页的最大ID（条件：按唯一自增ID排序）**
    ```sql
    -- 假设上一页最后一条记录的id是1000000
    SELECT * FROM orders 
    WHERE id > 1000000 
    ORDER BY id 
    LIMIT 20;
    ```
    这种方式几乎瞬间完成，但限制是必须有序且连续的自增ID，并且只能“下一页”，不能跳页。

### 16. 假如删一个Redis的大Key导致集群挂了，怎么避免这种情况？

*   **大Key的定义**：通常指一个Key的Value体积过大（如超过10KB的String，元素数量超过5000的Hash/List/Set/ZSet）。
*   **删除大Key的危害**：`DEL`命令是阻塞的。删除一个包含百万元素的Hash，会导致Redis单线程被长时间阻塞，无法处理其他请求，从而引发雪崩甚至集群宕机。
*   **解决方案**：
    1.  **拆分**：从源头上避免大Key的产生。将一个大Hash拆分成多个小Hash，通过一个固定的哈希算法决定数据落在哪个小Key上。
    2.  **异步删除（Redis 4.0+）**：使用`UNLINK`命令代替`DEL`。`UNLINK`会将Key从 keyspace 中**异步删除**，实际回收内存由后台线程处理，不会阻塞主线程。
    3.  **渐进式删除**：对于旧版本Redis，可以自己写脚本分批删除。例如，对于大Hash，每次用`HSCAN`读取一部分字段，再用`HDEL`分批删除。

### 17. Redis的事务和MySQL的事务，在ACID特性上有什么区别？

| 特性 | MySQL事务 | Redis事务（MULTI/EXEC） |
| :--- | :--- | :--- |
| **原子性 (A)** | **真正意义上的原子性**。所有语句要么全部成功，要么全部失败回滚。 | **是“伪原子性”**。它仅仅是**命令的打包**：所有命令入队，然后一次性顺序执行。**中间某条命令失败，不会回滚已执行的命令**。没有回滚机制。 |
| **一致性 (C)** | 强一致性。通过Undo/Redo Log、锁等机制保证。 | 弱一致性。它通过**错误检测**（如命令入队时检查语法）和**简单的乐观锁（WATCH）** 来保证，但较弱。 |
| **隔离性 (I)** | 提供多种隔离级别（读未提交、读已提交等），通过MVCC和锁实现。 | **天生“串行化”隔离**。因为Redis单线程执行，所有命令都是顺序执行的，不存在并发问题。 |
| **持久性 (D)** | 通过Redo Log保证，即使宕机也能恢复。 | 取决于配置（`appendfsync`）。即使配置为 always，也存在数据丢失的极小时间窗口。 |

**结论**：**不要用Redis事务来处理需要强一致性的业务逻辑**。它更像一个**批量执行命令的脚本**，其主要目的是减少网络开销，而不是保证ACID。

### 18. 缓存和数据库一致性有哪几种方案，能对比一下吗？像拼多多的秒杀场景，你觉得会用哪种？

*   **常见方案**：
    1.  **先更新数据库，再删除缓存（Cache-Aside）**：
        *   **流程**：写操作 -> 更新DB -> 删除Cache。
        *   **优点**：简单，常用。出现不一致的概率较低（缓存失效时间也能兜底）。
        *   **缺点**：存在**“先删缓存，后更新DB”** 方案中提到的“读写并发”导致的不一致问题（但概率更低），以及删除缓存失败的问题。
    2.  **延时双删**：`删除缓存 -> 更新DB -> (休眠一段时间) -> 再删除缓存`。
        *   **目的**：解决上述的并发问题。休眠时间略大于一次读操作+写缓存的时间。
        *   **缺点**：休眠时间难以确定，降低吞吐量。
    3.  **先更新数据库，再通过Binlog异步淘汰缓存**：
        *   **流程**：写操作 -> 更新DB -> MySQL Binlog -> 订阅Binlog的组件（如Canal） -> 发送消息 -> 消费消息删除缓存。
        *   **优点**：解耦，可靠性高。
        *   **缺点**：架构复杂，有延迟。

*   **拼多多秒杀场景的选择**：
    *   秒杀场景**对一致性和性能要求都极高**。
    *   通常会采用**“预扣减”** 的方案：库存数据直接在**Redis中扣减**（使用`DECR`等原子操作），秒杀成功后，再**异步地**将结果持久化到数据库。
    *   **一致性方案**：在这种架构下，Redis是“源”，数据库是“备份”。一致性通过**最终一致性**来保证：后台任务会同步Redis和数据库的库存数据。对于秒杀场景，用户更关心是否抢到，而对最终库存数字的一致性要求不是绝对的实时。因此，**Cache-Aside**或其变种（结合异步同步）是更可能的选择。

### 19. Redis Cluster在做slot迁移的时候，会阻塞客户端请求吗？

*   **不会完全阻塞**。Redis Cluster的resharding过程是**异步**和**非阻塞**的。
*   **过程**：
    1.  迁移开始时，源节点和目标节点会记录slot的迁移状态。
    2.  当客户端请求的Key**还在源节点**时，源节点正常处理。
    3.  当客户端请求的Key**已经迁移到目标节点**时，源节点会向客户端返回一个`-ASK`重定向错误，其中包含目标节点的地址。
    4.  客户端收到`-ASK`错误后，会先向目标节点发送一个`ASKING`命令，然后重新发送原来的命令。目标节点知道这个Key是正在导入的，会临时处理这个命令。
    5.  迁移完成后，客户端请求Key时，源节点会返回一个`-MOVED`重定向错误，客户端会更新本地的slot缓存，后续直接请求目标节点。

### 20. MySQL里遇到死锁了，一般的排查步骤是怎样的？另外，间隙锁（gap lock）是怎么解决幻读问题的？

*   **死锁排查步骤**：
    1.  **开启监控**：确保`innodb_print_all_deadlocks = ON`，这样死锁信息会打印到错误日志中。
    2.  **查看日志**：立刻去MySQL错误日志里查找最新的`LATEST DETECTED DEADLOCK`部分，它会详细记录两个事务各自持有的锁和等待的锁。
    3.  **分析SQL**：根据日志信息，定位到导致死锁的SQL语句和事务。
    4.  **优化**：
        *   确保所有事务都以**相同的顺序**访问表和行。
        *   降低事务的粒度，缩短事务执行时间。
        *   在业务层做重试。

*   **间隙锁解决幻读**：
    *   **幻读**：指一个事务在前后两次查询同一个范围时，**后一次查询看到了前一次查询没有看到的幻影行**（由其他事务插入导致）。
    *   **间隙锁（Gap Lock）**：它锁住的是索引记录之间的**间隙**，防止其他事务在这个间隙中插入新的数据。
    *   **如何解决**：在**可重复读（RR）** 隔离级别下，MySQL通过**next-key lock**（行锁 + 间隙锁）来给一个范围加锁。例如`SELECT * FROM table WHERE id BETWEEN 10 AND 20 FOR UPDATE;`，它不仅会锁住id=10,11,...20这些已有的行，还会锁住(10, 11), (11, 12), ... (19, 20), (20, +∞)这些间隙。这样，其他事务就无法在这个范围内插入任何新的id值，从而彻底防止了幻读的发生。

### 21. 让你来设计一个类似拼多多砍价的系统，你会怎么考虑防止刷单？

防刷是砍价系统的核心。
1.  **身份校验**：
    *   强制用户登录，一个用户只能帮砍一次（基于UserID）。
    *   绑定手机号、实名认证，提高刷单成本。
2.  **网络和设备指纹**：
    *   限制同一IP地址、同一设备ID在短时间内的大量砍价行为。
    *   检测IP池、设备农场等黑产工具。
3.  **业务逻辑风控**：
    *   设置砍价金额随机算法，并限制好友帮砍的**金额上限**，避免一个“大佬”直接砍掉大部分。
    *   分析用户社交关系图，异常密集的砍价行为（如突然出现大量“好友”）可以被识别为刷单。
4.  **人机验证**：在关键操作前引入验证码（滑块、点选等），增加自动化脚本的难度。
5.  **监控与审计**：
    *   实时监控砍价成功率、用户行为日志。
    *   建立黑名单系统，对识别出的刷单用户和IP进行处罚。

### 22. 介绍一下分布式事务吧，都有哪些常见的解决方案？

分布式事务用于在分布式系统中保证多个服务/数据库操作的一致性（ACID）。
1.  **2PC（两阶段提交）**：
    *   **阶段一（准备）**：协调者询问所有参与者是否可以提交，参与者执行事务但不提交，并回答“Yes”或“No”。
    *   **阶段二（提交/回滚）**：如果所有参与者都回答“Yes”，协调者发送提交命令；否则发送回滚命令。
    *   **缺点**：同步阻塞、性能差、协调者单点问题。
2.  **3PC（三阶段提交）**：在2PC基础上增加了超时机制和预提交阶段，缓解了阻塞和单点问题，但更复杂。
3.  **TCC（Try-Confirm-Cancel）**：
    *   **Try**：预留业务资源（如冻结库存、预扣款）。
    *   **Confirm**：确认操作，使用预留的资源（真正扣款）。
    *   **Cancel**：取消操作，释放预留的资源。
    *   **优点**：性能好，避免了长事务锁资源。
    *   **缺点**：业务侵入性强，需要为每个操作实现三个接口。
4.  **本地消息表**：
    *   在本地事务中将要执行的异步操作记录到一张数据库表中。
    *   后台任务轮询这张表，将消息发送给其他服务，成功后删除记录。
    *   **优点**：简单，最终一致性。
5.  **MQ事务消息**（如RocketMQ）：
    *   生产者先发送一个“半消息”到MQ，MQ持久化成功但不对消费者可见。
    *   生产者执行本地事务。
    *   根据本地事务执行结果，向MQ发送Commit或Rollback指令。
    *   **优点**：高性能，解耦。是本地消息表的升级版。
6.  **Saga**：
    *   将一个长事务拆分为多个本地短事务。
    *   每个短事务都有一个补偿操作。
    *   事务按顺序执行，如果某一步失败，则按**反方向**依次执行补偿操作。
    *   适用于业务流程长的系统。

### 23. 如果要你设计一个实时的热卖商品排行榜，你会怎么做？

1.  **数据统计**：用户下单后，通过MQ异步发送一条消息，内容为`商品ID`和`销量增量`。
2.  **实时聚合**：使用**Redis Sorted Set**。
    *   Key: `rank:hot`
    *   Member: `商品ID`
    *   Score: `销量`（或其他权重分，如销售额、点击量等）
    *   消费者接收MQ消息，执行`ZINCRBY rank:hot increment productId`命令，更新商品分数。
3.  **查询TopN**：通过`ZREVRANGE rank:hot 0 9 WITHSCORES`即可获取实时Top10。
4.  **优势**：
    *   **高性能**：Redis内存操作，速度极快。
    *   **内置排序**：Sorted Set天然支持排序和范围查询。
    *   **可扩展**：轻松应对高并发读写。

### 24. 在扣减库存的场景里，分布式锁是怎么应用的？Redisson的实现原理了解吗？

*   **应用场景**：防止超卖。多个用户同时抢购同一件商品时，保证只有一个请求能成功扣减库存。
*   **流程**：
    1.  在执行`库存 = 库存 - 1`的SQL前，先尝试获取一个以`商品ID`为Key的分布式锁。
    2.  获取锁成功的请求，执行扣减库存和后续下单逻辑。
    3.  获取锁失败的请求，等待或直接返回“抢购失败”。
    4.  操作完成后，释放锁。

*   **Redisson实现原理**：
    *   Redisson的分布式锁`RLock`实现了Java的`Lock`接口。
    *   **加锁**：它使用Lua脚本向Redis集群执行命令，保证原子性。核心命令是`SET lock_key client_id NX PX 30000`（NX表示不存在才设置，PX设置超时时间）。`client_id`用于标识加锁的客户端，避免其他客户端误删。
    *   **看门狗（Watchdog）机制**：如果获取锁时未指定超时时间，Redisson会启动一个后台线程（看门狗），每隔一段时间（锁失效时间的1/3）检查客户端是否还持有锁，如果是则**延长锁的生存时间**，防止业务未执行完锁就自动释放了。
    *   **解锁**：同样使用Lua脚本，先检查锁是否是自己的（`client_id`匹配），然后再执行删除。
    *   **可重入**：在Redis Hash结构中记录锁的持有者和重入次数。
    *   **RedLock**：Redisson也实现了RedLock算法，用于在多个独立的Redis主节点上获取锁，提高可靠性（但争议较大）。

### 25. 核心代码模式算法题：斐波那契数列

**要求**：高效地计算第n个斐波那契数。

1.  **递归（不推荐）**：效率极低，存在大量重复计算，时间复杂度O(2^n)。
    ```java
    public int fib(int n) {
        if (n <= 1) return n;
        return fib(n - 1) + fib(n - 2);
    }
    ```

2.  **记忆化递归（自顶向下）**：用一个数组缓存已计算的结果。
    ```java
    public int fib(int n) {
        if (n <= 1) return n;
        int[] memo = new int[n + 1];
        Arrays.fill(memo, -1);
        memo[0] = 0;
        memo[1] = 1;
        return helper(n, memo);
    }
    private int helper(int n, int[] memo) {
        if (memo[n] != -1) return memo[n];
        memo[n] = helper(n - 1, memo) + helper(n - 2, memo);
        return memo[n];
    }
    ```

3.  **动态规划（迭代，自底向上）**：**最佳实践**。时间复杂度O(n)，空间复杂度O(1)。
    ```java
    public int fib(int n) {
        if (n <= 1) return n;
        int prev = 0, curr = 1;
        for (int i = 2; i <= n; i++) {
            int sum = prev + curr;
            prev = curr;
            curr = sum;
        }
        return curr;
    }
    ```

4.  **矩阵快速幂（进阶）**：时间复杂度O(log n)。适用于非常大的n（如n=10^9）。
    ```java
    // 思路：将递推关系转化为矩阵乘法，然后用快速幂算法求解
    // [ F(n)   ]   = [1 1]^(n-1) * [F(1)]
    // [ F(n-1) ]     [1 0]          [F(0)]
    // 代码略复杂，面试中能说出思路即可。
    ```

---

希望这份详尽的解答能对你有所帮助！这些问题确实很有深度，准备的过程本身就是一次非常好的学习。祝你面试顺利！
