感谢你对这些技术问题的关注，下面我将为你逐一详细解答，并结合你的面试经历进行一些补充和反思。

### 1. Redis的事务和MySQL的事务区别

| 特性 | Redis 事务 | MySQL 事务 (InnoDB) |
| :--- | :--- | :--- |
| **原子性** | **“部分原子性”**：命令入队错误（如语法错误）则全体不执行；执行期间错误（如对字符串做INC操作）**出错命令不执行，但后续命令继续执行，不会回滚**。 | **真·原子性 (Atomicity)**：是ACID的A。所有操作要么全部成功，要么全部失败并回滚。 |
| **隔离性** | **“单线程天生隔离”**：由于Redis是单线程处理命令，事务中的所有命令会序列化顺序执行，不会被打断。 | **有多级别隔离** (读未提交、读已提交、可重复读、序列化)。通过MVCC、锁等机制实现。 |
| **持久性** | 取决于持久化配置（AOF的`appendfsync`策略）。事务成功不代表数据一定落盘。 | 取决于配置（如`innodb_flush_log_at_trx_commit`）。严格配置下可以保证事务提交后数据持久化。 |
| **一致性** | 不提供强一致性保证。可能出现执行到一半宕机，只有部分命令持久化的情况。 | 提供强一致性保证（在满足原子性、隔离性、持久性的基础上）。 |
| **回滚能力** | **没有回滚（Rollback）机制**。 | **有完整的回滚机制**，使用Undo Log。 |
| **核心思想** | **打包一组命令顺序执行**，主要目的是减少网络开销和保证执行期间的隔离，并非支持ACID。 | **完全支持ACID**的严格事务。 |

**核心区别**：Redis事务的本质是**批量指令脚本**，而MySQL事务是**支持ACID的数据库事务**。

---

### 2. Redis事务在命令入队期间出错了会不会回滚？

**不会回滚，但整个事务都不会执行。**

Redis事务分两步：
1.  **`MULTI`...`EXEC`入队阶段**：客户端将命令发送到服务器的队列中。
2.  **`EXEC`执行阶段**：服务器依次执行队列中的所有命令。

*   **入队期间出错（如语法错误、命令名错误）**：Redis会记录这个错误。当执行`EXEC`时，**服务器会直接拒绝执行整个事务队列中的所有命令**，返回`(error) EXECABORT Transaction discarded because of previous errors.`。
*   **执行期间出错（如对字符串执行`INCR`，类型错误）**：**只有那条出错的命令会失败**，队列中的其他命令会继续执行，**且之前已经执行成功的命令不会被回滚**。

**结论**：只有**入队错误**会导致全体不执行，这不算回滚，而是放弃执行。**执行错误**不会影响其他命令，且没有回滚。

---

### 3. Redis事务底层是如何实现的？

你的回答基本正确。底层主要依赖三个关键数据结构：

1.  **`multiState` 结构体**：包含一个事务队列（`FIFO`）和一个队列长度计数器。
    ```c
    typedef struct multiState {
        multiCmd *commands; // 事务队列，存储所有入队的命令
        int count;          // 已入队命令的数量
        // ...其他字段
    } multiState;
    ```
2.  **`multiCmd` 结构体**：队列中的每个元素，存储了命令的具体信息。
    ```c
    typedef struct multiCmd {
        robj **argv;        // 命令的参数列表
        int argc;           // 参数数量
        struct redisCommand *cmd; // 命令的实现函数指针
    } multiCmd;
    ```
3.  **客户端状态 `client`**：每个Redis客户端都有一个`flags`属性和一个`mstate`（multiState）属性。当客户端执行`MULTI`后，`REDIS_MULTI`标志被打开，后续的命令不再立即执行，而是被解析后存入`mstate.commands`队列。

当收到`EXEC`命令时，服务器遍历客户端`mstate.commands`队列中的每个`multiCmd`，依次调用其`cmd`函数执行命令，并将所有结果返回给客户端。

---

### 4. Redis线程模型

**单 Reactor 单进程 / 单线程模型**。

1.  **文件事件处理器 (File Event Handler)**：基于 **I/O 多路复用** (epoll, kqueue, select) 来同时监听多个套接字（Socket）。
2.  **工作流程**：
    *   **I/O 多路复用程序** 监听所有套接字，并将产生事件的套接字放入一个**队列**。
    *   文件事件分派器从队列中依次取出套接字，并根据事件类型（读/写）将套接字分发给对应的**事件处理器**（命令请求处理器、命令回复处理器、连接应答处理器等）。
    *   事件处理器是**单线程**执行的，它读取请求、解析命令、执行命令、发送回复。
3.  **为什么快？**
    *   纯内存操作。
    *   单线程避免了多线程的上下文切换和竞争条件。
    *   非阻塞I/O多路复用模型，高效处理海量连接。

**注意**：Redis 6.0 引入了**多线程I/O**（默认关闭），但**执行命令的核心模块仍然是单线程**。多线程只用于处理网络数据的读写和解析，这样可以减轻主线程的网络I/O负担，提升整体性能。

---

### 5. Redis持久化方式，只用AOF行不行？

**两种方式**：
1.  **RDB (Redis Database)**：在指定时间间隔生成内存数据的**快照**二进制文件。优点是文件紧凑，恢复快，适合备份。缺点是可能丢失最后一次快照后的数据。
2.  **AOF (Append Only File)**：记录每一次**写命令**，以协议文本格式追加到文件末尾。优点是数据完整性高，最多丢失1秒数据。缺点是文件大，恢复慢。

**只用AOF行不行？**
**可以，但需要权衡。**
*   **优点**：数据最安全，丢失数据风险极低。
*   **缺点**：
    *   AOF文件通常比RDB文件大。
    *   在数据量巨大时，**AOF重写**过程（即使后台`bgrewriteaof`）仍然会对CPU和内存造成额外负担。
    *   历史版本的Bug可能导致AOF文件出错，恢复起来比RDB麻烦。

**生产环境通常同时开启**，用RDB做冷备，用AOF保证数据安全。如果只选一种，**只用AOF是更常见的选择**，因为数据安全更重要。

---

### 6. Redis哨兵模式，如何判断主节点挂了？

**主观下线和客观下线**。

1.  **主观下线 (SDOWN)**：单个Sentinel节点通过**心跳检测（PING）**，在配置的`down-after-milliseconds`时间内没有收到主节点的有效回复，则该Sentinel**主观地**认为主节点下线。
2.  **客观下线 (ODOWN)**：当某个Sentinel认为主节点主观下线后，它会通过 **`SENTINEL is-master-down-by-addr`** 命令**询问**其他Sentinel节点是否也认为该主节点下线。当收到超过配置数量（`quorum`）的“认为下线”的确认后，该Sentinel节点就会将主节点标记为**客观下线**，并发起故障转移。

**Gossip协议**：Sentinel节点之间用来**发现新节点、交换主节点和从节点的状态信息、以及投票**的通信协议。

---

### 7. Redis集群模式，如何判断节点挂了和后续的选举动作？

**集群模式不依赖Sentinel。**

1.  **如何判断节点挂了？**
    *   集群中每个节点都定期向其他节点发送`PING`消息。
    *   如果节点A在`cluster-node-timeout`时间内没有收到节点B的`PONG`回复，则节点A将节点B标记为**疑似下线 (PFAIL)**。
    *   节点A通过Gossip协议将节点B疑似下线的信息传播给集群中的其他节点。
    *   如果某个主节点发现集群中**超过半数的主节点**都认为某个主节点B疑似下线，则节点B将被标记为**已下线 (FAIL)**，并广播一条`FAIL`消息给所有节点。

2.  **后续的选举动作（故障转移）**：
    a. 从节点发现其主节点进入`FAIL`状态。
    b. 从节点等待一个短暂的随机延迟时间（避免多个从节点同时发起选举），然后向集群广播一条`CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST`消息，要求投票。
    c. **主节点投票**：每个持有投票权的主节点在**一个纪元(epoch)内只能投一票**。它会给第一个收到请求的从节点投票。
    d. 如果一个从节点收到了**超过半数的主节点**的投票，它就选举成功。
    e. 选举成功的从节点执行`SLAVEOF no one`晋升为新的主节点，并广播一条`PONG`消息告知集群，更新配置。

---

### 8. Redis缓存淘汰策略

当内存不足时（`used_memory > maxmemory`），Redis根据`maxmemory-policy`配置决定如何回收内存：

*   **针对设置了过期时间的key**：
    *   `volatile-lru`：从已设置过期时间的key中，淘汰**最近最少使用**的。
    *   `volatile-lfu`：从已设置过期时间的key中，淘汰**最不经常使用**的。(4.0+)
    *   `volatile-ttl`：从已设置过期时间的key中，淘汰**存活时间最短**的。
    *   `volatile-random`：从已设置过期时间的key中，**随机**淘汰。
*   **针对所有key**：
    *   `allkeys-lru`：从所有key中，淘汰**最近最少使用**的。**(最常用)**
    *   `allkeys-lfu`：从所有key中，淘汰**最不经常使用**的。(4.0+)
    *   `allkeys-random`：从所有key中，**随机**淘汰。
*   **不淘汰**：
    *   `noeviction`：**默认策略**。不删除任何key，拒绝所有写命令并返回错误，读请求正常。

---

### 9. MySQL的DELETE、TRUNCATE、DROP的区别

| 操作 | 分类 | 功能 | 事务 | 速度 | 恢复 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **DELETE** | **DML** | **删除表中的行数据**。可带`WHERE`条件。 | 可回滚。会触发触发器。 | 慢（逐行删除，写Undo Log） | 支持 |
| **TRUNCATE** | **DDL** | **删除表中的所有行数据，并重置表（如自增ID）。** 本质是`DROP`和`CREATE`表的组合。 | **不可回滚**。不触发触发器。 | 快（直接释放数据页） | 不支持 |
| **DROP** | **DDL** | **删除整个表（包括数据、结构、索引、权限等）。** | **不可回滚**。 | 最快 | 不支持 |

**总结**：
*   `DELETE`是**细粒度**的删除数据。
*   `TRUNCATE`是**快速清空**表数据。
*   `DROP`是**删除整个表**。

---

### 10. MySQL持久化怎么实现的？

主要通过**日志**实现：

1.  **Redo Log (重做日志)**：
    *   **目的**：保证事务的**持久性 (Durability)**。防止在发生故障时，有脏页未写入磁盘。
    *   **实现**：事务提交时，先写Redo Log（顺序写，速度快），再适时将脏页刷盘（随机写，速度慢）。`WAL (Write-Ahead Logging)`技术。
    *   **组成**：通常是两个文件`ib_logfile0`和`ib_logfile1`，循环写入。

2.  **Undo Log (回滚日志)**：
    *   **目的**：保证事务的**原子性 (Atomicity)**。用于事务回滚和MVCC。
    *   **实现**：记录数据被修改前的旧值。回滚时根据Undo Log做逆向操作。

3.  **Binlog (二进制日志)**：
    *   **目的**：**服务器层面**的日志，用于**主从复制**和**数据恢复**。
    *   **模式**：`STATEMENT`（记录SQL语句），`ROW`（记录行的变化），`MIXED`（混合）。

**数据提交流程**（以InnoDB为例）：
1.  事务修改数据，生成Redo Log并写入`log buffer`。
2.  事务提交时，`log buffer`根据配置（`innodb_flush_log_at_trx_commit`）刷入磁盘Redo Log文件。
3.  同时，Binlog也会根据配置（`sync_binlog`）刷盘。
4.  数据库后台线程再将脏页慢慢刷回磁盘。

---

### 11. 什么是MVCC以及MVCC怎么实现的？可重复读和读已提交怎么实现的

*   **MVCC (Multi-Version Concurrency Control)**：多版本并发控制。它通过保存数据的历史版本，使得读操作不会阻塞写操作，写操作也不会阻塞读操作，提高了并发性能。

*   **实现**：InnoDB的MVCC是通过 **Undo Log** 和 **Read View** 来实现的。
    *   **Undo Log**：保存了数据行的多个历史版本。
    *   **隐藏字段**：`DB_TRX_ID`（最近修改该行的事务ID）、`DB_ROLL_PTR`（指向该行上一个历史版本的Undo Log指针）。
    *   **Read View (一致性视图)**：在事务执行快照读时生成，决定了当前事务能看到哪个版本的数据。它包含了：
        *   `m_ids`：生成Read View时，系统中活跃（未提交）的事务ID列表。
        *   `min_trx_id`：`m_ids`中的最小值。
        *   `max_trx_id`：生成Read View时，系统将要分配的下一个事务ID。
        *   `creator_trx_id`：创建该Read View的事务ID。

*   **版本可见性规则**：比较数据行上的`DB_TRX_ID`和当前Read View：
    1.  如果 `trx_id < min_trx_id`，说明该版本在Read View创建前已提交，**可见**。
    2.  如果 `trx_id >= max_trx_id`，说明该版本在Read View创建后才生成，**不可见**。
    3.  如果 `min_trx_id <= trx_id < max_trx_id`，则检查`trx_id`是否在`m_ids`中：
        *   如果在，说明生成该版本的事务当时还未提交，**不可见**。
        *   如果不在，说明生成该版本的事务当时已提交，**可见**。
    如果不可见，就顺着`DB_ROLL_PTR`找到上一个历史版本，重新判断，直到找到可见的版本。

*   **RR (可重复读) 和 RC (读已提交) 的区别**：
    *   **RC**：**每次执行普通SELECT语句前都会生成一个新的Read View**。所以它能读到其他事务**最新已提交**的数据。
    *   **RR**：**只在第一次执行普通SELECT语句时生成一个Read View**，后续的查询都复用这个Read View。所以它在事务期间看到的始终是同样的数据快照，实现了可重复读。

---

### 12. InnoDB引擎层的查询优化

*   **索引下推 (Index Condition Pushdown, ICP)** (5.6+)：
    *   **优化前**：首先根据索引查找记录，然后根据`WHERE`条件到**服务器层**进行过滤。
    *   **优化后**：将`WHERE`条件中**关于索引的过滤条件下推到存储引擎层**完成。减少了回表的次数和服务器层的压力。
    *   **例子**：`SELECT * FROM user WHERE name LIKE '张%' AND age = 10;` 有联合索引`(name, age)`。没有ICP时，引擎找到所有`姓张`的人，然后回表到服务器层再判断`age=10`。有ICP后，引擎在索引内部就直接判断`name LIKE '张%' AND age=10`，只回表符合所有条件的记录。

*   **MRR (Multi-Range Read)**：
    *   优化器先将查询得到的二级索引键值（主键ID）**放入缓冲区进行排序**，然后再根据排序后的主键ID顺序进行**回表**。将随机I/O转变为相对顺序的I/O，大大减少磁盘开销。

*   **覆盖索引 (Covering Index)**：
    *   查询的列都包含在索引中，无需回表，极大提升性能。

---

### 13. 慢SQL排查优化

1.  **排查**：
    *   开启慢查询日志 (`slow_query_log`)，设置阈值 (`long_query_time`)。
    *   使用`EXPLAIN`分析SQL执行计划，关注`type`（访问类型）、`key`（使用的索引）、`rows`（扫描行数）、`Extra`（额外信息，如Using filesort, Using temporary）。
    *   使用`SHOW PROFILE`（已废弃）或`Performance Schema`查看SQL执行的详细资源消耗。

2.  **优化**：
    *   **索引优化**：为`WHERE`, `ORDER BY`, `GROUP BY`, `JOIN ON`的列建立合适的索引。避免索引失效（如函数、运算、类型转换、`!=`、`%前缀模糊查询`）。
    *   **SQL语句优化**：
        *   避免`SELECT *`，只取需要的列。
        *   优化复杂查询，拆分成多个简单查询（MySQL对简单查询支持更好）。
        *   避免使用`%value%`模糊查询。
        *   使用连接（JOIN）代替子查询（大部分情况）。
    *   **设计优化**：合理的数据库结构、表设计（如范式与反范式）、分库分表。

---

### 14. 项目分库分表

*   **何时考虑分表**：没有一个绝对的数字，需要综合考量。
    *   **数据量**：单表数据量达到**千万级别**（一般是2-5千万）是一个常见的参考阈值。但更重要的是**增长速度**。
    *   **性能指标**：即使数据量不大，但如果已经出现明显的性能瓶颈（如查询缓慢、IO等待高），并且通过索引、硬件、SQL优化等手段都无法有效解决时。
    *   **业务复杂度**：单表字段过多，冷热数据混杂，影响查询效率。

*   **如何分**：
    *   **垂直分表**：将一张宽表的冷字段、大字段（如TEXT/BLOB）拆分出去到扩展表。
    *   **水平分表**：按某种规则（Range，Hash，时间等）将数据分散到多个结构相同的表中。
    *   **分库**：在分表的基础上，将表分布到不同的数据库实例上，以缓解连接数和IO压力。

---

### 15. 手撕算法 & 设计模式

*   **接雨水**：经典单调栈或双指针问题，需要多练习。
*   **层序遍历**：使用队列进行BFS。
*   **单例模式**：需要掌握懒汉式（双重检查锁定）、饿汉式、静态内部类、枚举等多种写法及其优缺点（线程安全、延迟加载、序列化安全等）。

---

### 16. volatile解释

`volatile`是Java轻量级的同步机制。

*   **保证可见性**：当一个线程修改了`volatile`变量，新值会**立即被刷新到主内存**。其他线程在使用该变量前，会**强制从主内存重新读取**最新值，而不是使用自己工作内存中的旧值。
*   **禁止指令重排序**：通过插入**内存屏障**，防止JVM和处理器为了优化性能而对指令进行重排序，保证了有序性。
*   **不保证原子性**：`volatile`修饰的变量，自增（i++）等复合操作不是原子性的。

---

### 17. synchronized底层实现原理

*   **Monitor（管程/监视器锁）**：是`synchronized`的底层核心。
*   **Java对象头**：每个Java对象都有一个对象头，其中包含**Mark Word**，它会存储指向Monitor对象的指针。
*   **ObjectMonitor (C++实现)**：这就是Monitor的具体实现。
    ```cpp
    ObjectMonitor() {
        _header       = NULL;
        _count        = 0;      // 重入次数
        _waiters      = 0,      // 等待线程数
        _recursions   = 0;      // 锁的重入次数
        _object       = NULL;
        _owner        = NULL;   // **指向持有该锁的线程**
        _WaitSet      = NULL;   // **处于wait状态的线程队列**
        _WaitSetLock  = 0 ;
        _Responsible  = NULL ;
        _succ         = NULL ;
        _cxq          = NULL ;
        FreeNext      = NULL ;
        _EntryList    = NULL ;  // **处于等待锁block状态的线程队列**
        _SpinFreq     = 0 ;
        _SpinClock    = 0 ;
        OwnerIsThread = 0 ;
        _previous_owner_tid = 0;
    }
    ```
*   **工作流程**：
    1.  线程尝试进入同步代码块，通过CAS操作尝试将`_owner`设置为自身。
    2.  成功，则获取锁，`_count`和`_recursions`置为1。
    3.  失败，则线程 spin（自旋优化）一段时间后，进入`_cxq`队列，然后被挂起（park），等待被唤醒。
    4.  当持有锁的线程执行完，会唤醒`_EntryList`或`_cxq`中的线程，使其重新竞争锁。

---

### 18. synchronized和ReentrantLock

| 特性 | synchronized | ReentrantLock |
| :--- | :--- | :--- |
| **实现** | JVM层面，关键字 | JDK层面，API |
| **锁的获取** | 隐式获取和释放 | 显式`lock()/unlock()` |
| **灵活性** | 不灵活 | 灵活，可尝试非阻塞获取锁(`tryLock`)、可中断(`lockInterruptibly`)、超时获取(`tryLock(time)`) |
| **公平性** | **只有非公平锁** | **两者都可**，构造函数传入`true`创建公平锁。 |
| ** Condition ** | 只有一个等待队列 | 可以绑定多个`Condition`，实现精确唤醒 |

*   **非公平锁实现**：线程获取锁时，**不管等待队列里有没有线程在等，直接尝试用CAS竞争锁**。竞争失败才入队。`ReentrantLock`默认和`synchronized`都是非公平的。
*   **JUC包下的类**：
    *   **锁相关**：`ReentrantLock`, `ReentrantReadWriteLock`, `StampedLock`
    *   **原子类**：`AtomicInteger`, `AtomicReference`
    *   **并发容器**：`ConcurrentHashMap`, `CopyOnWriteArrayList`, `BlockingQueue`的各种实现
    *   **线程池**：`ThreadPoolExecutor`, `Executors`
    *   **同步工具**：`CountDownLatch`, `CyclicBarrier`, `Semaphore`, `Exchanger`

---

### 19. & 20. 线程池与阻塞队列

*   **线程池7大参数**：
    1.  `corePoolSize`：核心线程数。
    2.  `maximumPoolSize`：最大线程数。
    3.  `keepAliveTime`：非核心线程空闲存活时间。
    4.  `unit`：存活时间单位。
    5.  `workQueue`：工作队列（阻塞队列）。
    6.  `threadFactory`：线程工厂。
    7.  `handler`：拒绝策略。

*   **核心线程数设置**：
    *   **CPU密集型**：`CPU核心数 + 1`。
    *   **IO密集型**：`CPU核心数 * (1 + 平均等待时间 / 平均计算时间)`。通常可设置为`2 * CPU核心数`。

*   **队列大小设置（响应速度要求高的场景）**：
    *   你的直觉是对的。**对于响应速度要求高的场景，队列一定不能无界，甚至应该很小（比如0）**。
    *   如果队列很大，任务会堆积在队列中，等待核心线程处理，**响应时间会变长**。
    *   正确的做法是：设置一个**较小的有界队列**（如`SynchronousQueue`或`ArrayBlockingQueue` with small capacity），这样当任务瞬间激增时，会快速创建非核心线程处理，如果线程数也达到最大，则会立即触发拒绝策略，快速失败，让调用方感知到系统压力，而不是让任务无休止地排队等待。

*   **阻塞队列 (BlockingQueue)**：
    *   `ArrayBlockingQueue`：**有界**，数组实现，FIFO。
    *   `LinkedBlockingQueue`：可选有界（默认`Integer.MAX_VALUE`，近乎无界），链表实现，FIFO。
    *   `SynchronousQueue`：**不存储元素**的队列。每个`put`操作必须等待一个`take`操作，反之亦然。直接传递任务。
    *   `PriorityBlockingQueue`：**无界**，支持优先级排序。
    *   `DelayQueue`：**无界**，元素只有到达其指定的延迟时间后，才能被取出。

希望这份详细的总结能帮助你更好地理解和复习这些核心知识点！祝你下次面试顺利！
