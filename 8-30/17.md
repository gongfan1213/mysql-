下面给你一份可直接用于面试现场的「高密度、可展开讲」版本。我把每个题目都整理成了**结构化要点 + 面试话术**，并给了可深入追问的扩展与最佳实践；涉及算法（区间反转链表）按你要求给出**题源映射、复杂度、最优解法与逐行注释 Java 代码**。结尾我挑了一个面试官最常深挖的模块（**MySQL 索引与 B+ 树**）做了“通俗但专业”的长讲稿，方便你在二面里“讲给面试官听”。

---

# 核心知识图谱与解题框架（mermaid）

```mermaid
mindmap
  root((面经全套答题框架))
    0.ai-coding
      ("题目阅读→澄清假设→需求拆分→方案草图→小步提交\n→单测/自测→复杂度与权衡→风险与改进")
    项目介绍
      背景/目标
      架构/职责
      亮点/难点/指标
      复盘/改进
    MCP
      定义/作用
      组成: Client/Server/Tools
      场景: IDE/Agent/LLM
      配置: mcp.json
    Java并发&集合
      HashMap线程安全性
      ConcurrentHashMap对比
      StringBuffer vs StringBuilder
    网络
      TCP/UDP
      场景&权衡
    随机算法
      rand5→rand7
      拒绝采样
    全栈经验
      前后端协作
      工程化/DevOps
    MySQL索引
      B+树为什么
      聚簇/二级索引
      覆盖/回表
      最左前缀/选择性
    秒杀系统设计
      限流/削峰/去重
      预减库存/幂等
      异步下单
      风控/监控
    AI-coding过程复盘
      代码可读性
      可测性
      复杂度&边界
    MCP在AI-coding里如何设置
    Prompt工程
      角色/目标/约束/示例/评测
    Agent vs Ask
      工具调用/状态/自治程度
    手撕题
      反转链表指定区间
      (LeetCode 92)
```

---

## 0. ai-coding（2 小时离线题）最佳答题范式

**面试话术（可直接说）：**

> 我拿到题后会先 10 分钟做需求澄清与边界假设，画出最小架构/伪代码；然后采用“**小步提交**”与“**先可用后最优**”策略，优先打通主路径，立刻补**关键单测**确保回归安全。每 20～30 分钟做一次里程碑自检：功能覆盖、复杂度、异常与日志、性能瓶颈、可维护性。最后 10 分钟补充 README：运行方式、配置、指标、可能的改进方向（如性能/边界/安全/可观测性）与**时间预算对照**。这套流程既保证交付，又暴露我的工程化能力。

**清单（抄用即可）：**

* 澄清：输入输出、边界、错误语义、数据规模、时延目标、资源限制。
* 设计：模块划分、数据结构、复杂度、持久化与缓存策略、并发模型。
* 编码：主路径→异常→日志→参数化→可测试点。
* 测试：功能样例、边界样例、随机/对拍、性能简单压测。
* 复盘：还能优化什么？为什么这次不做（时间/风险/收益）。

---

## 1. 挑一个项目介绍（STAR + 技术深挖）

**结构**：背景（S）→ 目标（T）→ 行动（A）→ 结果（R）→ 技术亮点/难点→ 可指标化成果
**示例话术：**

* 背景&目标：直播业务的**并发在线**与**礼物流水一致性**提升，目标 99.95% SLA、峰值 20 万 QPS。
* 架构：网关（鉴权/限流）→ 赠送礼物服务（幂等/扣库存）→ 账务（TCC/最终一致）→ 消息总线（Kafka）→ 风控（实时规则）。
* 我做的：**Redis 预减库存 + Lua 原子扣减**、**异步下单**、**幂等去重（订单号/去重键）**、**热点 key 分片**、**压测与容量预案**。
* 指标：峰值时 P99 从 280ms 降到 95ms；超卖率从 0.3% → 0%；系统成本降 15%。
* 难点：热点 key、并发扣减一致性、消息重复与顺序；怎么用**监控+熔断+回滚补偿**解决。

---

## 2. MCP 是什么？有什么作用？在哪里用？

* **定义**：MCP（Model Context Protocol）是一套**让 LLM/Agent 与外部工具或数据源以统一协议通信**的标准。它定义了\*\*Client（如 IDE/Agent Runtime）**与**Server（暴露 Tools/Resources 的服务）\*\*如何握手、注册、调用、流式传输与错误处理。
* **作用**：

  * **标准化工具接入**（DB、向量库、HTTP、文件、浏览器等），降低胶水代码成本。
  * **安全与隔离**：明确定义可用工具、参数白名单、资源权限。
  * **可观测**：协议级别的日志/事件，便于审计与调试。
* **在哪里用**：

  * IDE（如 Cursor）里为智能补全/命令面板接入“搜索代码、运行单测、查 API、查询数据库”等；
  * 多智能体系统里作为**统一工具层**；
  * 私有化部署的服务端给多个 Agent/LLM 客户端复用工具。
* **在 AI-coding / Cursor 里如何设置 MCP（通用做法）**：

  1. 在工程根目录准备 `mcp.json`（或 IDE 指定的 MCP 配置入口），声明要启用的 MCP servers；
  2. 每个 server 提供启动命令/端口与暴露的 tools；
  3. 在 IDE 设置里开启 MCP 功能，选择此配置；
  4. 打开命令面板验证工具清单是否可见。
* **示例 `mcp.json`（模板可直接用）**：

```json
{
  "clients": [
    {
      "name": "default",
      "servers": [
        {
          "id": "http",
          "command": "mcp-http-server",
          "args": ["--port", "9090"],
          "env": { "HTTP_PROXY": "" },
          "tools": ["http.request", "http.download"]
        },
        {
          "id": "pgvector",
          "command": "mcp-pgvector",
          "args": ["--dsn", "postgres://user:pass@host:5432/db"],
          "tools": ["vector.search", "vector.upsert"]
        },
        {
          "id": "filesystem",
          "command": "mcp-fs",
          "args": ["--root", "."],
          "tools": ["fs.read", "fs.write", "fs.search"]
        }
      ]
    }
  ]
}
```

> 面试追问可说：与“插件系统/自研工具总线”相比，MCP 的价值是**跨宿主的互通性**与**简化安全边界**；缺点是需要维护协议兼容与版本升级策略。

---

## 3. HashMap 线程安全吗？为什么？

* **结论**：`HashMap` **线程不安全**。多线程并发 put/resize 可能导致**数据丢失、链表形成环（JDK7）、读取到中间态**等。
* **原因**：

  * 复合操作（计算 hash → 定位桶 → 插入/扩容）缺乏原子性；
  * 扩容 `resize` 过程多线程搬迁可能交错，导致结构损坏（JDK8 改成尾插 + treeify 也仍非并发安全）。
* **如何做**：

  * 读多写少：`Collections.synchronizedMap`（粗粒度锁）或 `ConcurrentHashMap`；
  * 高并发：`ConcurrentHashMap`（JDK8：**CAS + 分段桶锁（Node/TreeBin 级）+ volatile 可见性**）；
  * 统计操作使用 `LongAdder`/`AtomicLong` 辅助。
* **最佳实践**：不要在并发场景下用 `HashMap`；避免 `size()` 等近似 O(n) 的聚合操作占热路径；注意 `computeIfAbsent` 的函数副作用与重入风险。

---

## 4. StringBuffer 和 StringBuilder

* **相同点**：二者都是**可变字符序列**，适合频繁拼接。
* **不同点**：

  * `StringBuffer` **方法带 synchronized**，线程安全，开销大；
  * `StringBuilder` 非线程安全，**单线程更快**。
* **JVM 层小知识**：`"a"+x` 在**单次表达式**里会被编译器优化为 `new StringBuilder().append(...)`；但**循环里**反复 `+` 会生成很多临时对象，性能差。
* **最佳实践**：

  * 单线程/局部变量：`StringBuilder`；
  * 需要跨线程共享缓冲区：`StringBuffer` 或上层同步策略；
  * 大拼接任务优先估计容量 `new StringBuilder(cap)` 以减少扩容。

---

## 5. TCP / UDP 特点与应用场景

* **TCP**：面向连接、可靠（重传、乱序重排、流量控制、拥塞控制）、字节流。**适合**：IM、下单接口、文件传输、业务 RPC。
* **UDP**：无连接、不保证到达/顺序、报文（MTU）边界，开销小、时延低。**适合**：实时音视频（配合 FEC/自研重传）、游戏帧同步、DNS。
* **直播业务常见权衡**：

  * 推流侧可走 QUIC/UDP（低时延），播放侧 HLS/DASH（HTTP/TCP，兼容性好）；
  * 内网 RPC 基本走 TCP（稳定性与观测性）。

---

## 6. 用 `rand5()` 实现 `rand7()`（随机算法）

* **类似题**：LeetCode 随机类问题（拒绝采样思想），经典面试题。
* **思路**：`rand5()` ∈ \[1..5]。两次调用生成**均匀的 1..25**：`(rand5()-1)*5 + rand5()`；取值落在 1..21（7 的倍数）就映射到 1..7；若在 22..25，**拒绝重来**。
* **复杂度**：期望常数次循环；时间 `O(1)` 期望，空间 `O(1)`。
* **Java 参考代码**：

```java
// 已给：rand5() 返回 1..5 区间的等概率整数
int rand5();

int rand7() {
    while (true) {                              // 循环直到落在可用区间
        int a = rand5();                        // 第一次 1..5
        int b = rand5();                        // 第二次 1..5
        int idx = (a - 1) * 5 + b;              // 等概率 1..25
        if (idx <= 21) {                        // 只接受 1..21
            return 1 + (idx - 1) % 7;           // 映射到 1..7
        }
        // 否则丢弃 22..25，继续循环
    }
}
```

* **注意**：不要对 25 直接取模 7，会导致 1..7 概率不等。

---

## 7. 做过全栈吗（如何答）

* **答题框**：

  * 前端：React/Next.js、组件复用、SSR/CSR 权衡、性能（懒加载、RUM 指标）。
  * 后端：Spring Boot/Spring Cloud、DDD 模块划分、接口契约、鉴权与幂等。
  * 数据：MySQL 索引设计 + Redis 缓存（旁路/只读副本）+ 消息队列。
  * 工程化：CI/CD、灰度、可观测（日志/指标/链路）、IaC（K8s + Helm）。
* **价值**：端到端故障定位、用户体验与后端指标统一优化、交付速度。

---

## 8. MySQL 索引简介；为什么是 B+ 树；每个节点存什么；聚簇索引一张表有几个？

* **B+ 树为什么**：

  * **IO 友好**：节点按页（一般 16KB）组织，扇出高，**高度低**（常见 2\~4 层）；
  * **范围查询友好**：叶子节点**链表**串联，顺序遍历快；
  * **稳定性**：非叶只存键，叶子存整行（聚簇）或键+主键（二级）；减少内存占用，提升命中率。
* **每个节点存什么**：

  * **聚簇索引（InnoDB）叶子**：**整行记录**；
  * **聚簇索引非叶**：键 + 子指针；
  * **二级索引叶子**：**二级键 + 主键值**（指向聚簇，而非物理地址）；
  * **二级索引非叶**：键 + 子指针。
* **聚簇索引一张表有几个**：**只有 1 个**（InnoDB）。优先级：显式主键 → 首个非空唯一键 → 隐式 6 字节 rowid。
* **关键词**：回表、覆盖索引、最左前缀、选择性、索引下推（ICP）。

> 这一块我在文末做了**面试官可听懂的长讲版**。

---

## 9. 秒杀系统设计（“一台手机，1000 个额度，20:00 开抢”）

**目标**：**不超卖、抗瞬时流量、低时延、可观测与可降级**。
**核心设计**：

1. **流量削峰限流**：边缘/网关限频（IP+设备指纹）、漏桶 + 本地令牌桶，黑白名单。
2. **资格预检**：登录态校验、风控校验（设备、账号、历史行为），直接挡掉灰产。
3. **库存模型**：

   * Redis 预热库存（按活动、sku、分片 key）；
   * **Lua 脚本原子扣减**（`if stock>0 then decr & add user_set else return 0`）+ **用户去重集合**；
   * 扣成功写入消息队列（Kafka）进行**异步下单**；
4. **异步下单**：订单服务消费消息，落库（幂等键：`activityId+userId`），失败走**重试 + 死信队列**；
5. **幂等与去重**：下单、支付均以业务键控幂等；
6. **超时回补**：未支付订单超时（如 15 分钟）回补库存；
7. **观测**：QPS、成功率、延迟分位、库存一致性、重试率、风控拦截率；
8. **应急**：手动熔断、灰度、静态页降级；
9. **手机/设备限额**：在 Lua 中对 `deviceId_set` 做**一次性写入判断**，命中直接拒绝。
   **数据一致性**：最终一致即可：Redis 预减视为“占位”，以消息驱动落库为准；异常回补。

---

## 10. 看我的 ai-coding 过程（面试官关注点）

* **结构化提交**：小步可运行、每步有注释与测试。
* **接口契约**：README 中明确输入/输出/错误码/样例。
* **复杂度说明**：关键函数在注释里标出时间/空间复杂度与边界。
* **可测性**：核心逻辑拆到纯函数，单测覆盖异常。
* **风险与改进**：性能瓶颈（热点、锁竞争）、回退方案、日志级别与脱敏。

---

## 11. 在 ai-coding 里怎么设置 MCP？

* **放置配置**：在工程根目录提供 `mcp.json`（或 IDE 指定位置）。
* **启动工具**：每个 MCP server 需要可启动命令（npm/py/二进制），本机或容器。
* **映射工具**：在配置中声明可调用的工具名与参数白名单。
* **校验**：在 IDE 的命令面板查看可用工具列表，运行一个健康检查工具（如 `fs.read`）。
* **安全**：对外部 HTTP/DB 工具加域名白名单/只读权限；敏感变量走环境变量，不写死在配置里。

> 上面的 `mcp.json` 模板可直接复用，再按题目需要增删工具。

---

## 12. 一个好的 Prompt 包含什么？

* **角色**（你是谁、口吻、规范）、**目标**（要达成的结果与评判标准）、
* **上下文**（输入数据、示例、反例、约束与禁止事项）、
* **过程**（允许的工具、调用上限、输出结构）、
* **自检**（列出核对清单/失败重试条件）、
* **评测**（给示例输入输出，要求对齐）。
  **加分项**：要求模型**先列步骤再执行**、输出**可解析格式**（JSON/MD 表格）、对**不确定性先提问**。

---

## 13. Agent 和 Ask 的区别

* **Ask（一次性问答）**：无持久状态与外部动作，输入→输出。
* **Agent（有“行为”的问答）**：具备**状态、记忆、工具调用、规划-反思**能力，可多轮与外部系统交互（HTTP/DB/文件/浏览器等）。
* **面试表达**：Agent 的关键是**可控性与可观测性**：工具白名单、调用预算、日志/回放、故障注入与回退策略。

---

## 手撕：特定区间反转链表（给头结点与 \[m,n]）

* **LeetCode 对应**：**92. Reverse Linked List II**
* **思路**：

  * 用虚拟头 `dummy`，走到 `m` 前一位 `pre`；
  * 采用**头插法**在 `[m,n]` 区间内部原地反转：每次把 `cur.next` 提到 `pre.next` 的位置；
  * 一次遍历完成，时间 **O(n)**，空间 **O(1)**。
* **边界**：`m==n`、空链表、`m=1`、单节点、区间到尾。
* **完整 Java（逐行注释，最优解）**：

```java
// 单链表节点定义
class ListNode {
    int val;            // 节点的值
    ListNode next;      // 指向下一个节点的指针
    ListNode(int x) { val = x; }
}

class Solution {
    public ListNode reverseBetween(ListNode head, int m, int n) {
        if (head == null || m == n) return head;   // 边界：空链表或区间长度为 1，无需处理

        ListNode dummy = new ListNode(0);          // 虚拟头结点，便于处理 m=1 的情况
        dummy.next = head;                         // 将虚拟头连到原链表头
        ListNode pre = dummy;                      // pre 指向待反转区间的前一个节点

        // 1) 将 pre 移动到第 m-1 个节点（即区间前驱）
        for (int i = 1; i < m; i++) {
            pre = pre.next;                        // 向前移动，直到到达 m 的前一个位置
        }

        // 2) 开始原地头插法反转区间 [m, n]
        ListNode cur = pre.next;                   // cur 指向区间的第一个节点（位置 m）
        // 循环 n - m 次，每次把 cur 后面的节点挪到 pre 后面，实现局部反转
        for (int i = 0; i < n - m; i++) {
            ListNode move = cur.next;              // 待移动的节点（位于 cur 的后一个）
            cur.next = move.next;                  // 先从原位置摘下 move（cur 跳过 move）
            move.next = pre.next;                  // 将 move 插到 pre 后（接到已反转片段前部）
            pre.next = move;                       // pre 连接到 move（头插完成）
        }

        return dummy.next;                         // 返回新的头结点（可能已变化）
    }
}
```

---

# 通俗讲解（面试官爱追问模块）——深入讲「MySQL 索引与 B+ 树」

> **场景引入（直播业务）**：礼物流水表 `gift_order` 每天千万级写入，常用查询是“按 `user_id` + 时间范围”查订单，“按 `order_no` 精确查一笔”。为什么我们用 **InnoDB + B+树索引**？

1. **B+ 树的形态**：可以把它理解成“**多叉有序目录**”。

* 内部节点只放“目录”（有序键 + 指针），**很薄**；
* **叶子节点才放数据**：

  * 对**聚簇索引**（主索引）：放整行记录；
  * 对**二级索引**：放（二级键 + 主键值）。
* 所有叶子通过**双向链表**串起来，范围扫描像“顺着书脊翻页”。

2. **为什么不是 B 树/跳表/红黑树？**

* **磁盘/页友好**是关键。B+ 树每个节点对应一个页（一般 16KB），由于内部节点不带数据，**扇出极大**（一页能放超多键），树**高度很低**，命中缓存的概率大，IO 次数小。
* 跳表/红黑树更适合内存结构；落盘后没有页意识、范围查询也不如 B+ 树叶子链表自然。

3. **回表与覆盖索引**：

* 走**二级索引**时，叶子只有（`secondary_key`, `PK`），还需“**回表**”到聚簇索引按主键取整行；
* 如果查询列都在二级索引里（或用 `include columns` 的覆盖），就**不回表**，延迟大幅降低。
* **面试话术**：我会优先按**高选择性**的等值条件建联合索引，并让查询**尽量覆盖**。

4. **最左前缀与联合索引**：

* 索引 `(a,b,c)` 能用于条件：`a`；`a,b`；`a,b,c`；以及对 `a` 的范围 + `b` 的等值可能失效。
* 直播“按 `user_id` + `create_time` 范围”很常见，可建 `(user_id, create_time)`，**user\_id 等值**、时间范围扫描刚好沿叶子链表走。

5. **聚簇索引到底有几个？**

* InnoDB **每表恰好 1 个**聚簇索引：优先主键；没有主键则选**首个非空唯一键**；否则创建隐藏 rowid。
* 因为聚簇叶子直接存整行，**只能有一个**。

6. **小坑 & 经验**：

* 主键尽量**递增**（如雪花 ID），减少页分裂；避免 UUID 这种离散主键做聚簇索引。
* 范围 + 排序常导致“**Using filesort**”，必要时让排序列参与索引或做**覆盖**。
* 大事务/批量导入：先关 `unique_checks`、`foreign_key_checks`，批量导入后再建索引/打开检查（要评估业务风险）。
* 指标观测：`Handler_read_key/next`、`Innodb_buffer_pool_read_requests`、`buffer_pool hit ratio`、慢日志采样。

> **一句话总结**：B+ 树把**磁盘 IO 次数最小化**和**范围扫描效率最大化**做到了极致，配合“高选择性联合索引 + 覆盖索引 + 最左前缀”原则，基本能拿到 80% 的线上收益。

---

## 附：面试官常追问的“为什么”与“怎么做”

* **为什么 Redis 预减库存不会超卖？**
  Lua 原子校验 `stock>0` 再 `decr`，失败不产生消息；最终以订单落库为准，失败或超时**回补**库存。
* **ConcurrentHashMap 为什么比 synchronizedMap 快？**
  JDK8 利用 **CAS + 节点级锁**，减少全表/全桶锁竞争；并发读无锁，写时锁粒度更细。
* **为什么随机拒绝采样是正确的？**
  因为从 25 个等可能结果筛出前 21 个仍然等可能，再按模 7 映射保持均匀。

---

### 你可以直接“照着说”的 30 秒总结

> 这轮我重点想展示三点：第一，有端到端思考并能在有限时间交付（ai-coding 的小步提交、单测与复杂度说明）；第二，关键系统设计能力（直播秒杀：限流、预减、异步下单、幂等与回补）；第三，数据库与并发的深度（B+ 树索引设计、覆盖索引与最左前缀；HashMap 与 CHM 的并发模型差异）。手撕题我用虚拟头 + 头插法，`O(n)/O(1)`，能覆盖所有边界。若有时间，我可以展开讲索引落地的压测与观测方案。

---

如果你希望，我可以把**MCP 的 `mcp.json`**和**秒杀的 Lua 脚本**、以及**JMH 基准/单测样例**整理成一个小仓库结构，方便你二面直接展示与讲解。
